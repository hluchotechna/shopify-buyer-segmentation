2018-07-30 11:52:42,427: Tracking: tracking
2018-07-30 11:52:42,431: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5042b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e504a58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e504d30>]}
2018-07-30 11:52:44,286: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 11:52:44,342: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 11:52:44,349: Parsing get_column_values.sql
2018-07-30 11:52:44,372: Parsing get_url_parameter.sql
2018-07-30 11:52:44,381: Parsing split_part.sql
2018-07-30 11:52:44,392: Parsing table_exists.sql
2018-07-30 11:52:44,410: Parsing core.sql
2018-07-30 11:52:44,431: Parsing adapters/bigquery.sql
2018-07-30 11:52:44,447: Parsing adapters/common.sql
2018-07-30 11:52:44,488: Parsing adapters/redshift.sql
2018-07-30 11:52:44,524: Parsing adapters/snowflake.sql
2018-07-30 11:52:44,532: Parsing etc/bigquery.sql
2018-07-30 11:52:44,537: Parsing etc/datetime.sql
2018-07-30 11:52:44,592: Parsing etc/get_custom_schema.sql
2018-07-30 11:52:44,606: Parsing materializations/helpers.sql
2018-07-30 11:52:44,628: Parsing materializations/archive/archive.sql
2018-07-30 11:52:44,678: Parsing materializations/incremental/incremental.sql
2018-07-30 11:52:44,725: Parsing materializations/seed/bigquery.sql
2018-07-30 11:52:44,756: Parsing materializations/seed/seed.sql
2018-07-30 11:52:44,844: Parsing materializations/table/bigquery_table.sql
2018-07-30 11:52:44,896: Parsing materializations/table/table.sql
2018-07-30 11:52:44,938: Parsing materializations/view/bigquery_view.sql
2018-07-30 11:52:44,956: Parsing materializations/view/view.sql
2018-07-30 11:52:44,993: Parsing schema_tests/accepted_values.sql
2018-07-30 11:52:44,999: Parsing schema_tests/not_null.sql
2018-07-30 11:52:45,004: Parsing schema_tests/relationships.sql
2018-07-30 11:52:45,012: Parsing schema_tests/unique.sql
2018-07-30 11:52:45,051: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 11:52:45,054: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 11:52:45,058: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 11:52:45,061: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 11:52:45,064: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 11:52:45,080: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 11:52:45,088: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 11:52:45,097: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 11:52:45,110: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 11:52:45,118: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 11:52:45,125: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 11:52:45,128: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 11:52:45,132: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 11:52:45,135: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 11:52:45,137: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 11:52:45,143: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 11:52:45,151: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 11:52:45,157: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 11:52:45,161: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 11:52:45,166: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 11:52:45,169: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 11:52:45,180: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 11:52:45,202: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 11:52:45,209: 
2018-07-30 11:52:45,217: Acquiring new bigquery connection "master".
2018-07-30 11:52:45,217: Opening a new connection (0 currently allocated)
2018-07-30 11:52:46,748: 11:52:46 | Concurrency: 4 threads (target='template')
2018-07-30 11:52:46,748: 11:52:46 | 
2018-07-30 11:52:46,869: 11:52:46 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 11:52:46,870: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 11:52:46,869: 11:52:46 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 11:52:46,870: 11:52:46 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 11:52:46,870: 11:52:46 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 11:52:46,877: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 11:52:46,878: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 11:52:46,878: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 11:52:46,879: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 11:52:46,883: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 11:52:46,889: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 11:52:46,900: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 11:52:46,902: Acquiring new bigquery connection "monthend_dates".
2018-07-30 11:52:46,906: Acquiring new bigquery connection "all_dates".
2018-07-30 11:52:46,906: Opening a new connection (1 currently allocated)
2018-07-30 11:52:46,910: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 11:52:46,913: Opening a new connection (2 currently allocated)
2018-07-30 11:52:46,916: Acquiring new bigquery connection "stores_proc".
2018-07-30 11:52:46,920: Opening a new connection (3 currently allocated)
2018-07-30 11:52:46,930: Opening a new connection (4 currently allocated)
2018-07-30 11:52:47,462: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 11:52:47,489: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 11:52:47,513: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 11:52:47,514: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 11:52:47,526: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 11:52:47,530: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 11:52:47,541: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 11:52:47,547: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 11:52:49,497: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e665dd8>]}
2018-07-30 11:52:49,691: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e698470>]}
2018-07-30 11:52:49,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e698438>]}
2018-07-30 11:52:49,798: 11:52:49 | 1 of 22 OK created table model template.monthend_dates............... [OK in 2.63s]
2018-07-30 11:52:49,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e651278>]}
2018-07-30 11:52:50,097: 11:52:50 | 4 of 22 OK created table model template.stores_proc.................. [OK in 2.81s]
2018-07-30 11:52:50,873: 11:52:50 | 2 of 22 OK created table model template.all_dates.................... [OK in 2.92s]
2018-07-30 11:52:52,087: 11:52:52 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.10s]
2018-07-30 11:52:52,088: 11:52:52 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 11:52:52,088: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 11:52:52,088: 11:52:52 | 6 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 11:52:52,094: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 11:52:52,101: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 11:52:52,088: 11:52:52 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 11:52:52,101: Re-using an available connection from the pool.
2018-07-30 11:52:52,101: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 11:52:52,114: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 11:52:52,128: Re-using an available connection from the pool.
2018-07-30 11:52:52,136: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:52,114: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:52,136: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 11:52:52,145: Re-using an available connection from the pool.
2018-07-30 11:52:52,145: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:53,835: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 11:52:53,838: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 11:52:54,002: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 11:52:54,003: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 11:52:54,009: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 11:52:54,012: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 11:52:54,297: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 11:52:54,494: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 11:52:54,496: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 11:52:56,253: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e651d30>]}
2018-07-30 11:52:56,606: 11:52:56 | 6 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.16s]
2018-07-30 11:52:56,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6bfbe0>]}
2018-07-30 11:52:57,120: 11:52:57 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.71s]
2018-07-30 11:52:58,705: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce29f98>]}
2018-07-30 11:52:59,119: 11:52:59 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.60s]
2018-07-30 11:52:59,119: 11:52:59 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 11:52:59,120: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 11:52:59,120: 11:52:59 | 9 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 11:52:59,122: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 11:52:59,129: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 11:52:59,120: 11:52:59 | 10 of 22 START table model template.shopify_products_proc............ [RUN]
2018-07-30 11:52:59,135: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 11:52:59,145: Acquiring new bigquery connection "ga_transactions".
2018-07-30 11:52:59,149: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 11:52:59,149: Re-using an available connection from the pool.
2018-07-30 11:52:59,149: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:59,150: Re-using an available connection from the pool.
2018-07-30 11:52:59,151: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:59,155: Acquiring new bigquery connection "agg_customers".
2018-07-30 11:52:59,156: Re-using an available connection from the pool.
2018-07-30 11:52:59,286: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 11:52:59,288: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 11:52:59,979: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 11:53:00,204: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 11:53:00,205: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 11:53:01,006: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 11:53:01,302: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 11:53:01,303: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 11:53:02,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc445f8>]}
2018-07-30 11:53:03,253: 11:53:03 | 10 of 22 OK created table model template.shopify_products_proc....... [OK in 3.80s]
2018-07-30 11:53:03,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc44470>]}
2018-07-30 11:53:03,864: 11:53:03 | 9 of 22 OK created table model template.agg_customers................ [OK in 4.41s]
2018-07-30 11:53:28,920: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:53:30,190: 11:53:30 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 29.80s]
2018-07-30 11:53:30,191: 11:53:30 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 11:53:30,192: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 11:53:30,210: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 11:53:30,210: Re-using an available connection from the pool.
2018-07-30 11:53:30,211: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:53:31,319: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 11:53:31,520: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 11:53:31,521: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 11:53:42,165: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce29f98>]}
2018-07-30 11:53:44,797: 11:53:44 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.97s]
2018-07-30 11:53:44,798: 11:53:44 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 11:53:44,799: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 11:53:44,813: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 11:53:44,815: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 11:53:44,816: Re-using an available connection from the pool.
2018-07-30 11:53:45,091: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 11:53:45,092: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 11:53:49,616: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:53:50,729: 11:53:50 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.82s]
2018-07-30 11:53:50,731: 11:53:50 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 11:53:50,732: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 11:53:50,744: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 11:53:50,748: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 11:53:50,748: Re-using an available connection from the pool.
2018-07-30 11:53:50,892: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 11:53:50,892: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 11:53:54,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:53:55,393: 11:53:55 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.10s]
2018-07-30 11:53:55,394: 11:53:55 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 11:53:55,394: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 11:53:55,404: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 11:53:55,406: Acquiring new bigquery connection "agg_transactions".
2018-07-30 11:53:55,406: Re-using an available connection from the pool.
2018-07-30 11:53:55,536: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 11:53:55,537: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 11:54:05,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:54:05,653: 11:54:05 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.95s]
2018-07-30 11:54:05,653: 11:54:05 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 11:54:05,654: 11:54:05 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 11:54:05,654: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 11:54:05,654: 11:54:05 | 17 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 11:54:05,654: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 11:54:05,662: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 11:54:05,663: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 11:54:05,672: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 11:54:05,679: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 11:54:05,682: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 11:54:05,684: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 11:54:05,684: Re-using an available connection from the pool.
2018-07-30 11:54:05,685: Re-using an available connection from the pool.
2018-07-30 11:54:05,687: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 11:54:05,689: Re-using an available connection from the pool.
2018-07-30 11:54:05,915: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 11:54:05,921: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 11:54:05,921: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY month, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 11:54:05,925: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 11:54:06,296: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 11:54:06,304: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 11:54:06,504: Bad request while running:
create dataset
2018-07-30 11:54:06,505: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/6cfada23-2a53-4ba8-8466-60c3f4ed9939?maxResults=0: Unrecognized name: month at [50:10]
2018-07-30 11:54:06,505: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6667b8>]}
2018-07-30 11:54:07,598: 11:54:07 | 17 of 22 ERROR creating table model template.monthly_cohort_stats.... [ERROR in 0.84s]
2018-07-30 11:54:18,873: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e681860>]}
2018-07-30 11:54:19,367: 11:54:19 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.22s]
2018-07-30 11:54:32,407: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:54:32,987: 11:54:32 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 26.75s]
2018-07-30 11:54:32,989: 11:54:32 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 11:54:32,990: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 11:54:33,012: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 11:54:33,017: Acquiring new bigquery connection "customers_proc".
2018-07-30 11:54:33,018: Re-using an available connection from the pool.
2018-07-30 11:54:33,199: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 11:54:33,200: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 11:55:00,654: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:55:01,961: 11:55:01 | 18 of 22 OK created table model template.customers_proc.............. [OK in 27.66s]
2018-07-30 11:55:01,963: 11:55:01 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 11:55:01,964: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 11:55:01,977: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 11:55:01,979: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 11:55:01,979: Re-using an available connection from the pool.
2018-07-30 11:55:02,162: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 11:55:02,163: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 11:55:29,821: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:55:30,157: 11:55:30 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 27.86s]
2018-07-30 11:55:30,157: 11:55:30 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 11:55:30,158: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 11:55:30,166: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 11:55:30,171: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 11:55:30,171: Re-using an available connection from the pool.
2018-07-30 11:55:30,298: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 11:55:30,299: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 11:56:04,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:56:05,590: 11:56:05 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 34.11s]
2018-07-30 11:56:05,592: 11:56:05 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 11:56:05,593: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 11:56:05,612: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 11:56:05,615: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 11:56:05,615: Re-using an available connection from the pool.
2018-07-30 11:56:05,731: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 11:56:05,732: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 11:56:09,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:56:10,757: 11:56:10 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 4.03s]
2018-07-30 11:56:10,761: 11:56:10 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 11:56:10,761: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 11:56:10,770: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 11:56:10,774: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 11:56:10,774: Re-using an available connection from the pool.
2018-07-30 11:56:11,070: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 11:56:11,076: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 11:56:51,037: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:56:51,360: 11:56:51 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 40.28s]
2018-07-30 11:56:51,454: 11:56:51 | 
2018-07-30 11:56:51,454: 11:56:51 | Finished running 22 table models in 246.24s.
2018-07-30 11:56:51,455: Connection 'master' was left open.
2018-07-30 11:56:51,455: 
2018-07-30 11:56:51,455: Completed with 1 errors:
2018-07-30 11:56:51,455: 
2018-07-30 11:56:51,455: Database Error in model monthly_cohort_stats (models/math/cohort-analysis/monthly_cohort_stats.sql)
2018-07-30 11:56:51,456:   Unrecognized name: month at [50:10]
2018-07-30 11:56:51,456:   compiled SQL at target/run/shopify_cohort_analysis/math/cohort-analysis/monthly_cohort_stats.sql
2018-07-30 11:56:51,456: 
Done. PASS=21 ERROR=1 SKIP=0 TOTAL=22
2018-07-30 11:56:51,456: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b394e48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3630f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b363080>]}
2018-07-30 11:56:51,754: Flushing usage events
2018-07-30 11:56:52,201: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50097), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,202: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50096), raddr=('172.217.3.10', 443)>

2018-07-30 11:56:52,202: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50095), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,203: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50098), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,203: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50099), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,203: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50100), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,204: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50102), raddr=('172.217.12.10', 443)>

2018-07-30 11:56:52,204: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50101), raddr=('172.217.12.10', 443)>

2018-07-30 11:56:52,205: sys:1: ResourceWarning: unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50103), raddr=('172.217.12.10', 443)>

2018-07-30 11:56:52,205: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50104), raddr=('172.217.12.10', 443)>

2018-07-30 12:03:17,996: Tracking: tracking
2018-07-30 12:03:17,998: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082502b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108250f28>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108250128>]}
2018-07-30 12:03:20,323: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:03:20,377: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:03:20,384: Parsing get_column_values.sql
2018-07-30 12:03:20,418: Parsing get_url_parameter.sql
2018-07-30 12:03:20,430: Parsing split_part.sql
2018-07-30 12:03:20,449: Parsing table_exists.sql
2018-07-30 12:03:20,474: Parsing core.sql
2018-07-30 12:03:20,522: Parsing adapters/bigquery.sql
2018-07-30 12:03:20,533: Parsing adapters/common.sql
2018-07-30 12:03:20,602: Parsing adapters/redshift.sql
2018-07-30 12:03:20,638: Parsing adapters/snowflake.sql
2018-07-30 12:03:20,648: Parsing etc/bigquery.sql
2018-07-30 12:03:20,652: Parsing etc/datetime.sql
2018-07-30 12:03:20,726: Parsing etc/get_custom_schema.sql
2018-07-30 12:03:20,743: Parsing materializations/helpers.sql
2018-07-30 12:03:20,780: Parsing materializations/archive/archive.sql
2018-07-30 12:03:20,934: Parsing materializations/incremental/incremental.sql
2018-07-30 12:03:20,981: Parsing materializations/seed/bigquery.sql
2018-07-30 12:03:20,995: Parsing materializations/seed/seed.sql
2018-07-30 12:03:21,064: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:03:21,115: Parsing materializations/table/table.sql
2018-07-30 12:03:21,163: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:03:21,215: Parsing materializations/view/view.sql
2018-07-30 12:03:21,262: Parsing schema_tests/accepted_values.sql
2018-07-30 12:03:21,274: Parsing schema_tests/not_null.sql
2018-07-30 12:03:21,280: Parsing schema_tests/relationships.sql
2018-07-30 12:03:21,285: Parsing schema_tests/unique.sql
2018-07-30 12:03:21,318: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:03:21,322: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:03:21,326: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:03:21,329: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:03:21,332: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:03:21,348: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:03:21,360: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:03:21,368: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:03:21,384: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:03:21,398: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:03:21,414: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:03:21,418: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:03:21,425: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:03:21,429: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:03:21,433: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:03:21,439: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:03:21,451: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:03:21,457: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:03:21,462: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:03:21,468: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:03:21,474: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:03:21,482: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:03:21,517: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:03:21,546: 
2018-07-30 12:03:21,634: Acquiring new bigquery connection "master".
2018-07-30 12:03:21,635: Opening a new connection (0 currently allocated)
2018-07-30 12:03:24,349: 12:03:24 | Concurrency: 4 threads (target='template')
2018-07-30 12:03:24,349: 12:03:24 | 
2018-07-30 12:03:24,461: 12:03:24 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:03:24,462: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:03:24,462: 12:03:24 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:03:24,469: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:03:24,462: 12:03:24 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:03:24,485: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:03:24,470: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:03:24,484: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:03:24,462: 12:03:24 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:03:24,499: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:03:24,500: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:03:24,516: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:03:24,516: Opening a new connection (1 currently allocated)
2018-07-30 12:03:24,526: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:03:24,531: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:03:24,532: Acquiring new bigquery connection "all_dates".
2018-07-30 12:03:24,534: Opening a new connection (2 currently allocated)
2018-07-30 12:03:24,538: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:03:24,543: Opening a new connection (3 currently allocated)
2018-07-30 12:03:24,546: Opening a new connection (4 currently allocated)
2018-07-30 12:03:26,092: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:03:26,102: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:03:26,103: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:03:26,107: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:03:26,396: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:03:26,397: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:03:26,697: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:03:26,697: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:03:28,006: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105884400>]}
2018-07-30 12:03:28,010: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:03:28,560: 12:03:28 | 1 of 22 OK created table model template.monthend_dates............... [OK in 3.54s]
2018-07-30 12:03:28,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105884240>]}
2018-07-30 12:03:28,827: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583c4a8>]}
2018-07-30 12:03:29,000: 12:03:29 | 2 of 22 OK created table model template.all_dates.................... [OK in 3.54s]
2018-07-30 12:03:29,318: 12:03:29 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 4.31s]
2018-07-30 12:03:29,630: 12:03:29 | 4 of 22 OK created table model template.stores_proc.................. [OK in 4.33s]
2018-07-30 12:03:29,630: 12:03:29 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:03:29,631: 12:03:29 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:03:29,631: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:03:29,631: 12:03:29 | 7 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:03:29,631: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:03:29,634: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:03:29,657: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:03:29,659: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:03:29,664: Re-using an available connection from the pool.
2018-07-30 12:03:29,668: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:03:29,668: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:29,668: Re-using an available connection from the pool.
2018-07-30 12:03:29,669: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:29,677: Re-using an available connection from the pool.
2018-07-30 12:03:29,677: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:31,734: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:03:31,992: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:03:32,115: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:03:32,142: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:03:32,142: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:03:32,276: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:03:32,277: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:03:32,326: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:03:32,327: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:03:36,463: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083bb400>]}
2018-07-30 12:03:38,366: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058dc2e8>]}
2018-07-30 12:03:38,606: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:03:39,763: 12:03:39 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 6.83s]
2018-07-30 12:03:40,199: 12:03:40 | 7 of 22 OK created table model template.shopify_discounts_proc....... [OK in 8.73s]
2018-07-30 12:03:40,564: 12:03:40 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 8.97s]
2018-07-30 12:03:40,565: 12:03:40 | 8 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 12:03:40,565: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:03:40,565: 12:03:40 | 9 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:03:40,580: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:03:40,586: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:03:40,565: 12:03:40 | 10 of 22 START table model template.shopify_products_proc............ [RUN]
2018-07-30 12:03:40,603: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:03:40,608: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:03:40,620: Re-using an available connection from the pool.
2018-07-30 12:03:40,621: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:40,644: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:03:40,647: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:03:40,647: Re-using an available connection from the pool.
2018-07-30 12:03:40,647: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:40,657: Re-using an available connection from the pool.
2018-07-30 12:03:40,901: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:03:40,903: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:03:41,597: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:03:41,865: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:03:41,865: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:03:43,220: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:03:43,432: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:03:43,433: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:03:44,948: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10838a2b0>]}
2018-07-30 12:03:45,268: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583c4a8>]}
2018-07-30 12:03:48,239: 12:03:48 | 10 of 22 OK created table model template.shopify_products_proc....... [OK in 4.34s]
2018-07-30 12:03:49,274: 12:03:49 | 8 of 22 OK created table model template.agg_customers................ [OK in 4.70s]
2018-07-30 12:04:08,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10584e898>]}
2018-07-30 12:04:09,359: 12:04:09 | 9 of 22 OK created table model template.ga_transactions.............. [OK in 27.71s]
2018-07-30 12:04:09,360: 12:04:09 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:04:09,360: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:04:09,380: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:04:09,380: Re-using an available connection from the pool.
2018-07-30 12:04:09,380: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:04:10,386: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:04:10,692: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:04:10,693: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:04:19,141: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:04:19,696: 12:04:19 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 9.78s]
2018-07-30 12:04:19,697: 12:04:19 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:04:19,697: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:04:19,703: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:04:19,704: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:04:19,704: Re-using an available connection from the pool.
2018-07-30 12:04:19,864: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:04:19,865: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:04:24,955: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:04:26,964: 12:04:26 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 5.26s]
2018-07-30 12:04:26,965: 12:04:26 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:04:26,965: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:04:26,972: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:04:26,977: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:04:26,977: Re-using an available connection from the pool.
2018-07-30 12:04:27,268: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:04:27,268: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:04:31,262: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:04:33,461: 12:04:33 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.30s]
2018-07-30 12:04:33,465: 12:04:33 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:04:33,466: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:04:33,474: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:04:33,477: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:04:33,477: Re-using an available connection from the pool.
2018-07-30 12:04:33,818: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:04:33,819: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:04:42,974: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:04:44,110: 12:04:44 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.51s]
2018-07-30 12:04:44,111: 12:04:44 | 15 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:04:44,111: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:04:44,117: 12:04:44 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:04:44,117: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:04:44,123: 12:04:44 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:04:44,132: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:04:44,134: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:04:44,138: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:04:44,152: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:04:44,161: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:04:44,161: Re-using an available connection from the pool.
2018-07-30 12:04:44,155: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:04:44,169: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:04:44,197: Re-using an available connection from the pool.
2018-07-30 12:04:44,199: Re-using an available connection from the pool.
2018-07-30 12:04:44,463: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:04:44,464: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:04:44,559: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:04:44,560: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:04:45,671: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:04:45,672: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:04:50,512: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:04:52,602: 12:04:52 | 15 of 22 OK created table model template.monthly_cohort_stats........ [OK in 6.40s]
2018-07-30 12:04:58,096: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105853cc0>]}
2018-07-30 12:04:58,400: 12:04:58 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.98s]
2018-07-30 12:05:08,233: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058d4710>]}
2018-07-30 12:05:08,559: 12:05:08 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 24.10s]
2018-07-30 12:05:08,560: 12:05:08 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:05:08,563: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:05:08,594: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:05:08,602: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:05:08,602: Re-using an available connection from the pool.
2018-07-30 12:05:08,772: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:05:08,773: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:05:35,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:05:37,313: 12:05:37 | 18 of 22 OK created table model template.customers_proc.............. [OK in 27.34s]
2018-07-30 12:05:37,318: 12:05:37 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:05:37,318: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:05:37,351: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:05:37,360: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:05:37,360: Re-using an available connection from the pool.
2018-07-30 12:05:37,591: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:05:37,592: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:06:09,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105867c88>]}
2018-07-30 12:06:10,271: 12:06:10 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 32.62s]
2018-07-30 12:06:10,272: 12:06:10 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:06:10,273: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:06:10,291: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:06:10,295: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:06:10,295: Re-using an available connection from the pool.
2018-07-30 12:06:10,431: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:06:10,431: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:06:57,135: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:06:58,082: 12:06:58 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 46.86s]
2018-07-30 12:06:58,087: 12:06:58 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:06:58,087: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:06:58,124: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:06:58,132: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:06:58,132: Re-using an available connection from the pool.
2018-07-30 12:06:58,672: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:06:58,673: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:07:04,275: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083501d0>]}
2018-07-30 12:07:04,836: 12:07:04 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 6.19s]
2018-07-30 12:07:04,837: 12:07:04 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:07:04,838: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:07:04,861: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:07:04,864: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:07:04,865: Re-using an available connection from the pool.
2018-07-30 12:07:05,478: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:07:05,479: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:07:39,618: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:07:40,004: 12:07:40 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 34.78s]
2018-07-30 12:07:40,098: 12:07:40 | 
2018-07-30 12:07:40,098: 12:07:40 | Finished running 22 table models in 258.55s.
2018-07-30 12:07:40,099: Connection 'master' was left open.
2018-07-30 12:07:40,099: 
2018-07-30 12:07:40,100: Completed successfully
2018-07-30 12:07:40,100: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 12:07:40,101: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10831c1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10831c780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083504e0>]}
2018-07-30 12:07:40,484: Flushing usage events
2018-07-30 12:07:41,066: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50221), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,068: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50220), raddr=('172.217.1.202', 443)>

2018-07-30 12:07:41,068: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50218), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,069: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50222), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,077: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50226), raddr=('172.217.2.10', 443)>

2018-07-30 12:07:41,079: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50223), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,079: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50224), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,080: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50227), raddr=('172.217.2.10', 443)>

2018-07-30 12:07:41,080: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50225), raddr=('172.217.2.10', 443)>

2018-07-30 12:07:41,081: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50228), raddr=('172.217.2.10', 443)>

2018-07-30 12:28:00,115: Tracking: tracking
2018-07-30 12:28:00,117: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108524e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108524278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108524ef0>]}
2018-07-30 12:28:01,092: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:28:01,120: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:28:01,127: Parsing get_column_values.sql
2018-07-30 12:28:01,148: Parsing get_url_parameter.sql
2018-07-30 12:28:01,154: Parsing split_part.sql
2018-07-30 12:28:01,162: Parsing table_exists.sql
2018-07-30 12:28:01,174: Parsing core.sql
2018-07-30 12:28:01,189: Parsing adapters/bigquery.sql
2018-07-30 12:28:01,198: Parsing adapters/common.sql
2018-07-30 12:28:01,225: Parsing adapters/redshift.sql
2018-07-30 12:28:01,246: Parsing adapters/snowflake.sql
2018-07-30 12:28:01,252: Parsing etc/bigquery.sql
2018-07-30 12:28:01,257: Parsing etc/datetime.sql
2018-07-30 12:28:01,286: Parsing etc/get_custom_schema.sql
2018-07-30 12:28:01,294: Parsing materializations/helpers.sql
2018-07-30 12:28:01,316: Parsing materializations/archive/archive.sql
2018-07-30 12:28:01,364: Parsing materializations/incremental/incremental.sql
2018-07-30 12:28:01,400: Parsing materializations/seed/bigquery.sql
2018-07-30 12:28:01,408: Parsing materializations/seed/seed.sql
2018-07-30 12:28:01,466: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:28:01,509: Parsing materializations/table/table.sql
2018-07-30 12:28:01,543: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:28:01,565: Parsing materializations/view/view.sql
2018-07-30 12:28:01,591: Parsing schema_tests/accepted_values.sql
2018-07-30 12:28:01,599: Parsing schema_tests/not_null.sql
2018-07-30 12:28:01,603: Parsing schema_tests/relationships.sql
2018-07-30 12:28:01,608: Parsing schema_tests/unique.sql
2018-07-30 12:28:01,635: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:28:01,637: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:28:01,640: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:28:01,642: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:28:01,645: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:28:01,655: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:28:01,663: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:28:01,669: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:28:01,680: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:28:01,689: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:28:01,696: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:28:01,700: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:28:01,705: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:28:01,711: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:28:01,716: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:28:01,720: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:28:01,731: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:28:01,735: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:28:01,740: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:28:01,747: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:28:01,750: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:28:01,756: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:28:01,779: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:28:01,788: 
2018-07-30 12:28:01,800: Acquiring new bigquery connection "master".
2018-07-30 12:28:01,800: Opening a new connection (0 currently allocated)
2018-07-30 12:28:03,250: 12:28:03 | Concurrency: 4 threads (target='template')
2018-07-30 12:28:03,250: 12:28:03 | 
2018-07-30 12:28:03,387: 12:28:03 | 1 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:28:03,388: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:28:03,388: 12:28:03 | 2 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:28:03,395: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:28:03,400: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:28:03,388: 12:28:03 | 3 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:28:03,410: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:28:03,388: 12:28:03 | 4 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:28:03,411: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:28:03,411: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:28:03,420: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:28:03,429: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:28:03,432: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:28:03,435: Acquiring new bigquery connection "all_dates".
2018-07-30 12:28:03,437: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:28:03,439: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:28:03,439: Opening a new connection (1 currently allocated)
2018-07-30 12:28:03,441: Opening a new connection (2 currently allocated)
2018-07-30 12:28:03,450: Opening a new connection (3 currently allocated)
2018-07-30 12:28:03,453: Opening a new connection (4 currently allocated)
2018-07-30 12:28:03,963: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:28:03,964: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:28:04,014: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:28:04,015: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:28:04,263: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:28:04,264: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:28:04,301: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:28:04,302: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:28:06,520: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088067b8>]}
2018-07-30 12:28:06,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873c438>]}
2018-07-30 12:28:06,986: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873c470>]}
2018-07-30 12:28:07,294: 12:28:07 | 1 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.13s]
2018-07-30 12:28:07,853: 12:28:07 | 2 of 22 OK created table model template.stores_proc.................. [OK in 3.41s]
2018-07-30 12:28:08,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:28:08,168: 12:28:08 | 4 of 22 OK created table model template.monthend_dates............... [OK in 3.57s]
2018-07-30 12:28:08,690: 12:28:08 | 3 of 22 OK created table model template.all_dates.................... [OK in 4.63s]
2018-07-30 12:28:08,691: 12:28:08 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:28:08,691: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:28:08,695: 12:28:08 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:28:08,696: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:28:08,696: 12:28:08 | 7 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:28:08,707: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:28:08,717: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:28:08,729: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:28:08,738: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:28:08,738: Re-using an available connection from the pool.
2018-07-30 12:28:08,738: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:08,741: Re-using an available connection from the pool.
2018-07-30 12:28:08,741: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:08,742: Re-using an available connection from the pool.
2018-07-30 12:28:08,747: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:10,256: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:28:10,281: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:28:10,429: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:28:10,431: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:28:10,432: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:28:10,432: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:28:10,794: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:28:10,957: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:28:10,958: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:28:12,569: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108746748>]}
2018-07-30 12:28:12,824: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108813e10>]}
2018-07-30 12:28:12,872: 12:28:12 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 3.88s]
2018-07-30 12:28:13,198: 12:28:13 | 7 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.12s]
2018-07-30 12:28:14,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108787ba8>]}
2018-07-30 12:28:17,122: 12:28:17 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.16s]
2018-07-30 12:28:17,125: 12:28:17 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:28:17,126: 12:28:17 | 9 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:28:17,126: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:28:17,126: 12:28:17 | 10 of 22 START table model template.agg_customers.................... [RUN]
2018-07-30 12:28:17,126: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:28:17,138: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:28:17,146: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:28:17,161: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:28:17,168: Re-using an available connection from the pool.
2018-07-30 12:28:17,186: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:28:17,186: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:17,187: Re-using an available connection from the pool.
2018-07-30 12:28:17,188: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:17,190: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:28:17,190: Re-using an available connection from the pool.
2018-07-30 12:28:17,478: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:28:17,480: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:28:18,217: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:28:18,379: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:28:18,380: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:28:18,745: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:28:18,950: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:28:18,950: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:28:20,482: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087ed390>]}
2018-07-30 12:28:20,793: 12:28:20 | 9 of 22 OK created table model template.shopify_products_proc........ [OK in 3.36s]
2018-07-30 12:28:22,003: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088061d0>]}
2018-07-30 12:28:22,307: 12:28:22 | 10 of 22 OK created table model template.agg_customers............... [OK in 4.86s]
2018-07-30 12:28:40,828: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:28:41,165: 12:28:41 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 23.70s]
2018-07-30 12:28:41,166: 12:28:41 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:28:41,166: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:28:41,194: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:28:41,194: Re-using an available connection from the pool.
2018-07-30 12:28:41,195: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:41,828: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:28:41,964: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:28:41,965: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:28:52,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108787ba8>]}
2018-07-30 12:28:53,079: 12:28:53 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.27s]
2018-07-30 12:28:53,081: 12:28:53 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:28:53,081: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:28:53,093: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:28:53,096: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:28:53,096: Re-using an available connection from the pool.
2018-07-30 12:28:53,747: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:28:53,750: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:28:58,747: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:28:59,079: 12:28:59 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 5.67s]
2018-07-30 12:28:59,080: 12:28:59 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:28:59,080: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:28:59,090: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:28:59,091: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:28:59,092: Re-using an available connection from the pool.
2018-07-30 12:28:59,592: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:28:59,593: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:29:03,609: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108787ba8>]}
2018-07-30 12:29:05,282: 12:29:05 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.53s]
2018-07-30 12:29:05,286: 12:29:05 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:29:05,286: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:29:05,308: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:29:05,310: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:29:05,311: Re-using an available connection from the pool.
2018-07-30 12:29:05,471: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:29:05,472: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:29:13,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:29:14,748: 12:29:14 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.51s]
2018-07-30 12:29:14,749: 12:29:14 | 15 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:29:14,750: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:29:14,764: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:29:14,755: 12:29:14 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:29:14,756: 12:29:14 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:29:14,765: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:29:14,765: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:29:14,790: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:29:14,798: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:29:14,802: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:29:14,804: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:29:14,807: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:29:14,807: Re-using an available connection from the pool.
2018-07-30 12:29:14,808: Re-using an available connection from the pool.
2018-07-30 12:29:14,812: Re-using an available connection from the pool.
2018-07-30 12:29:15,030: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:29:15,083: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:29:15,085: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:29:15,090: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:29:15,095: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:29:15,103: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:29:20,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873c898>]}
2018-07-30 12:29:20,330: 12:29:20 | 15 of 22 OK created table model template.monthly_cohort_stats........ [OK in 5.28s]
2018-07-30 12:29:27,400: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087b3cf8>]}
2018-07-30 12:29:27,739: 12:29:27 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 12.63s]
2018-07-30 12:29:35,097: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087b3550>]}
2018-07-30 12:29:35,444: 12:29:35 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 20.33s]
2018-07-30 12:29:35,445: 12:29:35 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:29:35,445: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:29:35,457: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:29:35,458: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:29:35,459: Re-using an available connection from the pool.
2018-07-30 12:29:35,627: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:29:35,627: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:30:01,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:30:02,463: 12:30:02 | 18 of 22 OK created table model template.customers_proc.............. [OK in 26.36s]
2018-07-30 12:30:02,464: 12:30:02 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:30:02,465: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:30:02,478: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:30:02,482: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:30:02,482: Re-using an available connection from the pool.
2018-07-30 12:30:02,733: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:30:02,736: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:30:32,230: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108715048>]}
2018-07-30 12:30:33,032: 12:30:33 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.77s]
2018-07-30 12:30:33,032: 12:30:33 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:30:33,033: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:30:33,045: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:30:33,047: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:30:33,047: Re-using an available connection from the pool.
2018-07-30 12:30:33,176: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:30:33,177: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:31:05,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:31:06,220: 12:31:06 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 32.50s]
2018-07-30 12:31:06,221: 12:31:06 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:31:06,222: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:31:06,235: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:31:06,239: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:31:06,239: Re-using an available connection from the pool.
2018-07-30 12:31:06,425: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:31:06,433: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:31:07,657: Bad request while running:
create dataset
2018-07-30 12:31:07,658: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/cd2bed1b-2ddc-47c8-b7f7-008b0039e960?maxResults=0: Unrecognized name: retention_eligible at [22:5]
2018-07-30 12:31:07,658: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10870d1d0>]}
2018-07-30 12:31:08,526: 12:31:08 | 21 of 22 ERROR creating table model template.buyer_segment_stats..... [ERROR in 1.44s]
2018-07-30 12:31:08,527: 12:31:08 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:31:08,528: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:31:08,540: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:31:08,550: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:31:08,550: Re-using an available connection from the pool.
2018-07-30 12:31:09,084: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:31:09,085: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:31:44,059: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:31:46,305: 12:31:46 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 35.53s]
2018-07-30 12:31:46,362: 12:31:46 | 
2018-07-30 12:31:46,362: 12:31:46 | Finished running 22 table models in 224.57s.
2018-07-30 12:31:46,362: Connection 'master' was left open.
2018-07-30 12:31:46,363: 
2018-07-30 12:31:46,364: Completed with 1 errors:
2018-07-30 12:31:46,364: 
2018-07-30 12:31:46,364: Database Error in model buyer_segment_stats (models/math/buyer-segmentation/buyer_segment_stats.sql)
2018-07-30 12:31:46,364:   Unrecognized name: retention_eligible at [22:5]
2018-07-30 12:31:46,365:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/buyer_segment_stats.sql
2018-07-30 12:31:46,365: 
Done. PASS=21 ERROR=1 SKIP=0 TOTAL=22
2018-07-30 12:31:46,367: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085f1080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085f11d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085f1780>]}
2018-07-30 12:31:46,671: Flushing usage events
2018-07-30 12:31:47,236: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50428), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,237: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50426), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,238: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50411), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,238: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50429), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,239: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50434), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,239: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50439), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,240: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50430), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,240: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50431), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,241: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50435), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,241: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50440), raddr=('172.217.3.10', 443)>

2018-07-30 12:34:45,741: Tracking: tracking
2018-07-30 12:34:45,744: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04add8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04ae48>]}
2018-07-30 12:34:47,254: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:34:47,286: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:34:47,296: Parsing get_column_values.sql
2018-07-30 12:34:47,323: Parsing get_url_parameter.sql
2018-07-30 12:34:47,334: Parsing split_part.sql
2018-07-30 12:34:47,342: Parsing table_exists.sql
2018-07-30 12:34:47,356: Parsing core.sql
2018-07-30 12:34:47,370: Parsing adapters/bigquery.sql
2018-07-30 12:34:47,380: Parsing adapters/common.sql
2018-07-30 12:34:47,405: Parsing adapters/redshift.sql
2018-07-30 12:34:47,434: Parsing adapters/snowflake.sql
2018-07-30 12:34:47,441: Parsing etc/bigquery.sql
2018-07-30 12:34:47,447: Parsing etc/datetime.sql
2018-07-30 12:34:47,480: Parsing etc/get_custom_schema.sql
2018-07-30 12:34:47,489: Parsing materializations/helpers.sql
2018-07-30 12:34:47,510: Parsing materializations/archive/archive.sql
2018-07-30 12:34:47,561: Parsing materializations/incremental/incremental.sql
2018-07-30 12:34:47,598: Parsing materializations/seed/bigquery.sql
2018-07-30 12:34:47,606: Parsing materializations/seed/seed.sql
2018-07-30 12:34:47,660: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:34:47,698: Parsing materializations/table/table.sql
2018-07-30 12:34:47,741: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:34:47,765: Parsing materializations/view/view.sql
2018-07-30 12:34:47,786: Parsing schema_tests/accepted_values.sql
2018-07-30 12:34:47,798: Parsing schema_tests/not_null.sql
2018-07-30 12:34:47,802: Parsing schema_tests/relationships.sql
2018-07-30 12:34:47,807: Parsing schema_tests/unique.sql
2018-07-30 12:34:47,843: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:34:47,847: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:34:47,850: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:34:47,852: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:34:47,854: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:34:47,864: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:34:47,872: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:34:47,882: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:34:47,899: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:34:47,913: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:34:47,923: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:34:47,927: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:34:47,931: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:34:47,935: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:34:47,939: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:34:47,945: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:34:47,957: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:34:47,962: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:34:47,971: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:34:47,978: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:34:47,980: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:34:47,986: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:34:48,005: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:34:48,020: 
2018-07-30 12:34:48,119: Acquiring new bigquery connection "master".
2018-07-30 12:34:48,119: Opening a new connection (0 currently allocated)
2018-07-30 12:34:49,521: 12:34:49 | Concurrency: 4 threads (target='template')
2018-07-30 12:34:49,521: 12:34:49 | 
2018-07-30 12:34:49,648: 12:34:49 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:34:49,648: 12:34:49 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:34:49,649: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:34:49,648: 12:34:49 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:34:49,649: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:34:49,648: 12:34:49 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:34:49,659: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:34:49,659: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:34:49,668: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:34:49,668: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:34:49,678: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:34:49,680: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:34:49,696: Opening a new connection (1 currently allocated)
2018-07-30 12:34:49,695: Acquiring new bigquery connection "all_dates".
2018-07-30 12:34:49,696: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:34:49,699: Opening a new connection (2 currently allocated)
2018-07-30 12:34:49,704: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:34:49,710: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:34:49,710: Opening a new connection (3 currently allocated)
2018-07-30 12:34:49,720: Opening a new connection (4 currently allocated)
2018-07-30 12:34:50,129: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:34:50,129: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:34:50,154: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:34:50,155: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:34:50,184: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:34:50,185: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:34:50,202: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:34:50,202: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:34:51,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b264240>]}
2018-07-30 12:34:51,975: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b264358>]}
2018-07-30 12:34:52,139: 12:34:52 | 2 of 22 OK created table model template.all_dates.................... [OK in 2.18s]
2018-07-30 12:34:52,208: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2641d0>]}
2018-07-30 12:34:52,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b207908>]}
2018-07-30 12:34:52,428: 12:34:52 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 2.32s]
2018-07-30 12:34:52,742: 12:34:52 | 4 of 22 OK created table model template.stores_proc.................. [OK in 2.54s]
2018-07-30 12:34:53,049: 12:34:53 | 1 of 22 OK created table model template.monthend_dates............... [OK in 2.76s]
2018-07-30 12:34:53,049: 12:34:53 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:34:53,050: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:34:53,049: 12:34:53 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:34:53,059: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:34:53,050: 12:34:53 | 7 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:34:53,059: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:34:53,059: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:34:53,061: Re-using an available connection from the pool.
2018-07-30 12:34:53,078: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:34:53,079: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:34:53,079: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:34:53,079: Re-using an available connection from the pool.
2018-07-30 12:34:53,080: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:34:53,080: Re-using an available connection from the pool.
2018-07-30 12:34:53,080: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:34:55,260: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:34:55,482: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:34:55,503: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:34:55,552: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:34:55,553: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:34:55,691: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:34:55,691: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:34:55,842: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:34:55,843: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:34:57,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1fae48>]}
2018-07-30 12:34:57,844: 12:34:57 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.50s]
2018-07-30 12:34:58,774: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b264eb8>]}
2018-07-30 12:34:59,936: 12:34:59 | 7 of 22 OK created table model template.shopify_discounts_proc....... [OK in 5.71s]
2018-07-30 12:35:00,759: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:35:02,138: 12:35:02 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 7.70s]
2018-07-30 12:35:02,140: 12:35:02 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:35:02,140: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:35:02,151: 12:35:02 | 9 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:35:02,152: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:35:02,159: 12:35:02 | 10 of 22 START table model template.agg_customers.................... [RUN]
2018-07-30 12:35:02,166: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:35:02,182: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:35:02,195: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:35:02,205: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:35:02,206: Re-using an available connection from the pool.
2018-07-30 12:35:02,206: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:35:02,206: Re-using an available connection from the pool.
2018-07-30 12:35:02,207: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:35:02,210: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:35:02,212: Re-using an available connection from the pool.
2018-07-30 12:35:02,362: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:35:02,365: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:35:02,974: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:35:03,098: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:35:03,099: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:35:04,138: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:35:04,313: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:35:04,317: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:35:05,862: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2ad6d8>]}
2018-07-30 12:35:06,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b247ef0>]}
2018-07-30 12:35:07,337: 12:35:07 | 9 of 22 OK created table model template.shopify_products_proc........ [OK in 3.71s]
2018-07-30 12:35:07,635: 12:35:07 | 10 of 22 OK created table model template.agg_customers............... [OK in 4.36s]
2018-07-30 12:35:31,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:35:31,875: 12:35:31 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 29.40s]
2018-07-30 12:35:31,876: 12:35:31 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:35:31,876: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:35:31,905: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:35:31,905: Re-using an available connection from the pool.
2018-07-30 12:35:31,906: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:35:33,613: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:35:33,841: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:35:33,841: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:35:43,378: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:35:44,133: 12:35:44 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.50s]
2018-07-30 12:35:44,134: 12:35:44 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:35:44,135: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:35:44,143: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:35:44,146: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:35:44,146: Re-using an available connection from the pool.
2018-07-30 12:35:44,330: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:35:44,331: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:35:48,914: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:35:49,750: 12:35:49 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.78s]
2018-07-30 12:35:49,753: 12:35:49 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:35:49,753: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:35:49,761: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:35:49,769: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:35:49,769: Re-using an available connection from the pool.
2018-07-30 12:35:49,895: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:35:49,896: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:35:53,705: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:35:54,159: 12:35:54 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 3.95s]
2018-07-30 12:35:54,160: 12:35:54 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:35:54,160: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:35:54,171: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:35:54,176: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:35:54,176: Re-using an available connection from the pool.
2018-07-30 12:35:54,302: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:35:54,303: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:36:03,089: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:36:04,627: 12:36:04 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.93s]
2018-07-30 12:36:04,628: 12:36:04 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:36:04,628: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:36:04,628: 12:36:04 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:36:04,628: 12:36:04 | 17 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:36:04,644: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:36:04,643: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:36:04,643: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:36:04,662: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:36:04,669: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:36:04,677: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:36:04,677: Re-using an available connection from the pool.
2018-07-30 12:36:04,682: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:36:04,682: Re-using an available connection from the pool.
2018-07-30 12:36:04,704: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:36:04,705: Re-using an available connection from the pool.
2018-07-30 12:36:04,873: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:36:04,891: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:36:04,892: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:36:04,900: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:36:04,904: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:36:04,910: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:36:09,518: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b29b400>]}
2018-07-30 12:36:10,144: 12:36:10 | 17 of 22 OK created table model template.monthly_cohort_stats........ [OK in 4.87s]
2018-07-30 12:36:17,758: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e93160>]}
2018-07-30 12:36:18,055: 12:36:18 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.11s]
2018-07-30 12:36:31,158: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:36:31,808: 12:36:31 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 26.53s]
2018-07-30 12:36:31,809: 12:36:31 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:36:31,810: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:36:31,834: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:36:31,839: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:36:31,839: Re-using an available connection from the pool.
2018-07-30 12:36:31,993: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:36:31,994: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:36:58,546: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:37:00,228: 12:37:00 | 18 of 22 OK created table model template.customers_proc.............. [OK in 26.73s]
2018-07-30 12:37:00,229: 12:37:00 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:37:00,230: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:37:00,265: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:37:00,267: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:37:00,267: Re-using an available connection from the pool.
2018-07-30 12:37:00,405: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:37:00,406: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:37:29,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:37:29,583: 12:37:29 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.01s]
2018-07-30 12:37:29,585: 12:37:29 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:37:29,585: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:37:29,617: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:37:29,621: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:37:29,621: Re-using an available connection from the pool.
2018-07-30 12:37:29,774: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:37:29,775: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:37:56,130: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:37:56,546: 12:37:56 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 26.54s]
2018-07-30 12:37:56,548: 12:37:56 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:37:56,548: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:37:56,589: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:37:56,593: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:37:56,594: Re-using an available connection from the pool.
2018-07-30 12:37:56,735: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:37:56,736: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:37:59,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:38:01,086: 12:38:01 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 3.21s]
2018-07-30 12:38:01,087: 12:38:01 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:38:01,087: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:38:01,095: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:38:01,097: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:38:01,097: Re-using an available connection from the pool.
2018-07-30 12:38:01,280: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:38:01,282: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:38:31,023: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:38:31,643: 12:38:31 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 29.93s]
2018-07-30 12:38:31,708: 12:38:31 | 
2018-07-30 12:38:31,709: 12:38:31 | Finished running 22 table models in 223.69s.
2018-07-30 12:38:31,710: Connection 'master' was left open.
2018-07-30 12:38:31,711: 
2018-07-30 12:38:31,711: Completed successfully
2018-07-30 12:38:31,712: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 12:38:31,713: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b14a048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b272588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b272ba8>]}
2018-07-30 12:38:32,029: Flushing usage events
2018-07-30 12:38:32,448: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51378), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,450: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51379), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,450: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51376), raddr=('172.217.1.74', 443)>

2018-07-30 12:38:32,451: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51371), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,452: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51380), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,452: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51381), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,452: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51388), raddr=('172.217.12.10', 443)>

2018-07-30 12:38:32,453: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51389), raddr=('172.217.12.10', 443)>

2018-07-30 12:38:32,453: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51385), raddr=('172.217.12.10', 443)>

2018-07-30 12:38:32,453: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51387), raddr=('172.217.12.10', 443)>

2018-07-30 12:42:40,316: Tracking: tracking
2018-07-30 12:42:40,318: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105295e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052952b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105295ef0>]}
2018-07-30 12:42:41,251: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:42:41,294: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:42:41,301: Parsing get_column_values.sql
2018-07-30 12:42:41,320: Parsing get_url_parameter.sql
2018-07-30 12:42:41,329: Parsing split_part.sql
2018-07-30 12:42:41,341: Parsing table_exists.sql
2018-07-30 12:42:41,354: Parsing core.sql
2018-07-30 12:42:41,371: Parsing adapters/bigquery.sql
2018-07-30 12:42:41,382: Parsing adapters/common.sql
2018-07-30 12:42:41,407: Parsing adapters/redshift.sql
2018-07-30 12:42:41,428: Parsing adapters/snowflake.sql
2018-07-30 12:42:41,434: Parsing etc/bigquery.sql
2018-07-30 12:42:41,439: Parsing etc/datetime.sql
2018-07-30 12:42:41,468: Parsing etc/get_custom_schema.sql
2018-07-30 12:42:41,482: Parsing materializations/helpers.sql
2018-07-30 12:42:41,509: Parsing materializations/archive/archive.sql
2018-07-30 12:42:41,549: Parsing materializations/incremental/incremental.sql
2018-07-30 12:42:41,589: Parsing materializations/seed/bigquery.sql
2018-07-30 12:42:41,597: Parsing materializations/seed/seed.sql
2018-07-30 12:42:41,648: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:42:41,682: Parsing materializations/table/table.sql
2018-07-30 12:42:41,717: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:42:41,733: Parsing materializations/view/view.sql
2018-07-30 12:42:41,759: Parsing schema_tests/accepted_values.sql
2018-07-30 12:42:41,768: Parsing schema_tests/not_null.sql
2018-07-30 12:42:41,774: Parsing schema_tests/relationships.sql
2018-07-30 12:42:41,782: Parsing schema_tests/unique.sql
2018-07-30 12:42:41,812: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:42:41,815: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:42:41,818: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:42:41,820: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:42:41,823: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:42:41,833: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:42:41,841: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:42:41,849: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:42:41,858: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:42:41,867: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:42:41,873: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:42:41,875: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:42:41,879: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:42:41,882: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:42:41,885: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:42:41,888: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:42:41,896: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:42:41,900: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:42:41,904: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:42:41,909: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:42:41,913: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:42:41,920: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:42:41,941: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:42:41,949: 
2018-07-30 12:42:41,955: Acquiring new bigquery connection "master".
2018-07-30 12:42:41,956: Opening a new connection (0 currently allocated)
2018-07-30 12:42:45,675: 12:42:45 | Concurrency: 4 threads (target='template')
2018-07-30 12:42:45,676: 12:42:45 | 
2018-07-30 12:42:45,743: 12:42:45 | 1 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:42:45,744: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:42:45,749: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:42:45,744: 12:42:45 | 2 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:42:45,750: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:42:45,755: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:42:45,744: 12:42:45 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:42:45,756: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:42:45,744: 12:42:45 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:42:45,762: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:42:45,762: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:42:45,764: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:42:45,769: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:42:45,771: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:42:45,772: Acquiring new bigquery connection "all_dates".
2018-07-30 12:42:45,772: Opening a new connection (1 currently allocated)
2018-07-30 12:42:45,778: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:42:45,780: Opening a new connection (2 currently allocated)
2018-07-30 12:42:45,783: Opening a new connection (3 currently allocated)
2018-07-30 12:42:45,793: Opening a new connection (4 currently allocated)
2018-07-30 12:42:46,985: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:42:47,017: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:42:47,018: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:42:47,018: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:42:47,036: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:42:47,037: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:42:47,046: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:42:47,055: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:42:48,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d95f8>]}
2018-07-30 12:42:48,815: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c14a8>]}
2018-07-30 12:42:48,817: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105425470>]}
2018-07-30 12:42:49,021: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054251d0>]}
2018-07-30 12:42:49,150: 12:42:49 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.05s]
2018-07-30 12:42:49,448: 12:42:49 | 2 of 22 OK created table model template.monthend_dates............... [OK in 3.07s]
2018-07-30 12:42:49,750: 12:42:49 | 1 of 22 OK created table model template.all_dates.................... [OK in 3.07s]
2018-07-30 12:42:50,056: 12:42:50 | 4 of 22 OK created table model template.stores_proc.................. [OK in 3.26s]
2018-07-30 12:42:50,057: 12:42:50 | 5 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:42:50,057: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:42:50,057: 12:42:50 | 6 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:42:50,063: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:42:50,057: 12:42:50 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:42:50,078: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:42:50,078: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:42:50,084: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:42:50,092: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:42:50,092: Re-using an available connection from the pool.
2018-07-30 12:42:50,092: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:50,093: Re-using an available connection from the pool.
2018-07-30 12:42:50,093: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:50,093: Re-using an available connection from the pool.
2018-07-30 12:42:50,096: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:51,542: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:42:51,670: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:42:51,680: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:42:51,686: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:42:51,713: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:42:51,828: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:42:51,829: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:42:51,884: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:42:51,884: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:42:53,999: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054251d0>]}
2018-07-30 12:42:54,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c14a8>]}
2018-07-30 12:42:54,659: 12:42:54 | 6 of 22 OK created table model template.shopify_refunds_proc......... [OK in 3.94s]
2018-07-30 12:42:55,305: 12:42:55 | 5 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.29s]
2018-07-30 12:42:56,437: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:42:56,726: 12:42:56 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.36s]
2018-07-30 12:42:56,727: 12:42:56 | 8 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:42:56,727: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:42:56,727: 12:42:56 | 9 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:42:56,727: 12:42:56 | 10 of 22 START table model template.agg_customers.................... [RUN]
2018-07-30 12:42:56,730: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:42:56,737: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:42:56,744: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:42:56,763: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:42:56,764: Re-using an available connection from the pool.
2018-07-30 12:42:56,767: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:42:56,767: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:56,768: Re-using an available connection from the pool.
2018-07-30 12:42:56,770: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:42:56,772: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:56,774: Re-using an available connection from the pool.
2018-07-30 12:42:56,933: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:42:56,936: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:42:57,620: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:42:57,750: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:42:57,750: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:42:58,346: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:42:58,486: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:42:58,490: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:42:59,967: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105395e48>]}
2018-07-30 12:43:00,265: 12:43:00 | 8 of 22 OK created table model template.shopify_products_proc........ [OK in 3.24s]
2018-07-30 12:43:01,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f5240>]}
2018-07-30 12:43:01,544: 12:43:01 | 10 of 22 OK created table model template.agg_customers............... [OK in 4.50s]
2018-07-30 12:43:26,600: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f8748>]}
2018-07-30 12:43:26,932: 12:43:26 | 9 of 22 OK created table model template.ga_transactions.............. [OK in 29.87s]
2018-07-30 12:43:26,932: 12:43:26 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:43:26,932: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:43:26,943: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:43:26,943: Re-using an available connection from the pool.
2018-07-30 12:43:26,944: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:43:27,726: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:43:27,844: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:43:27,845: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:43:41,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:43:45,661: 12:43:45 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 14.26s]
2018-07-30 12:43:45,664: 12:43:45 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:43:45,665: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:43:45,675: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:43:45,677: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:43:45,677: Re-using an available connection from the pool.
2018-07-30 12:43:45,869: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:43:45,870: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:43:51,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053fe4a8>]}
2018-07-30 12:43:54,443: 12:43:54 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 6.16s]
2018-07-30 12:43:54,448: 12:43:54 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:43:54,449: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:43:54,455: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:43:54,465: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:43:54,465: Re-using an available connection from the pool.
2018-07-30 12:43:54,670: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:43:54,670: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:43:59,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:44:02,803: 12:44:02 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.93s]
2018-07-30 12:44:02,806: 12:44:02 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:44:02,806: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:44:02,820: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:44:02,825: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:44:02,825: Re-using an available connection from the pool.
2018-07-30 12:44:03,579: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:44:03,580: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:44:11,954: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053616a0>]}
2018-07-30 12:44:12,819: 12:44:12 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.15s]
2018-07-30 12:44:12,820: 12:44:12 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:44:12,821: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:44:12,820: 12:44:12 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:44:12,831: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:44:12,820: 12:44:12 | 17 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:44:12,831: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:44:12,831: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:44:12,841: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:44:12,854: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:44:12,854: Re-using an available connection from the pool.
2018-07-30 12:44:12,849: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:44:12,861: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:44:12,861: Re-using an available connection from the pool.
2018-07-30 12:44:12,868: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:44:12,870: Re-using an available connection from the pool.
2018-07-30 12:44:13,157: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:44:13,157: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:44:13,221: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:44:13,231: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:44:13,231: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:44:13,231: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:44:18,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105472358>]}
2018-07-30 12:44:20,604: 12:44:20 | 17 of 22 OK created table model template.monthly_cohort_stats........ [OK in 5.60s]
2018-07-30 12:44:26,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054e5a20>]}
2018-07-30 12:44:31,879: 12:44:31 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.99s]
2018-07-30 12:44:33,951: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:44:34,345: 12:44:34 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 21.13s]
2018-07-30 12:44:34,346: 12:44:34 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:44:34,346: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:44:34,359: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:44:34,362: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:44:34,362: Re-using an available connection from the pool.
2018-07-30 12:44:34,557: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:44:34,558: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:45:02,126: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053616a0>]}
2018-07-30 12:45:04,702: 12:45:04 | 18 of 22 OK created table model template.customers_proc.............. [OK in 27.78s]
2018-07-30 12:45:04,702: 12:45:04 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:45:04,702: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:45:04,712: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:45:04,714: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:45:04,714: Re-using an available connection from the pool.
2018-07-30 12:45:05,131: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:45:05,131: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:45:34,118: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:45:34,494: 12:45:34 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.42s]
2018-07-30 12:45:34,495: 12:45:34 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:45:34,495: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:45:34,505: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:45:34,509: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:45:34,510: Re-using an available connection from the pool.
2018-07-30 12:45:36,545: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:45:36,546: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:46:06,681: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053feb00>]}
2018-07-30 12:46:07,588: 12:46:07 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 32.19s]
2018-07-30 12:46:07,589: 12:46:07 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:46:07,589: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:46:07,612: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:46:07,615: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:46:07,615: Re-using an available connection from the pool.
2018-07-30 12:46:08,128: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:46:08,129: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:46:09,943: Bad request while running:
create dataset
2018-07-30 12:46:09,943: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/ba5b92ff-2086-405c-b977-ce6820e7a8e5?maxResults=0: Unrecognized name: retention_elibible; Did you mean retention_eligible? at [22:15]
2018-07-30 12:46:09,944: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102810208>]}
2018-07-30 12:46:10,247: 12:46:10 | 21 of 22 ERROR creating table model template.buyer_segment_stats..... [ERROR in 2.36s]
2018-07-30 12:46:10,248: 12:46:10 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:46:10,249: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:46:10,257: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:46:10,260: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:46:10,260: Re-using an available connection from the pool.
2018-07-30 12:46:10,824: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:46:10,825: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:46:45,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105395e48>]}
2018-07-30 12:46:46,572: 12:46:46 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 35.55s]
2018-07-30 12:46:46,625: 12:46:46 | 
2018-07-30 12:46:46,626: 12:46:46 | Finished running 22 table models in 244.68s.
2018-07-30 12:46:46,626: Connection 'master' was left open.
2018-07-30 12:46:46,626: 
2018-07-30 12:46:46,626: Completed with 1 errors:
2018-07-30 12:46:46,627: 
2018-07-30 12:46:46,627: Database Error in model buyer_segment_stats (models/math/buyer-segmentation/buyer_segment_stats.sql)
2018-07-30 12:46:46,627:   Unrecognized name: retention_elibible; Did you mean retention_eligible? at [22:15]
2018-07-30 12:46:46,627:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/buyer_segment_stats.sql
2018-07-30 12:46:46,627: 
Done. PASS=21 ERROR=1 SKIP=0 TOTAL=22
2018-07-30 12:46:46,628: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054256d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054be1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054be240>]}
2018-07-30 12:46:48,168: Flushing usage events
2018-07-30 12:46:48,445: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52079), raddr=('172.217.11.234', 443)>

2018-07-30 12:46:48,446: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52078), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,446: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52081), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,446: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52080), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52082), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52083), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52088), raddr=('172.217.12.10', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52087), raddr=('172.217.12.10', 443)>

2018-07-30 12:46:48,448: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52085), raddr=('172.217.12.10', 443)>

2018-07-30 12:46:48,448: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52086), raddr=('172.217.12.10', 443)>

2018-07-30 12:48:54,633: Tracking: tracking
2018-07-30 12:48:54,635: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff1b358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff1bb38>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff1bcf8>]}
2018-07-30 12:48:56,819: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:48:56,879: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:48:56,887: Parsing get_column_values.sql
2018-07-30 12:48:56,915: Parsing get_url_parameter.sql
2018-07-30 12:48:56,921: Parsing split_part.sql
2018-07-30 12:48:56,928: Parsing table_exists.sql
2018-07-30 12:48:56,945: Parsing core.sql
2018-07-30 12:48:56,971: Parsing adapters/bigquery.sql
2018-07-30 12:48:56,984: Parsing adapters/common.sql
2018-07-30 12:48:57,034: Parsing adapters/redshift.sql
2018-07-30 12:48:57,074: Parsing adapters/snowflake.sql
2018-07-30 12:48:57,082: Parsing etc/bigquery.sql
2018-07-30 12:48:57,088: Parsing etc/datetime.sql
2018-07-30 12:48:57,132: Parsing etc/get_custom_schema.sql
2018-07-30 12:48:57,156: Parsing materializations/helpers.sql
2018-07-30 12:48:57,194: Parsing materializations/archive/archive.sql
2018-07-30 12:48:57,272: Parsing materializations/incremental/incremental.sql
2018-07-30 12:48:57,350: Parsing materializations/seed/bigquery.sql
2018-07-30 12:48:57,366: Parsing materializations/seed/seed.sql
2018-07-30 12:48:57,444: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:48:57,493: Parsing materializations/table/table.sql
2018-07-30 12:48:57,549: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:48:57,574: Parsing materializations/view/view.sql
2018-07-30 12:48:57,598: Parsing schema_tests/accepted_values.sql
2018-07-30 12:48:57,605: Parsing schema_tests/not_null.sql
2018-07-30 12:48:57,609: Parsing schema_tests/relationships.sql
2018-07-30 12:48:57,614: Parsing schema_tests/unique.sql
2018-07-30 12:48:57,636: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:48:57,639: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:48:57,642: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:48:57,646: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:48:57,649: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:48:57,662: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:48:57,673: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:48:57,683: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:48:57,698: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:48:57,712: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:48:57,721: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:48:57,724: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:48:57,729: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:48:57,733: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:48:57,736: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:48:57,740: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:48:57,748: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:48:57,753: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:48:57,757: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:48:57,763: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:48:57,767: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:48:57,773: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:48:57,794: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:48:57,802: 
2018-07-30 12:48:57,821: Acquiring new bigquery connection "master".
2018-07-30 12:48:57,822: Opening a new connection (0 currently allocated)
2018-07-30 12:48:59,142: 12:48:59 | Concurrency: 4 threads (target='template')
2018-07-30 12:48:59,142: 12:48:59 | 
2018-07-30 12:48:59,299: 12:48:59 | 1 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:48:59,299: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:48:59,311: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:48:59,306: 12:48:59 | 2 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:48:59,311: 12:48:59 | 3 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:48:59,314: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:48:59,312: 12:48:59 | 4 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:48:59,328: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:48:59,312: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:48:59,346: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:48:59,347: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:48:59,358: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:48:59,361: Acquiring new bigquery connection "all_dates".
2018-07-30 12:48:59,363: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:48:59,364: Opening a new connection (1 currently allocated)
2018-07-30 12:48:59,368: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:48:59,376: Opening a new connection (2 currently allocated)
2018-07-30 12:48:59,378: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:48:59,383: Opening a new connection (3 currently allocated)
2018-07-30 12:48:59,385: Opening a new connection (4 currently allocated)
2018-07-30 12:48:59,812: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:48:59,813: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:48:59,846: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:48:59,846: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:48:59,864: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:48:59,865: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:48:59,892: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:48:59,892: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:49:01,227: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3240>]}
2018-07-30 12:49:01,522: 12:49:01 | 1 of 22 OK created table model template.all_dates.................... [OK in 1.93s]
2018-07-30 12:49:01,555: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110059ef0>]}
2018-07-30 12:49:01,746: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b2f98>]}
2018-07-30 12:49:01,816: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110016b38>]}
2018-07-30 12:49:01,850: 12:49:01 | 3 of 22 OK created table model template.monthend_dates............... [OK in 2.24s]
2018-07-30 12:49:02,141: 12:49:02 | 2 of 22 OK created table model template.stores_proc.................. [OK in 2.43s]
2018-07-30 12:49:02,434: 12:49:02 | 4 of 22 OK created table model template.mappings_ga_proc............. [OK in 2.49s]
2018-07-30 12:49:02,435: 12:49:02 | 5 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:49:02,435: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:49:02,435: 12:49:02 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:49:02,435: 12:49:02 | 7 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:49:02,437: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:49:02,444: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:49:02,446: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:49:02,463: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:49:02,466: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:49:02,466: Re-using an available connection from the pool.
2018-07-30 12:49:02,466: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:02,467: Re-using an available connection from the pool.
2018-07-30 12:49:02,467: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:02,467: Re-using an available connection from the pool.
2018-07-30 12:49:02,469: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:04,273: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:49:04,274: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:49:04,551: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:49:04,568: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:49:04,570: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:49:04,575: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:49:04,868: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:49:05,044: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:49:05,050: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:49:06,639: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0b3400>]}
2018-07-30 12:49:06,954: 12:49:06 | 7 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.20s]
2018-07-30 12:49:07,170: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b2128>]}
2018-07-30 12:49:07,483: 12:49:07 | 5 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.73s]
2018-07-30 12:49:09,328: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:49:09,622: 12:49:09 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.89s]
2018-07-30 12:49:09,623: 12:49:09 | 8 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:49:09,624: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:49:09,623: 12:49:09 | 9 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 12:49:09,623: 12:49:09 | 10 of 22 START table model template.ga_transactions.................. [RUN]
2018-07-30 12:49:09,637: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:49:09,637: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:49:09,637: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:49:09,638: Re-using an available connection from the pool.
2018-07-30 12:49:09,657: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:09,643: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:49:09,662: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:49:09,663: Re-using an available connection from the pool.
2018-07-30 12:49:09,669: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:49:09,669: Re-using an available connection from the pool.
2018-07-30 12:49:09,669: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:09,821: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:49:09,824: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:49:10,432: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:49:10,558: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:49:10,559: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:49:11,199: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:49:11,328: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:49:11,329: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:49:12,922: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110016b38>]}
2018-07-30 12:49:13,585: 12:49:13 | 8 of 22 OK created table model template.shopify_products_proc........ [OK in 3.30s]
2018-07-30 12:49:13,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018ae48>]}
2018-07-30 12:49:14,543: 12:49:14 | 9 of 22 OK created table model template.agg_customers................ [OK in 4.24s]
2018-07-30 12:49:34,518: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3c88>]}
2018-07-30 12:49:34,913: 12:49:34 | 10 of 22 OK created table model template.ga_transactions............. [OK in 24.88s]
2018-07-30 12:49:34,914: 12:49:34 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:49:34,915: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:49:34,942: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:49:34,943: Re-using an available connection from the pool.
2018-07-30 12:49:34,943: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:35,901: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:49:36,034: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:49:36,035: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:49:44,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:49:45,215: 12:49:45 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 9.82s]
2018-07-30 12:49:45,217: 12:49:45 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:49:45,218: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:49:45,234: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:49:45,237: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:49:45,238: Re-using an available connection from the pool.
2018-07-30 12:49:45,791: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:49:45,792: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:49:50,117: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3c88>]}
2018-07-30 12:49:50,434: 12:49:50 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.90s]
2018-07-30 12:49:50,435: 12:49:50 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:49:50,435: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:49:50,448: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:49:50,455: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:49:50,455: Re-using an available connection from the pool.
2018-07-30 12:49:50,699: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:49:50,700: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:49:54,414: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:49:54,726: 12:49:54 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 3.98s]
2018-07-30 12:49:54,727: 12:49:54 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:49:54,727: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:49:54,747: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:49:54,750: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:49:54,750: Re-using an available connection from the pool.
2018-07-30 12:49:54,891: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:49:54,892: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:50:03,774: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007e550>]}
2018-07-30 12:50:04,602: 12:50:04 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.05s]
2018-07-30 12:50:04,603: 12:50:04 | 15 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:50:04,603: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:50:04,603: 12:50:04 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:50:04,603: 12:50:04 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:50:04,611: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:50:04,611: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:50:04,611: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:50:04,628: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:50:04,630: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:50:04,634: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:50:04,635: Re-using an available connection from the pool.
2018-07-30 12:50:04,641: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:50:04,644: Re-using an available connection from the pool.
2018-07-30 12:50:04,644: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:50:04,648: Re-using an available connection from the pool.
2018-07-30 12:50:04,765: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:50:04,783: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:50:04,796: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:50:04,801: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:50:04,802: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:50:04,805: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:50:11,029: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:50:11,681: 12:50:11 | 15 of 22 OK created table model template.monthly_cohort_stats........ [OK in 6.43s]
2018-07-30 12:50:15,689: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc9e390>]}
2018-07-30 12:50:16,175: 12:50:16 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 11.08s]
2018-07-30 12:50:29,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110083898>]}
2018-07-30 12:50:31,154: 12:50:31 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 25.09s]
2018-07-30 12:50:31,160: 12:50:31 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:50:31,161: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:50:31,185: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:50:31,194: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:50:31,194: Re-using an available connection from the pool.
2018-07-30 12:50:31,943: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:50:31,944: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:51:01,450: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110140f60>]}
2018-07-30 12:51:01,893: 12:51:01 | 18 of 22 OK created table model template.customers_proc.............. [OK in 30.29s]
2018-07-30 12:51:01,896: 12:51:01 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:51:01,896: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:51:01,918: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:51:01,926: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:51:01,926: Re-using an available connection from the pool.
2018-07-30 12:51:02,114: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:51:02,115: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:51:31,245: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018a668>]}
2018-07-30 12:51:32,112: 12:51:32 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.35s]
2018-07-30 12:51:32,114: 12:51:32 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:51:32,114: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:51:32,134: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:51:32,136: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:51:32,137: Re-using an available connection from the pool.
2018-07-30 12:51:32,279: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:51:32,280: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:51:58,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe7160>]}
2018-07-30 12:51:58,820: 12:51:58 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 26.32s]
2018-07-30 12:51:58,822: 12:51:58 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:51:58,822: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:51:58,850: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:51:58,863: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:51:58,863: Re-using an available connection from the pool.
2018-07-30 12:51:59,064: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:51:59,066: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:52:02,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018a668>]}
2018-07-30 12:52:02,474: 12:52:02 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 3.36s]
2018-07-30 12:52:02,475: 12:52:02 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:52:02,475: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:52:02,488: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:52:02,492: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:52:02,492: Re-using an available connection from the pool.
2018-07-30 12:52:02,631: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:52:02,632: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:52:35,672: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe7160>]}
2018-07-30 12:52:37,111: 12:52:37 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 33.20s]
2018-07-30 12:52:37,258: 12:52:37 | 
2018-07-30 12:52:37,258: 12:52:37 | Finished running 22 table models in 219.45s.
2018-07-30 12:52:37,259: Connection 'master' was left open.
2018-07-30 12:52:37,278: 
2018-07-30 12:52:37,282: Completed successfully
2018-07-30 12:52:37,282: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 12:52:37,301: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11001e518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b30b8>]}
2018-07-30 12:52:37,645: Flushing usage events
2018-07-30 12:52:38,147: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52530), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,148: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52529), raddr=('172.217.11.234', 443)>

2018-07-30 12:52:38,148: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52526), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,149: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52531), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,149: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52537), raddr=('172.217.12.10', 443)>

2018-07-30 12:52:38,150: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52535), raddr=('172.217.12.10', 443)>

2018-07-30 12:52:38,152: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52532), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,153: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52533), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,153: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52534), raddr=('172.217.12.10', 443)>

2018-07-30 12:52:38,160: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52536), raddr=('172.217.12.10', 443)>

2018-07-30 13:36:33,354: Tracking: tracking
2018-07-30 13:36:33,357: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ed0320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ed0f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ed0278>]}
2018-07-30 13:36:35,078: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 13:36:35,114: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 13:36:35,121: Parsing get_column_values.sql
2018-07-30 13:36:35,138: Parsing get_url_parameter.sql
2018-07-30 13:36:35,146: Parsing split_part.sql
2018-07-30 13:36:35,154: Parsing table_exists.sql
2018-07-30 13:36:35,167: Parsing core.sql
2018-07-30 13:36:35,191: Parsing adapters/bigquery.sql
2018-07-30 13:36:35,203: Parsing adapters/common.sql
2018-07-30 13:36:35,238: Parsing adapters/redshift.sql
2018-07-30 13:36:35,285: Parsing adapters/snowflake.sql
2018-07-30 13:36:35,292: Parsing etc/bigquery.sql
2018-07-30 13:36:35,297: Parsing etc/datetime.sql
2018-07-30 13:36:35,349: Parsing etc/get_custom_schema.sql
2018-07-30 13:36:35,360: Parsing materializations/helpers.sql
2018-07-30 13:36:35,391: Parsing materializations/archive/archive.sql
2018-07-30 13:36:35,462: Parsing materializations/incremental/incremental.sql
2018-07-30 13:36:35,519: Parsing materializations/seed/bigquery.sql
2018-07-30 13:36:35,528: Parsing materializations/seed/seed.sql
2018-07-30 13:36:35,588: Parsing materializations/table/bigquery_table.sql
2018-07-30 13:36:35,625: Parsing materializations/table/table.sql
2018-07-30 13:36:35,658: Parsing materializations/view/bigquery_view.sql
2018-07-30 13:36:35,677: Parsing materializations/view/view.sql
2018-07-30 13:36:35,707: Parsing schema_tests/accepted_values.sql
2018-07-30 13:36:35,714: Parsing schema_tests/not_null.sql
2018-07-30 13:36:35,719: Parsing schema_tests/relationships.sql
2018-07-30 13:36:35,724: Parsing schema_tests/unique.sql
2018-07-30 13:36:35,756: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 13:36:35,760: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:36:35,762: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:36:35,766: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 13:36:35,770: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:36:35,781: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:36:35,790: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:36:35,798: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:36:35,809: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:36:35,818: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:36:35,826: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 13:36:35,829: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:36:35,833: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:36:35,836: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:36:35,839: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 13:36:35,844: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 13:36:35,852: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 13:36:35,857: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:36:35,862: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:36:35,867: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:36:35,871: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:36:35,879: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:36:35,899: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 13:36:35,905: 
2018-07-30 13:36:35,919: Acquiring new bigquery connection "master".
2018-07-30 13:36:35,920: Opening a new connection (0 currently allocated)
2018-07-30 13:36:37,321: 13:36:37 | Concurrency: 4 threads (target='template')
2018-07-30 13:36:37,322: 13:36:37 | 
2018-07-30 13:36:37,462: 13:36:37 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 13:36:37,463: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:36:37,462: 13:36:37 | 2 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 13:36:37,462: 13:36:37 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 13:36:37,469: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 13:36:37,473: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:36:37,463: 13:36:37 | 4 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 13:36:37,475: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:36:37,482: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:36:37,482: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 13:36:37,489: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:36:37,491: Acquiring new bigquery connection "monthend_dates".
2018-07-30 13:36:37,503: Opening a new connection (1 currently allocated)
2018-07-30 13:36:37,503: Acquiring new bigquery connection "stores_proc".
2018-07-30 13:36:37,500: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:36:37,506: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 13:36:37,509: Opening a new connection (2 currently allocated)
2018-07-30 13:36:37,512: Acquiring new bigquery connection "all_dates".
2018-07-30 13:36:37,518: Opening a new connection (3 currently allocated)
2018-07-30 13:36:37,522: Opening a new connection (4 currently allocated)
2018-07-30 13:36:37,987: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:36:37,995: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 13:36:38,011: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:36:38,012: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 13:36:38,063: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:36:38,064: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 13:36:38,068: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:36:38,070: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 13:36:39,719: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205d400>]}
2018-07-30 13:36:39,731: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205d4a8>]}
2018-07-30 13:36:39,746: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205d240>]}
2018-07-30 13:36:39,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112016470>]}
2018-07-30 13:36:40,007: 13:36:40 | 1 of 22 OK created table model template.monthend_dates............... [OK in 2.26s]
2018-07-30 13:36:40,289: 13:36:40 | 2 of 22 OK created table model template.stores_proc.................. [OK in 2.26s]
2018-07-30 13:36:40,583: 13:36:40 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 2.27s]
2018-07-30 13:36:40,878: 13:36:40 | 4 of 22 OK created table model template.all_dates.................... [OK in 2.27s]
2018-07-30 13:36:40,879: 13:36:40 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 13:36:40,879: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:36:40,879: 13:36:40 | 6 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 13:36:40,885: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:36:40,899: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 13:36:40,885: 13:36:40 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 13:36:40,901: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 13:36:40,901: Re-using an available connection from the pool.
2018-07-30 13:36:40,901: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:36:40,901: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:40,901: Re-using an available connection from the pool.
2018-07-30 13:36:40,911: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 13:36:40,911: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:40,911: Re-using an available connection from the pool.
2018-07-30 13:36:40,913: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:42,465: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:36:42,605: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:36:42,771: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:36:42,940: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:36:42,941: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:36:42,943: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:36:42,946: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 13:36:43,063: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:36:43,063: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 13:36:45,099: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112016160>]}
2018-07-30 13:36:45,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112160ef0>]}
2018-07-30 13:36:45,410: 13:36:45 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.22s]
2018-07-30 13:36:45,795: 13:36:45 | 6 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.30s]
2018-07-30 13:36:48,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112035860>]}
2018-07-30 13:36:48,880: 13:36:48 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 7.44s]
2018-07-30 13:36:48,881: 13:36:48 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 13:36:48,881: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:36:48,881: 13:36:48 | 9 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 13:36:48,881: 13:36:48 | 10 of 22 START table model template.shopify_products_proc............ [RUN]
2018-07-30 13:36:48,883: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 13:36:48,897: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:36:48,902: Acquiring new bigquery connection "ga_transactions".
2018-07-30 13:36:48,912: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:36:48,930: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 13:36:48,932: Acquiring new bigquery connection "agg_customers".
2018-07-30 13:36:48,933: Re-using an available connection from the pool.
2018-07-30 13:36:48,933: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:48,933: Re-using an available connection from the pool.
2018-07-30 13:36:48,934: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:48,934: Re-using an available connection from the pool.
2018-07-30 13:36:49,073: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:36:49,077: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 13:36:49,619: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:36:49,770: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:36:49,771: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 13:36:50,522: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:36:50,685: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:36:50,685: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 13:36:52,036: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120adac8>]}
2018-07-30 13:36:52,820: 13:36:52 | 10 of 22 OK created table model template.shopify_products_proc....... [OK in 3.14s]
2018-07-30 13:36:54,105: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112181d30>]}
2018-07-30 13:36:54,404: 13:36:54 | 9 of 22 OK created table model template.agg_customers................ [OK in 5.22s]
2018-07-30 13:37:13,869: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:37:14,177: 13:37:14 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 24.99s]
2018-07-30 13:37:14,178: 13:37:14 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 13:37:14,179: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:37:14,194: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 13:37:14,194: Re-using an available connection from the pool.
2018-07-30 13:37:14,195: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:37:14,943: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:37:15,090: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:37:15,091: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:37:26,083: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112035860>]}
2018-07-30 13:37:26,391: 13:37:26 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.90s]
2018-07-30 13:37:26,392: 13:37:26 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 13:37:26,392: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:37:26,404: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:37:26,405: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 13:37:26,405: Re-using an available connection from the pool.
2018-07-30 13:37:26,521: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:37:26,523: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 13:37:31,303: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:37:31,878: 13:37:31 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.91s]
2018-07-30 13:37:31,879: 13:37:31 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 13:37:31,879: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:37:31,886: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:37:31,890: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 13:37:31,891: Re-using an available connection from the pool.
2018-07-30 13:37:32,014: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:37:32,015: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 13:37:37,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112160438>]}
2018-07-30 13:37:38,730: 13:37:38 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 5.21s]
2018-07-30 13:37:38,731: 13:37:38 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 13:37:38,731: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:37:38,744: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:37:38,747: Acquiring new bigquery connection "agg_transactions".
2018-07-30 13:37:38,747: Re-using an available connection from the pool.
2018-07-30 13:37:38,893: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:37:38,893: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 13:37:46,824: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:37:47,127: 13:37:47 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.09s]
2018-07-30 13:37:47,128: 13:37:47 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 13:37:47,128: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:37:47,128: 13:37:47 | 16 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 13:37:47,128: 13:37:47 | 17 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 13:37:47,137: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:37:47,138: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:37:47,138: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:37:47,144: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:37:47,154: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:37:47,158: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 13:37:47,161: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 13:37:47,164: Re-using an available connection from the pool.
2018-07-30 13:37:47,164: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 13:37:47,165: Re-using an available connection from the pool.
2018-07-30 13:37:47,167: Re-using an available connection from the pool.
2018-07-30 13:37:47,298: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:37:47,299: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 13:37:47,391: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:37:47,415: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:37:47,415: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:37:47,416: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:37:51,608: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112016748>]}
2018-07-30 13:37:51,913: 13:37:51 | 16 of 22 OK created table model template.monthly_cohort_stats........ [OK in 4.47s]
2018-07-30 13:37:59,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120e8ef0>]}
2018-07-30 13:38:00,023: 13:38:00 | 17 of 22 OK created table model template.customers_proc_qoq.......... [OK in 12.10s]
2018-07-30 13:38:09,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112160438>]}
2018-07-30 13:38:09,895: 13:38:09 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 22.37s]
2018-07-30 13:38:09,896: 13:38:09 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 13:38:09,896: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 13:38:09,907: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:38:09,909: Acquiring new bigquery connection "customers_proc".
2018-07-30 13:38:09,909: Re-using an available connection from the pool.
2018-07-30 13:38:10,056: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:38:10,057: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 13:38:34,245: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:38:34,546: 13:38:34 | 18 of 22 OK created table model template.customers_proc.............. [OK in 24.35s]
2018-07-30 13:38:34,547: 13:38:34 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 13:38:34,547: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:38:34,556: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:38:34,560: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 13:38:34,561: Re-using an available connection from the pool.
2018-07-30 13:38:34,794: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:38:34,794: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 13:39:03,843: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120202b0>]}
2018-07-30 13:39:05,300: 13:39:05 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.30s]
2018-07-30 13:39:05,301: 13:39:05 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 13:39:05,301: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:39:05,310: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:39:05,311: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 13:39:05,312: Re-using an available connection from the pool.
2018-07-30 13:39:05,934: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:39:05,935: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 13:39:32,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112020240>]}
2018-07-30 13:39:33,652: 13:39:33 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 27.70s]
2018-07-30 13:39:33,653: 13:39:33 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 13:39:33,653: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 13:39:33,664: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 13:39:33,669: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 13:39:33,669: Re-using an available connection from the pool.
2018-07-30 13:39:33,954: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 13:39:33,954: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 13:39:37,156: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120abdd8>]}
2018-07-30 13:39:37,462: 13:39:37 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 3.50s]
2018-07-30 13:39:37,463: 13:39:37 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 13:39:37,463: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 13:39:37,471: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 13:39:37,472: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 13:39:37,473: Re-using an available connection from the pool.
2018-07-30 13:39:37,622: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 13:39:37,623: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 13:40:10,461: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f409c50>]}
2018-07-30 13:40:12,374: 13:40:12 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 33.00s]
2018-07-30 13:40:12,394: 13:40:12 | 
2018-07-30 13:40:12,394: 13:40:12 | Finished running 22 table models in 216.49s.
2018-07-30 13:40:12,394: Connection 'master' was left open.
2018-07-30 13:40:12,395: 
2018-07-30 13:40:12,395: Completed successfully
2018-07-30 13:40:12,395: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 13:40:12,396: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205dba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4253c8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f425e48>]}
2018-07-30 13:40:12,701: Flushing usage events
2018-07-30 13:40:12,850: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55334), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,851: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55333), raddr=('172.217.12.10', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55332), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55335), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55336), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55337), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,853: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55339), raddr=('172.217.1.202', 443)>

2018-07-30 13:40:12,853: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55338), raddr=('172.217.1.202', 443)>

2018-07-30 13:40:12,853: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55340), raddr=('172.217.1.202', 443)>

2018-07-30 13:40:12,854: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55341), raddr=('172.217.1.202', 443)>

2018-07-30 13:41:01,227: Tracking: tracking
2018-07-30 13:41:01,229: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2b38>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2320>]}
2018-07-30 13:41:01,638: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 13:41:01,676: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 13:41:01,683: Parsing get_column_values.sql
2018-07-30 13:41:01,704: Parsing get_url_parameter.sql
2018-07-30 13:41:01,713: Parsing split_part.sql
2018-07-30 13:41:01,722: Parsing table_exists.sql
2018-07-30 13:41:01,735: Parsing core.sql
2018-07-30 13:41:01,753: Parsing adapters/bigquery.sql
2018-07-30 13:41:01,763: Parsing adapters/common.sql
2018-07-30 13:41:01,791: Parsing adapters/redshift.sql
2018-07-30 13:41:01,819: Parsing adapters/snowflake.sql
2018-07-30 13:41:01,825: Parsing etc/bigquery.sql
2018-07-30 13:41:01,829: Parsing etc/datetime.sql
2018-07-30 13:41:01,891: Parsing etc/get_custom_schema.sql
2018-07-30 13:41:01,901: Parsing materializations/helpers.sql
2018-07-30 13:41:01,924: Parsing materializations/archive/archive.sql
2018-07-30 13:41:01,976: Parsing materializations/incremental/incremental.sql
2018-07-30 13:41:02,014: Parsing materializations/seed/bigquery.sql
2018-07-30 13:41:02,022: Parsing materializations/seed/seed.sql
2018-07-30 13:41:02,088: Parsing materializations/table/bigquery_table.sql
2018-07-30 13:41:02,122: Parsing materializations/table/table.sql
2018-07-30 13:41:02,150: Parsing materializations/view/bigquery_view.sql
2018-07-30 13:41:02,171: Parsing materializations/view/view.sql
2018-07-30 13:41:02,194: Parsing schema_tests/accepted_values.sql
2018-07-30 13:41:02,201: Parsing schema_tests/not_null.sql
2018-07-30 13:41:02,207: Parsing schema_tests/relationships.sql
2018-07-30 13:41:02,215: Parsing schema_tests/unique.sql
2018-07-30 13:41:02,245: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 13:41:02,248: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:41:02,250: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:41:02,253: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 13:41:02,255: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:41:02,266: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:41:02,274: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:41:02,287: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:41:02,302: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:41:02,314: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:41:02,322: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 13:41:02,325: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:41:02,330: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:41:02,334: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:41:02,339: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 13:41:02,351: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 13:41:02,368: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 13:41:02,374: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:41:02,382: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:41:02,391: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:41:02,397: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:41:02,407: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:41:02,438: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 13:41:02,453: 
2018-07-30 13:41:02,497: Acquiring new bigquery connection "master".
2018-07-30 13:41:02,497: Opening a new connection (0 currently allocated)
2018-07-30 13:41:03,875: 13:41:03 | Concurrency: 4 threads (target='template')
2018-07-30 13:41:03,876: 13:41:03 | 
2018-07-30 13:41:04,016: 13:41:04 | 1 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 13:41:04,017: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:41:04,017: 13:41:04 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 13:41:04,026: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:41:04,026: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 13:41:04,017: 13:41:04 | 3 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 13:41:04,017: 13:41:04 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 13:41:04,036: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:41:04,036: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:41:04,039: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 13:41:04,039: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 13:41:04,050: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:41:04,053: Acquiring new bigquery connection "all_dates".
2018-07-30 13:41:04,053: Opening a new connection (1 currently allocated)
2018-07-30 13:41:04,066: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:41:04,068: Opening a new connection (2 currently allocated)
2018-07-30 13:41:04,074: Acquiring new bigquery connection "monthend_dates".
2018-07-30 13:41:04,081: Acquiring new bigquery connection "stores_proc".
2018-07-30 13:41:04,090: Opening a new connection (3 currently allocated)
2018-07-30 13:41:04,100: Opening a new connection (4 currently allocated)
2018-07-30 13:41:04,939: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:41:04,962: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 13:41:04,980: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:41:05,009: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:41:05,011: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 13:41:05,035: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:41:05,037: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 13:41:05,039: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 13:41:06,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b82438>]}
2018-07-30 13:41:06,972: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:41:07,258: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b82470>]}
2018-07-30 13:41:07,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b82358>]}
2018-07-30 13:41:07,757: 13:41:07 | 2 of 22 OK created table model template.all_dates.................... [OK in 2.78s]
2018-07-30 13:41:08,552: 13:41:08 | 3 of 22 OK created table model template.monthend_dates............... [OK in 2.94s]
2018-07-30 13:41:09,120: 13:41:09 | 4 of 22 OK created table model template.stores_proc.................. [OK in 3.22s]
2018-07-30 13:41:09,405: 13:41:09 | 1 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.24s]
2018-07-30 13:41:09,406: 13:41:09 | 5 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 13:41:09,407: 13:41:09 | 6 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 13:41:09,407: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:41:09,407: 13:41:09 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 13:41:09,407: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:41:09,414: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:41:09,422: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 13:41:09,430: Re-using an available connection from the pool.
2018-07-30 13:41:09,430: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:09,433: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 13:41:09,434: Re-using an available connection from the pool.
2018-07-30 13:41:09,434: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:09,447: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 13:41:09,447: Re-using an available connection from the pool.
2018-07-30 13:41:09,448: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:10,934: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:41:11,059: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:41:11,062: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 13:41:11,154: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:41:11,208: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:41:11,283: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:41:11,284: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:41:11,333: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:41:11,333: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 13:41:13,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c36710>]}
2018-07-30 13:41:13,526: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c364a8>]}
2018-07-30 13:41:14,085: 13:41:14 | 6 of 22 OK created table model template.shopify_refunds_proc......... [OK in 3.84s]
2018-07-30 13:41:14,369: 13:41:14 | 5 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.12s]
2018-07-30 13:41:16,686: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:41:17,494: 13:41:17 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 7.27s]
2018-07-30 13:41:17,495: 13:41:17 | 8 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 13:41:17,495: 13:41:17 | 9 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 13:41:17,496: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:41:17,495: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 13:41:17,495: 13:41:17 | 10 of 22 START table model template.ga_transactions.................. [RUN]
2018-07-30 13:41:17,508: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 13:41:17,509: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:41:17,509: Re-using an available connection from the pool.
2018-07-30 13:41:17,515: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:41:17,522: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:17,524: Acquiring new bigquery connection "ga_transactions".
2018-07-30 13:41:17,526: Re-using an available connection from the pool.
2018-07-30 13:41:17,527: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:17,530: Acquiring new bigquery connection "agg_customers".
2018-07-30 13:41:17,530: Re-using an available connection from the pool.
2018-07-30 13:41:17,801: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:41:17,806: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 13:41:18,605: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:41:18,901: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:41:18,902: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 13:41:19,242: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:41:19,385: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:41:19,386: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 13:41:21,926: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b8c7f0>]}
2018-07-30 13:41:22,214: 13:41:22 | 9 of 22 OK created table model template.shopify_products_proc........ [OK in 4.43s]
2018-07-30 13:41:22,553: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18e10>]}
2018-07-30 13:41:22,837: 13:41:22 | 8 of 22 OK created table model template.agg_customers................ [OK in 5.06s]
2018-07-30 13:41:46,337: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c03eb8>]}
2018-07-30 13:41:46,850: 13:41:46 | 10 of 22 OK created table model template.ga_transactions............. [OK in 28.83s]
2018-07-30 13:41:46,851: 13:41:46 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 13:41:46,851: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:41:46,865: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 13:41:46,866: Re-using an available connection from the pool.
2018-07-30 13:41:46,866: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:47,589: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:41:47,729: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:41:47,730: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:41:58,314: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:41:58,628: 13:41:58 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.46s]
2018-07-30 13:41:58,628: 13:41:58 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 13:41:58,629: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:41:58,637: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:41:58,639: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 13:41:58,639: Re-using an available connection from the pool.
2018-07-30 13:41:58,758: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:41:58,759: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 13:42:02,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18e10>]}
2018-07-30 13:42:03,381: 13:42:03 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 3.90s]
2018-07-30 13:42:03,382: 13:42:03 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 13:42:03,382: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:42:03,392: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:42:03,393: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 13:42:03,394: Re-using an available connection from the pool.
2018-07-30 13:42:03,570: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:42:03,570: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 13:42:07,710: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:42:08,008: 13:42:08 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.33s]
2018-07-30 13:42:08,008: 13:42:08 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 13:42:08,009: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:42:08,018: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:42:08,019: Acquiring new bigquery connection "agg_transactions".
2018-07-30 13:42:08,019: Re-using an available connection from the pool.
2018-07-30 13:42:08,143: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:42:08,147: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 13:42:16,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c99b70>]}
2018-07-30 13:42:18,113: 13:42:18 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.87s]
2018-07-30 13:42:18,114: 13:42:18 | 15 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 13:42:18,114: 13:42:18 | 16 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 13:42:18,115: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:42:18,115: 13:42:18 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 13:42:18,115: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:42:18,123: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:42:18,125: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:42:18,130: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:42:18,140: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:42:18,144: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 13:42:18,144: Re-using an available connection from the pool.
2018-07-30 13:42:18,146: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 13:42:18,146: Re-using an available connection from the pool.
2018-07-30 13:42:18,150: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 13:42:18,152: Re-using an available connection from the pool.
2018-07-30 13:42:18,308: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:42:18,338: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:42:18,347: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:42:18,347: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 13:42:18,354: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:42:18,355: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:42:24,327: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b59da0>]}
2018-07-30 13:42:24,622: 13:42:24 | 16 of 22 OK created table model template.monthly_cohort_stats........ [OK in 6.21s]
2018-07-30 13:42:30,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:42:31,520: 13:42:31 | 15 of 22 OK created table model template.customers_proc_qoq.......... [OK in 12.76s]
2018-07-30 13:42:40,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bd4198>]}
2018-07-30 13:42:41,170: 13:42:41 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 22.39s]
2018-07-30 13:42:41,171: 13:42:41 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 13:42:41,171: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 13:42:41,179: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:42:41,180: Acquiring new bigquery connection "customers_proc".
2018-07-30 13:42:41,181: Re-using an available connection from the pool.
2018-07-30 13:42:41,468: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:42:41,468: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 13:43:17,149: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d739f60>]}
2018-07-30 13:43:17,518: 13:43:17 | 18 of 22 OK created table model template.customers_proc.............. [OK in 35.98s]
2018-07-30 13:43:17,519: 13:43:17 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 13:43:17,519: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:43:17,527: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:43:17,532: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 13:43:17,532: Re-using an available connection from the pool.
2018-07-30 13:43:17,706: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:43:17,707: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 13:43:46,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b2c780>]}
2018-07-30 13:43:47,928: 13:43:47 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.10s]
2018-07-30 13:43:47,929: 13:43:47 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 13:43:47,930: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:43:47,946: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:43:47,950: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 13:43:47,950: Re-using an available connection from the pool.
2018-07-30 13:43:48,248: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:43:48,249: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 13:43:49,026: Bad request while running:
create dataset
2018-07-30 13:43:49,026: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/8565d834-4116-46d8-827d-31d62d988892?maxResults=0: Unrecognized name: recency; Did you mean frequency? at [48:9]
2018-07-30 13:43:49,027: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b49080>]}
2018-07-30 13:43:49,416: 13:43:49 | 20 of 22 ERROR creating table model template.segment_stats_customers_agg [ERROR in 1.10s]
2018-07-30 13:43:49,418: 13:43:49 | 21 of 22 SKIP relation template.buyer_segment_stats.................. [SKIP]
2018-07-30 13:43:49,419: 13:43:49 | 22 of 22 SKIP relation template.buyer_segment_lists.................. [SKIP]
2018-07-30 13:43:49,437: 13:43:49 | 
2018-07-30 13:43:49,437: 13:43:49 | Finished running 22 table models in 166.98s.
2018-07-30 13:43:49,437: Connection 'master' was left open.
2018-07-30 13:43:49,438: 
2018-07-30 13:43:49,438: Completed with 1 errors:
2018-07-30 13:43:49,438: 
2018-07-30 13:43:49,438: Database Error in model segment_stats_customers_agg (models/math/buyer-segmentation/segment_stats_customers_agg.sql)
2018-07-30 13:43:49,438:   Unrecognized name: recency; Did you mean frequency? at [48:9]
2018-07-30 13:43:49,438:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/segment_stats_customers_agg.sql
2018-07-30 13:43:49,438: 
Done. PASS=19 ERROR=1 SKIP=2 TOTAL=22
2018-07-30 13:43:49,439: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18e10>]}
2018-07-30 13:43:49,733: Flushing usage events
2018-07-30 13:43:49,974: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55379), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,975: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55378), raddr=('172.217.11.234', 443)>

2018-07-30 13:43:49,976: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55377), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,976: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55380), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,976: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55383), raddr=('172.217.2.10', 443)>

2018-07-30 13:43:49,977: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55381), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,977: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55382), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,977: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55385), raddr=('172.217.2.10', 443)>

2018-07-30 13:43:49,978: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55384), raddr=('172.217.2.10', 443)>

2018-07-30 13:43:49,978: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55386), raddr=('172.217.2.10', 443)>

2018-07-30 14:06:20,480: Tracking: tracking
2018-07-30 14:06:20,482: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081c00f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082edd68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082ede48>]}
2018-07-30 14:06:21,453: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:06:21,487: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:06:21,497: Parsing get_column_values.sql
2018-07-30 14:06:21,521: Parsing get_url_parameter.sql
2018-07-30 14:06:21,528: Parsing split_part.sql
2018-07-30 14:06:21,540: Parsing table_exists.sql
2018-07-30 14:06:21,558: Parsing core.sql
2018-07-30 14:06:21,579: Parsing adapters/bigquery.sql
2018-07-30 14:06:21,596: Parsing adapters/common.sql
2018-07-30 14:06:21,629: Parsing adapters/redshift.sql
2018-07-30 14:06:21,656: Parsing adapters/snowflake.sql
2018-07-30 14:06:21,661: Parsing etc/bigquery.sql
2018-07-30 14:06:21,667: Parsing etc/datetime.sql
2018-07-30 14:06:21,698: Parsing etc/get_custom_schema.sql
2018-07-30 14:06:21,706: Parsing materializations/helpers.sql
2018-07-30 14:06:21,731: Parsing materializations/archive/archive.sql
2018-07-30 14:06:21,789: Parsing materializations/incremental/incremental.sql
2018-07-30 14:06:21,828: Parsing materializations/seed/bigquery.sql
2018-07-30 14:06:21,836: Parsing materializations/seed/seed.sql
2018-07-30 14:06:21,881: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:06:21,918: Parsing materializations/table/table.sql
2018-07-30 14:06:21,950: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:06:21,967: Parsing materializations/view/view.sql
2018-07-30 14:06:21,987: Parsing schema_tests/accepted_values.sql
2018-07-30 14:06:21,994: Parsing schema_tests/not_null.sql
2018-07-30 14:06:22,000: Parsing schema_tests/relationships.sql
2018-07-30 14:06:22,007: Parsing schema_tests/unique.sql
2018-07-30 14:06:22,063: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:06:22,067: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:06:22,071: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:06:22,074: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:06:22,076: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:06:22,085: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:06:22,092: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:06:22,099: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:06:22,109: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:06:22,118: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:06:22,124: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:06:22,127: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:06:22,130: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:06:22,133: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:06:22,138: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:06:22,142: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:06:22,145: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:06:22,148: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:06:22,152: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:06:22,157: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:06:22,159: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:06:22,165: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:06:22,172: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:06:22,190: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:06:22,199: 
2018-07-30 14:06:22,207: Acquiring new bigquery connection "master".
2018-07-30 14:06:22,207: Opening a new connection (0 currently allocated)
2018-07-30 14:06:23,585: 14:06:23 | Concurrency: 4 threads (target='template')
2018-07-30 14:06:23,585: 14:06:23 | 
2018-07-30 14:06:23,643: 14:06:23 | 1 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:06:23,643: 14:06:23 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:06:23,644: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:06:23,644: 14:06:23 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:06:23,644: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:06:23,644: 14:06:23 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:06:23,649: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:06:23,649: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:06:23,655: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:06:23,655: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:06:23,662: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:06:23,668: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:06:23,671: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:06:23,672: Opening a new connection (1 currently allocated)
2018-07-30 14:06:23,675: Acquiring new bigquery connection "all_dates".
2018-07-30 14:06:23,677: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:06:23,679: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:06:23,687: Opening a new connection (2 currently allocated)
2018-07-30 14:06:23,690: Opening a new connection (3 currently allocated)
2018-07-30 14:06:23,699: Opening a new connection (4 currently allocated)
2018-07-30 14:06:24,120: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:06:24,121: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:06:24,144: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:06:24,155: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:06:24,162: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:06:24,166: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:06:24,167: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:06:24,173: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:06:25,771: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108426ef0>]}
2018-07-30 14:06:26,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084265f8>]}
2018-07-30 14:06:26,243: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108426cf8>]}
2018-07-30 14:06:26,246: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108426978>]}
2018-07-30 14:06:27,531: 14:06:27 | 1 of 23 OK created table model template.all_dates.................... [OK in 2.13s]
2018-07-30 14:06:27,918: 14:06:27 | 2 of 23 OK created table model template.stores_proc.................. [OK in 2.60s]
2018-07-30 14:06:28,205: 14:06:28 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.59s]
2018-07-30 14:06:28,552: 14:06:28 | 3 of 23 OK created table model template.monthend_dates............... [OK in 2.60s]
2018-07-30 14:06:28,556: 14:06:28 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:06:28,556: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:06:28,565: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:06:28,565: Re-using an available connection from the pool.
2018-07-30 14:06:28,566: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:28,556: 14:06:28 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:06:28,566: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:06:28,556: 14:06:28 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:06:28,568: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:06:28,581: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:06:28,582: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:06:28,583: Re-using an available connection from the pool.
2018-07-30 14:06:28,583: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:28,584: Re-using an available connection from the pool.
2018-07-30 14:06:28,584: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:30,053: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:06:30,068: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:06:30,184: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:06:30,184: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:06:30,215: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:06:30,216: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:06:30,937: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:06:31,068: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:06:31,069: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:06:32,503: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084fce10>]}
2018-07-30 14:06:32,793: 14:06:32 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 3.94s]
2018-07-30 14:06:33,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085254e0>]}
2018-07-30 14:06:33,369: 14:06:33 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.51s]
2018-07-30 14:06:34,729: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:06:35,516: 14:06:35 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.17s]
2018-07-30 14:06:35,516: 14:06:35 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:06:35,517: 14:06:35 | 9 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:06:35,517: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:06:35,517: 14:06:35 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 14:06:35,518: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:06:35,519: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:06:35,525: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:06:35,553: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:06:35,553: Re-using an available connection from the pool.
2018-07-30 14:06:35,555: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:06:35,555: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:35,556: Re-using an available connection from the pool.
2018-07-30 14:06:35,561: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:35,559: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:06:35,564: Re-using an available connection from the pool.
2018-07-30 14:06:35,868: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:06:35,874: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:06:36,649: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:06:36,818: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:06:36,819: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:06:37,407: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:06:37,545: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:06:37,545: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:06:39,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108475e10>]}
2018-07-30 14:06:39,356: 14:06:39 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.55s]
2018-07-30 14:06:39,601: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b7160>]}
2018-07-30 14:06:39,918: 14:06:39 | 9 of 23 OK created table model template.agg_customers................ [OK in 4.08s]
2018-07-30 14:07:01,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:07:02,628: 14:07:02 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 26.37s]
2018-07-30 14:07:02,628: 14:07:02 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:07:02,629: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:07:02,643: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:07:02,643: Re-using an available connection from the pool.
2018-07-30 14:07:02,643: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:07:03,652: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:07:03,817: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:07:03,817: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:07:13,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:07:14,563: 14:07:14 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.28s]
2018-07-30 14:07:14,563: 14:07:14 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:07:14,564: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:07:14,574: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:07:14,577: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:07:14,577: Re-using an available connection from the pool.
2018-07-30 14:07:14,749: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:07:14,750: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:07:18,792: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:07:19,121: 14:07:19 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.23s]
2018-07-30 14:07:19,128: 14:07:19 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:07:19,128: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:07:19,140: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:07:19,144: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:07:19,144: Re-using an available connection from the pool.
2018-07-30 14:07:19,263: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:07:19,263: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:07:22,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:07:24,452: 14:07:24 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.73s]
2018-07-30 14:07:24,453: 14:07:24 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:07:24,453: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:07:24,460: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:07:24,462: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:07:24,462: Re-using an available connection from the pool.
2018-07-30 14:07:24,599: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:07:24,599: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:07:32,625: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:07:33,420: 14:07:33 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.17s]
2018-07-30 14:07:33,420: 14:07:33 | 15 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:07:33,421: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:07:33,421: 14:07:33 | 16 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:07:33,421: 14:07:33 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:07:33,429: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:07:33,429: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:07:33,429: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:07:33,437: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:07:33,444: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:07:33,450: Re-using an available connection from the pool.
2018-07-30 14:07:33,449: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:07:33,457: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:07:33,457: Re-using an available connection from the pool.
2018-07-30 14:07:33,463: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:07:33,464: Re-using an available connection from the pool.
2018-07-30 14:07:33,779: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:07:33,799: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:07:33,804: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:07:33,805: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:07:33,806: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:07:33,806: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:07:39,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:07:40,611: 14:07:40 | 15 of 23 OK created table model template.monthly_cohort_stats........ [OK in 6.46s]
2018-07-30 14:07:46,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084482e8>]}
2018-07-30 14:07:46,626: 14:07:46 | 16 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.90s]
2018-07-30 14:07:57,449: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108448940>]}
2018-07-30 14:07:57,742: 14:07:57 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 24.02s]
2018-07-30 14:07:57,743: 14:07:57 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:07:57,743: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:07:57,752: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:07:57,753: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:07:57,753: Re-using an available connection from the pool.
2018-07-30 14:07:57,907: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:07:57,908: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:08:27,556: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:08:29,176: 14:08:29 | 18 of 23 OK created table model template.customers_proc.............. [OK in 29.81s]
2018-07-30 14:08:29,177: 14:08:29 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:08:29,178: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:08:29,195: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:08:29,199: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:08:29,199: Re-using an available connection from the pool.
2018-07-30 14:08:29,357: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:08:29,375: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:09:00,541: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510ef60>]}
2018-07-30 14:09:00,862: 14:09:00 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 31.36s]
2018-07-30 14:09:00,863: 14:09:00 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:09:00,863: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:09:00,876: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:09:00,877: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:09:00,878: Re-using an available connection from the pool.
2018-07-30 14:09:01,410: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:09:01,411: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 14:09:28,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:09:29,768: 14:09:29 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 27.66s]
2018-07-30 14:09:29,769: 14:09:29 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:09:29,769: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:09:29,784: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:09:29,786: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:09:29,786: Re-using an available connection from the pool.
2018-07-30 14:09:30,340: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:09:30,341: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 14:09:34,857: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510ef60>]}
2018-07-30 14:09:35,650: 14:09:35 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.09s]
2018-07-30 14:09:35,651: 14:09:35 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:09:35,652: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:09:35,663: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:09:35,664: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:09:35,665: Re-using an available connection from the pool.
2018-07-30 14:09:35,826: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:09:35,826: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
segment_prev,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	segment_prev,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	where revenue_segment != ''
	and revenue_segment_prev != ''
	GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:09:36,306: Bad request while running:
create dataset
2018-07-30 14:09:36,308: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/d9d50381-ec74-4f8f-a04d-ed662259a98a?maxResults=0: Unrecognized name: revenue_segment at [51:15]
2018-07-30 14:09:36,309: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108484be0>]}
2018-07-30 14:09:36,606: 14:09:36 | 22 of 23 ERROR creating table model template.buyer_segment_stats..... [ERROR in 0.66s]
2018-07-30 14:09:36,607: 14:09:36 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:09:36,608: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:09:36,614: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:09:36,616: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:09:36,616: Re-using an available connection from the pool.
2018-07-30 14:09:36,748: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:09:36,749: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:10:07,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510ef60>]}
2018-07-30 14:10:07,763: 14:10:07 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 30.83s]
2018-07-30 14:10:07,861: 14:10:07 | 
2018-07-30 14:10:07,861: 14:10:07 | Finished running 23 table models in 225.66s.
2018-07-30 14:10:07,862: Connection 'master' was left open.
2018-07-30 14:10:07,862: 
2018-07-30 14:10:07,862: Completed with 1 errors:
2018-07-30 14:10:07,863: 
2018-07-30 14:10:07,863: Database Error in model buyer_segment_stats (models/math/buyer-segmentation/buyer_segment_stats.sql)
2018-07-30 14:10:07,863:   Unrecognized name: revenue_segment at [51:15]
2018-07-30 14:10:07,863:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/buyer_segment_stats.sql
2018-07-30 14:10:07,864: 
Done. PASS=22 ERROR=1 SKIP=0 TOTAL=23
2018-07-30 14:10:07,864: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b7780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b7080>]}
2018-07-30 14:10:08,167: Flushing usage events
2018-07-30 14:10:08,347: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55453), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55452), raddr=('172.217.1.202', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55451), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55459), raddr=('172.217.12.10', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55457), raddr=('172.217.1.202', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55454), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55458), raddr=('172.217.12.10', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55460), raddr=('172.217.12.10', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55455), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55456), raddr=('172.217.2.13', 443)>

2018-07-30 14:11:51,400: Tracking: tracking
2018-07-30 14:11:51,402: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba26be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba26b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba26e80>]}
2018-07-30 14:11:52,439: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:11:52,500: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:11:52,510: Parsing get_column_values.sql
2018-07-30 14:11:52,539: Parsing get_url_parameter.sql
2018-07-30 14:11:52,549: Parsing split_part.sql
2018-07-30 14:11:52,559: Parsing table_exists.sql
2018-07-30 14:11:52,587: Parsing core.sql
2018-07-30 14:11:52,620: Parsing adapters/bigquery.sql
2018-07-30 14:11:52,637: Parsing adapters/common.sql
2018-07-30 14:11:52,683: Parsing adapters/redshift.sql
2018-07-30 14:11:52,724: Parsing adapters/snowflake.sql
2018-07-30 14:11:52,729: Parsing etc/bigquery.sql
2018-07-30 14:11:52,733: Parsing etc/datetime.sql
2018-07-30 14:11:52,762: Parsing etc/get_custom_schema.sql
2018-07-30 14:11:52,770: Parsing materializations/helpers.sql
2018-07-30 14:11:52,799: Parsing materializations/archive/archive.sql
2018-07-30 14:11:52,847: Parsing materializations/incremental/incremental.sql
2018-07-30 14:11:52,882: Parsing materializations/seed/bigquery.sql
2018-07-30 14:11:52,890: Parsing materializations/seed/seed.sql
2018-07-30 14:11:52,943: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:11:52,976: Parsing materializations/table/table.sql
2018-07-30 14:11:53,014: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:11:53,028: Parsing materializations/view/view.sql
2018-07-30 14:11:53,051: Parsing schema_tests/accepted_values.sql
2018-07-30 14:11:53,059: Parsing schema_tests/not_null.sql
2018-07-30 14:11:53,067: Parsing schema_tests/relationships.sql
2018-07-30 14:11:53,075: Parsing schema_tests/unique.sql
2018-07-30 14:11:53,141: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:11:53,146: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:11:53,151: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:11:53,154: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:11:53,159: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:11:53,177: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:11:53,185: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:11:53,191: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:11:53,202: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:11:53,211: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:11:53,218: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:11:53,220: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:11:53,223: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:11:53,226: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:11:53,229: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:11:53,234: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:11:53,237: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:11:53,240: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:11:53,244: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:11:53,249: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:11:53,252: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:11:53,257: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:11:53,264: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:11:53,288: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:11:53,303: 
2018-07-30 14:11:53,313: Acquiring new bigquery connection "master".
2018-07-30 14:11:53,314: Opening a new connection (0 currently allocated)
2018-07-30 14:11:54,939: 14:11:54 | Concurrency: 4 threads (target='template')
2018-07-30 14:11:54,939: 14:11:54 | 
2018-07-30 14:11:55,015: 14:11:55 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:11:55,015: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:11:55,015: 14:11:55 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:11:55,021: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:11:55,025: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:11:55,015: 14:11:55 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:11:55,029: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:11:55,028: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:11:55,034: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:11:55,015: 14:11:55 | 4 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:11:55,034: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:11:55,040: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:11:55,042: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:11:55,042: Opening a new connection (1 currently allocated)
2018-07-30 14:11:55,044: Acquiring new bigquery connection "all_dates".
2018-07-30 14:11:55,047: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:11:55,048: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:11:55,050: Opening a new connection (2 currently allocated)
2018-07-30 14:11:55,063: Opening a new connection (3 currently allocated)
2018-07-30 14:11:55,068: Opening a new connection (4 currently allocated)
2018-07-30 14:11:56,218: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:11:56,241: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:11:56,245: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:11:56,246: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:11:56,246: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:11:56,247: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:11:56,363: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:11:56,364: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:11:57,896: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb635c0>]}
2018-07-30 14:11:57,925: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbf518>]}
2018-07-30 14:11:58,166: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb63f98>]}
2018-07-30 14:11:58,206: 14:11:58 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.87s]
2018-07-30 14:11:58,449: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb6c748>]}
2018-07-30 14:11:58,518: 14:11:58 | 4 of 23 OK created table model template.monthend_dates............... [OK in 2.89s]
2018-07-30 14:11:58,830: 14:11:58 | 2 of 23 OK created table model template.stores_proc.................. [OK in 3.15s]
2018-07-30 14:11:59,131: 14:11:59 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 3.43s]
2018-07-30 14:11:59,131: 14:11:59 | 5 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:11:59,132: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:11:59,132: 14:11:59 | 6 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:11:59,145: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:11:59,132: 14:11:59 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:11:59,155: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:11:59,161: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:11:59,164: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:11:59,165: Re-using an available connection from the pool.
2018-07-30 14:11:59,182: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:11:59,182: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:11:59,188: Re-using an available connection from the pool.
2018-07-30 14:11:59,188: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:11:59,190: Re-using an available connection from the pool.
2018-07-30 14:11:59,190: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:00,718: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:12:00,759: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:12:00,851: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:12:00,851: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:12:00,900: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:12:00,904: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:12:01,206: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:12:01,349: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:12:01,349: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:12:02,868: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087757b8>]}
2018-07-30 14:12:03,164: 14:12:03 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 3.71s]
2018-07-30 14:12:03,352: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb6c748>]}
2018-07-30 14:12:03,648: 14:12:03 | 5 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.22s]
2018-07-30 14:12:05,643: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:12:06,451: 14:12:06 | 6 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.50s]
2018-07-30 14:12:06,453: 14:12:06 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:12:06,453: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:12:06,460: 14:12:06 | 9 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:12:06,460: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:12:06,478: 14:12:06 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 14:12:06,479: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:12:06,536: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:12:06,539: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:12:06,545: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:12:06,549: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:12:06,549: Re-using an available connection from the pool.
2018-07-30 14:12:06,549: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:06,549: Re-using an available connection from the pool.
2018-07-30 14:12:06,550: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:06,550: Re-using an available connection from the pool.
2018-07-30 14:12:06,766: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:12:06,768: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:12:07,403: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:12:07,545: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:12:07,546: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:12:07,910: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:12:08,036: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:12:08,037: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:12:10,043: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc56080>]}
2018-07-30 14:12:10,328: 14:12:10 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.56s]
2018-07-30 14:12:10,824: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10927fc18>]}
2018-07-30 14:12:11,115: 14:12:11 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.37s]
2018-07-30 14:12:34,654: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc49d68>]}
2018-07-30 14:12:35,320: 14:12:35 | 9 of 23 OK created table model template.ga_transactions.............. [OK in 28.19s]
2018-07-30 14:12:35,321: 14:12:35 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:12:35,321: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:12:35,337: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:12:35,337: Re-using an available connection from the pool.
2018-07-30 14:12:35,337: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:35,975: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:12:36,105: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:12:36,106: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:12:47,127: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:12:47,418: 14:12:47 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.81s]
2018-07-30 14:12:47,419: 14:12:47 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:12:47,419: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:12:47,430: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:12:47,437: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:12:47,438: Re-using an available connection from the pool.
2018-07-30 14:12:47,577: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:12:47,578: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:12:51,561: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb8ce48>]}
2018-07-30 14:12:52,228: 14:12:52 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.14s]
2018-07-30 14:12:52,229: 14:12:52 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:12:52,229: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:12:52,236: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:12:52,238: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:12:52,238: Re-using an available connection from the pool.
2018-07-30 14:12:52,527: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:12:52,528: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:12:55,893: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:12:57,138: 14:12:57 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.66s]
2018-07-30 14:12:57,139: 14:12:57 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:12:57,139: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:12:57,151: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:12:57,154: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:12:57,154: Re-using an available connection from the pool.
2018-07-30 14:12:57,282: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:12:57,283: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:13:06,012: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb8ce48>]}
2018-07-30 14:13:06,313: 14:13:06 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.87s]
2018-07-30 14:13:06,314: 14:13:06 | 15 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:13:06,314: 14:13:06 | 16 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:13:06,314: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:13:06,314: 14:13:06 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:13:06,315: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:13:06,320: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:13:06,330: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:13:06,353: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:13:06,358: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:13:06,361: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:13:06,361: Re-using an available connection from the pool.
2018-07-30 14:13:06,363: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:13:06,364: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:13:06,365: Re-using an available connection from the pool.
2018-07-30 14:13:06,369: Re-using an available connection from the pool.
2018-07-30 14:13:06,527: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:13:06,539: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:13:06,555: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:13:06,555: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:13:06,557: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:13:06,563: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:13:11,241: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:13:11,908: 14:13:11 | 15 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.93s]
2018-07-30 14:13:20,086: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc49da0>]}
2018-07-30 14:13:20,877: 14:13:20 | 16 of 23 OK created table model template.customers_proc_qoq.......... [OK in 13.77s]
2018-07-30 14:13:31,721: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcbb0f0>]}
2018-07-30 14:13:32,024: 14:13:32 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 25.40s]
2018-07-30 14:13:32,025: 14:13:32 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:13:32,025: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:13:32,042: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:13:32,047: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:13:32,047: Re-using an available connection from the pool.
2018-07-30 14:13:32,193: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:13:32,194: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:13:58,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109002860>]}
2018-07-30 14:14:00,318: 14:14:00 | 18 of 23 OK created table model template.customers_proc.............. [OK in 26.42s]
2018-07-30 14:14:00,319: 14:14:00 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:14:00,319: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:14:00,329: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:14:00,331: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:14:00,331: Re-using an available connection from the pool.
2018-07-30 14:14:00,851: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:14:00,851: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:14:30,721: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090027f0>]}
2018-07-30 14:14:31,021: 14:14:31 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 30.40s]
2018-07-30 14:14:31,022: 14:14:31 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:14:31,022: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:14:31,033: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:14:31,038: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:14:31,038: Re-using an available connection from the pool.
2018-07-30 14:14:31,160: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:14:31,161: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
max(newness_segment) newness_segment,	
max(newness_segment_prev) newness_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 14:14:59,898: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109002320>]}
2018-07-30 14:15:01,114: 14:15:01 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 28.88s]
2018-07-30 14:15:01,115: 14:15:01 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:15:01,115: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:15:01,131: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:15:01,135: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:15:01,135: Re-using an available connection from the pool.
2018-07-30 14:15:01,260: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:15:01,260: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 14:15:04,714: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090027f0>]}
2018-07-30 14:15:05,502: 14:15:05 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 3.60s]
2018-07-30 14:15:05,503: 14:15:05 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:15:05,504: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:15:05,517: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:15:05,519: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:15:05,519: Re-using an available connection from the pool.
2018-07-30 14:15:05,675: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:15:05,676: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
segment_prev,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	segment_prev,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:15:07,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109002320>]}
2018-07-30 14:15:08,181: 14:15:08 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.37s]
2018-07-30 14:15:08,182: 14:15:08 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:15:08,182: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:15:08,195: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:15:08,197: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:15:08,197: Re-using an available connection from the pool.
2018-07-30 14:15:08,339: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:15:08,339: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:15:45,506: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090027f0>]}
2018-07-30 14:15:45,827: 14:15:45 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 37.32s]
2018-07-30 14:15:45,902: 14:15:45 | 
2018-07-30 14:15:45,902: 14:15:45 | Finished running 23 table models in 232.60s.
2018-07-30 14:15:45,903: Connection 'master' was left open.
2018-07-30 14:15:45,903: 
2018-07-30 14:15:45,903: Completed successfully
2018-07-30 14:15:45,904: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 14:15:45,905: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb29518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10baf4128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10baf45c0>]}
2018-07-30 14:15:46,281: Flushing usage events
2018-07-30 14:15:46,492: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55500), raddr=('172.217.2.10', 443)>

2018-07-30 14:15:46,493: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55499), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,493: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55505), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,493: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55506), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,494: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55508), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,495: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55501), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,495: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55502), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,496: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55507), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,496: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55503), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,497: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55504), raddr=('172.217.1.205', 443)>

2018-07-30 14:16:59,915: Tracking: tracking
2018-07-30 14:16:59,921: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514ac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514ac88>]}
2018-07-30 14:17:00,832: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:17:00,860: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:17:00,870: Parsing get_column_values.sql
2018-07-30 14:17:00,897: Parsing get_url_parameter.sql
2018-07-30 14:17:00,904: Parsing split_part.sql
2018-07-30 14:17:00,916: Parsing table_exists.sql
2018-07-30 14:17:00,932: Parsing core.sql
2018-07-30 14:17:00,950: Parsing adapters/bigquery.sql
2018-07-30 14:17:00,959: Parsing adapters/common.sql
2018-07-30 14:17:00,988: Parsing adapters/redshift.sql
2018-07-30 14:17:01,017: Parsing adapters/snowflake.sql
2018-07-30 14:17:01,025: Parsing etc/bigquery.sql
2018-07-30 14:17:01,030: Parsing etc/datetime.sql
2018-07-30 14:17:01,074: Parsing etc/get_custom_schema.sql
2018-07-30 14:17:01,086: Parsing materializations/helpers.sql
2018-07-30 14:17:01,121: Parsing materializations/archive/archive.sql
2018-07-30 14:17:01,183: Parsing materializations/incremental/incremental.sql
2018-07-30 14:17:01,232: Parsing materializations/seed/bigquery.sql
2018-07-30 14:17:01,245: Parsing materializations/seed/seed.sql
2018-07-30 14:17:01,293: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:17:01,325: Parsing materializations/table/table.sql
2018-07-30 14:17:01,358: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:17:01,378: Parsing materializations/view/view.sql
2018-07-30 14:17:01,413: Parsing schema_tests/accepted_values.sql
2018-07-30 14:17:01,422: Parsing schema_tests/not_null.sql
2018-07-30 14:17:01,426: Parsing schema_tests/relationships.sql
2018-07-30 14:17:01,432: Parsing schema_tests/unique.sql
2018-07-30 14:17:01,499: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:17:01,504: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:17:01,508: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:17:01,510: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:17:01,513: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:17:01,523: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:17:01,530: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:17:01,539: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:17:01,550: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:17:01,561: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:17:01,570: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:17:01,576: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:17:01,582: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:17:01,590: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:17:01,595: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:17:01,600: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:17:01,603: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:17:01,611: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:17:01,617: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:17:01,626: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:17:01,630: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:17:01,641: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:17:01,654: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:17:01,683: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:17:01,696: 
2018-07-30 14:17:01,711: Acquiring new bigquery connection "master".
2018-07-30 14:17:01,711: Opening a new connection (0 currently allocated)
2018-07-30 14:17:02,986: 14:17:02 | Concurrency: 4 threads (target='template')
2018-07-30 14:17:02,986: 14:17:02 | 
2018-07-30 14:17:03,077: 14:17:03 | 1 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:17:03,077: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:17:03,077: 14:17:03 | 2 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:17:03,084: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:17:03,094: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:17:03,095: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:17:03,077: 14:17:03 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:17:03,077: 14:17:03 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:17:03,096: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:17:03,096: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:17:03,103: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:17:03,113: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:17:03,119: Opening a new connection (1 currently allocated)
2018-07-30 14:17:03,115: Acquiring new bigquery connection "all_dates".
2018-07-30 14:17:03,131: Opening a new connection (2 currently allocated)
2018-07-30 14:17:03,130: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:17:03,119: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:17:03,137: Opening a new connection (3 currently allocated)
2018-07-30 14:17:03,142: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:17:03,153: Opening a new connection (4 currently allocated)
2018-07-30 14:17:03,632: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:17:03,656: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:17:03,679: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:17:03,679: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:17:03,686: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:17:03,693: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:17:03,694: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:17:03,703: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:17:05,593: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105285668>]}
2018-07-30 14:17:05,598: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105285b70>]}
2018-07-30 14:17:05,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052854a8>]}
2018-07-30 14:17:05,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105285160>]}
2018-07-30 14:17:06,274: 14:17:06 | 2 of 23 OK created table model template.monthend_dates............... [OK in 2.51s]
2018-07-30 14:17:06,902: 14:17:06 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.50s]
2018-07-30 14:17:07,571: 14:17:07 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.51s]
2018-07-30 14:17:08,393: 14:17:08 | 1 of 23 OK created table model template.stores_proc.................. [OK in 2.73s]
2018-07-30 14:17:08,393: 14:17:08 | 5 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:17:08,394: 14:17:08 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:17:08,394: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:17:08,394: 14:17:08 | 7 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:17:08,395: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:17:08,400: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:17:08,412: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:17:08,418: Re-using an available connection from the pool.
2018-07-30 14:17:08,418: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:08,423: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:17:08,424: Re-using an available connection from the pool.
2018-07-30 14:17:08,424: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:08,431: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:17:08,433: Re-using an available connection from the pool.
2018-07-30 14:17:08,433: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:10,454: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:17:10,600: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:17:10,601: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:17:10,607: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:17:10,762: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:17:10,762: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:17:10,949: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:17:11,092: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:17:11,092: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:17:12,771: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105380828>]}
2018-07-30 14:17:13,162: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105284898>]}
2018-07-30 14:17:13,166: 14:17:13 | 5 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.38s]
2018-07-30 14:17:13,466: 14:17:13 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.77s]
2018-07-30 14:17:15,581: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052185c0>]}
2018-07-30 14:17:16,199: 14:17:16 | 7 of 23 OK created table model template.shopify_customers_proc....... [OK in 7.18s]
2018-07-30 14:17:16,199: 14:17:16 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:17:16,200: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:17:16,199: 14:17:16 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 14:17:16,206: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:17:16,207: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:17:16,200: 14:17:16 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 14:17:16,208: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:17:16,222: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:17:16,230: Re-using an available connection from the pool.
2018-07-30 14:17:16,224: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:17:16,230: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:17:16,230: Re-using an available connection from the pool.
2018-07-30 14:17:16,231: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:16,231: Re-using an available connection from the pool.
2018-07-30 14:17:16,235: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:16,538: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:17:16,541: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:17:17,328: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:17:17,509: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:17:17,510: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:17:18,090: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:17:18,260: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:17:18,261: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:17:19,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad748>]}
2018-07-30 14:17:19,931: 14:17:19 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.43s]
2018-07-30 14:17:20,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102986c18>]}
2018-07-30 14:17:21,177: 14:17:21 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.66s]
2018-07-30 14:17:43,103: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad198>]}
2018-07-30 14:17:43,866: 14:17:43 | 10 of 23 OK created table model template.ga_transactions............. [OK in 26.89s]
2018-07-30 14:17:43,867: 14:17:43 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:17:43,868: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:17:43,884: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:17:43,884: Re-using an available connection from the pool.
2018-07-30 14:17:43,884: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:44,835: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:17:45,009: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:17:45,009: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:17:56,000: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052185c0>]}
2018-07-30 14:17:56,310: 14:17:56 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 12.13s]
2018-07-30 14:17:56,310: 14:17:56 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:17:56,311: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:17:56,321: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:17:56,325: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:17:56,325: Re-using an available connection from the pool.
2018-07-30 14:17:56,518: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:17:56,518: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:18:00,945: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad198>]}
2018-07-30 14:18:02,670: 14:18:02 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.63s]
2018-07-30 14:18:02,671: 14:18:02 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:18:02,672: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:18:02,679: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:18:02,682: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:18:02,682: Re-using an available connection from the pool.
2018-07-30 14:18:02,854: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:18:02,855: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:18:07,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f1b00>]}
2018-07-30 14:18:07,566: 14:18:07 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.60s]
2018-07-30 14:18:07,567: 14:18:07 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:18:07,567: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:18:07,580: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:18:07,583: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:18:07,583: Re-using an available connection from the pool.
2018-07-30 14:18:07,712: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:18:07,713: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:18:15,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad198>]}
2018-07-30 14:18:16,153: 14:18:16 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.17s]
2018-07-30 14:18:16,154: 14:18:16 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:18:16,154: 14:18:16 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:18:16,155: 14:18:16 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:18:16,155: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:18:16,156: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:18:16,156: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:18:16,168: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:18:16,174: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:18:16,186: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:18:16,188: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:18:16,188: Re-using an available connection from the pool.
2018-07-30 14:18:16,190: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:18:16,191: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:18:16,192: Re-using an available connection from the pool.
2018-07-30 14:18:16,194: Re-using an available connection from the pool.
2018-07-30 14:18:16,388: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:18:16,396: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:18:16,397: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:18:16,397: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:18:16,412: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:18:16,413: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:18:21,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105218128>]}
2018-07-30 14:18:22,524: 14:18:22 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 5.12s]
2018-07-30 14:18:28,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f1b00>]}
2018-07-30 14:18:29,332: 14:18:29 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.78s]
2018-07-30 14:18:42,150: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052aa358>]}
2018-07-30 14:18:42,996: 14:18:42 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 25.99s]
2018-07-30 14:18:42,997: 14:18:42 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:18:42,997: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:18:43,010: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:18:43,012: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:18:43,013: Re-using an available connection from the pool.
2018-07-30 14:18:43,242: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:18:43,242: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:19:13,142: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a630>]}
2018-07-30 14:19:14,502: 14:19:14 | 18 of 23 OK created table model template.customers_proc.............. [OK in 30.14s]
2018-07-30 14:19:14,503: 14:19:14 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:19:14,503: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:19:14,513: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:19:14,515: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:19:14,515: Re-using an available connection from the pool.
2018-07-30 14:19:15,085: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:19:15,086: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:19:43,383: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102683080>]}
2018-07-30 14:19:44,711: 14:19:44 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 28.88s]
2018-07-30 14:19:44,712: 14:19:44 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:19:44,712: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:19:44,726: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:19:44,729: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:19:44,729: Re-using an available connection from the pool.
2018-07-30 14:19:44,916: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:19:44,917: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
max(newness_segment) newness_segment,	
max(newness_segment_prev) newness_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 14:20:10,732: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a630>]}
2018-07-30 14:20:11,913: 14:20:11 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 26.02s]
2018-07-30 14:20:11,915: 14:20:11 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:20:11,915: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:20:11,928: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:20:11,930: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:20:11,930: Re-using an available connection from the pool.
2018-07-30 14:20:12,277: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:20:12,278: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 14:20:17,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026530b8>]}
2018-07-30 14:20:19,196: 14:20:19 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.62s]
2018-07-30 14:20:19,197: 14:20:19 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:20:19,197: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:20:19,206: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:20:19,208: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:20:19,208: Re-using an available connection from the pool.
2018-07-30 14:20:19,479: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:20:19,479: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
segment_prev,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	segment_prev,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:20:22,216: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a630>]}
2018-07-30 14:20:22,763: 14:20:22 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 3.02s]
2018-07-30 14:20:22,765: 14:20:22 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:20:22,765: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:20:22,773: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:20:22,775: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:20:22,775: Re-using an available connection from the pool.
2018-07-30 14:20:22,953: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:20:22,954: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:20:56,283: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026530b8>]}
2018-07-30 14:20:56,793: 14:20:56 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 33.52s]
2018-07-30 14:20:56,837: 14:20:56 | 
2018-07-30 14:20:56,837: 14:20:56 | Finished running 23 table models in 235.14s.
2018-07-30 14:20:56,838: Connection 'master' was left open.
2018-07-30 14:20:56,839: 
2018-07-30 14:20:56,839: Completed successfully
2018-07-30 14:20:56,839: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 14:20:56,840: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10524b4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105250a90>]}
2018-07-30 14:20:57,475: Flushing usage events
2018-07-30 14:20:57,645: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55548), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,645: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55546), raddr=('172.217.3.10', 443)>

2018-07-30 14:20:57,646: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55545), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,646: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55554), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,647: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55555), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,647: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55552), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,648: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55549), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,648: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55553), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,649: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55550), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,649: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55551), raddr=('172.217.1.205', 443)>

2018-07-30 14:44:45,491: Tracking: tracking
2018-07-30 14:44:45,504: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cc18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cf28>]}
2018-07-30 14:44:46,529: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:44:46,576: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:44:46,582: Parsing get_column_values.sql
2018-07-30 14:44:46,610: Parsing get_url_parameter.sql
2018-07-30 14:44:46,622: Parsing split_part.sql
2018-07-30 14:44:46,633: Parsing table_exists.sql
2018-07-30 14:44:46,647: Parsing core.sql
2018-07-30 14:44:46,681: Parsing adapters/bigquery.sql
2018-07-30 14:44:46,701: Parsing adapters/common.sql
2018-07-30 14:44:46,741: Parsing adapters/redshift.sql
2018-07-30 14:44:46,778: Parsing adapters/snowflake.sql
2018-07-30 14:44:46,789: Parsing etc/bigquery.sql
2018-07-30 14:44:46,794: Parsing etc/datetime.sql
2018-07-30 14:44:46,835: Parsing etc/get_custom_schema.sql
2018-07-30 14:44:46,849: Parsing materializations/helpers.sql
2018-07-30 14:44:46,885: Parsing materializations/archive/archive.sql
2018-07-30 14:44:46,975: Parsing materializations/incremental/incremental.sql
2018-07-30 14:44:47,040: Parsing materializations/seed/bigquery.sql
2018-07-30 14:44:47,049: Parsing materializations/seed/seed.sql
2018-07-30 14:44:47,124: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:44:47,166: Parsing materializations/table/table.sql
2018-07-30 14:44:47,194: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:44:47,210: Parsing materializations/view/view.sql
2018-07-30 14:44:47,237: Parsing schema_tests/accepted_values.sql
2018-07-30 14:44:47,244: Parsing schema_tests/not_null.sql
2018-07-30 14:44:47,249: Parsing schema_tests/relationships.sql
2018-07-30 14:44:47,256: Parsing schema_tests/unique.sql
2018-07-30 14:44:47,347: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:44:47,350: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:44:47,354: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:44:47,356: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:44:47,359: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:44:47,373: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:44:47,422: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:44:47,437: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:44:47,452: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:44:47,463: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:44:47,473: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:44:47,477: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:44:47,482: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:44:47,486: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:44:47,489: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:44:47,493: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:44:47,497: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:44:47,503: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:44:47,508: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:44:47,514: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:44:47,517: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:44:47,524: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:44:47,556: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:44:47,581: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:44:47,592: 
2018-07-30 14:44:47,602: Acquiring new bigquery connection "master".
2018-07-30 14:44:47,602: Opening a new connection (0 currently allocated)
2018-07-30 14:44:49,791: 14:44:49 | Concurrency: 4 threads (target='template')
2018-07-30 14:44:49,791: 14:44:49 | 
2018-07-30 14:44:49,956: 14:44:49 | 1 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:44:49,958: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:44:49,957: 14:44:49 | 2 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:44:49,964: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:44:49,957: 14:44:49 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:44:49,971: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:44:49,957: 14:44:49 | 4 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:44:49,982: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:44:49,981: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:44:49,978: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:44:49,997: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:44:50,002: Acquiring new bigquery connection "all_dates".
2018-07-30 14:44:50,002: Opening a new connection (1 currently allocated)
2018-07-30 14:44:50,010: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:44:50,010: Opening a new connection (2 currently allocated)
2018-07-30 14:44:50,015: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:44:50,020: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:44:50,020: Opening a new connection (3 currently allocated)
2018-07-30 14:44:50,032: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:44:50,035: Opening a new connection (4 currently allocated)
2018-07-30 14:44:51,415: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:44:51,452: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:44:51,471: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:44:51,477: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:44:51,473: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:44:51,515: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:44:51,516: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:44:51,517: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:44:53,194: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e642860>]}
2018-07-30 14:44:53,224: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89cb70>]}
2018-07-30 14:44:53,498: 14:44:53 | 4 of 23 OK created table model template.all_dates.................... [OK in 3.21s]
2018-07-30 14:44:53,519: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7d7b70>]}
2018-07-30 14:44:53,557: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e786e48>]}
2018-07-30 14:44:53,802: 14:44:53 | 3 of 23 OK created table model template.monthend_dates............... [OK in 3.25s]
2018-07-30 14:44:54,134: 14:44:54 | 1 of 23 OK created table model template.stores_proc.................. [OK in 3.56s]
2018-07-30 14:44:54,469: 14:44:54 | 2 of 23 OK created table model template.mappings_ga_proc............. [OK in 3.59s]
2018-07-30 14:44:54,470: 14:44:54 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:44:54,471: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:44:54,475: 14:44:54 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:44:54,476: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:44:54,475: 14:44:54 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:44:54,487: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:44:54,508: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:44:54,512: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:44:54,523: Re-using an available connection from the pool.
2018-07-30 14:44:54,523: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:44:54,521: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:44:54,527: Re-using an available connection from the pool.
2018-07-30 14:44:54,528: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:44:54,528: Re-using an available connection from the pool.
2018-07-30 14:44:54,528: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:44:56,040: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:44:56,186: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:44:56,187: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:44:56,296: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:44:56,472: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:44:56,472: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:44:56,585: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:44:56,721: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:44:56,722: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:44:58,652: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b4080>]}
2018-07-30 14:44:59,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85b048>]}
2018-07-30 14:44:59,901: 14:44:59 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.17s]
2018-07-30 14:45:00,561: 14:45:00 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 5.42s]
2018-07-30 14:45:00,840: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:45:01,131: 14:45:01 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.37s]
2018-07-30 14:45:01,131: 14:45:01 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:45:01,132: 14:45:01 | 9 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:45:01,132: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:45:01,132: 14:45:01 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 14:45:01,133: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:45:01,144: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:45:01,153: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:45:01,185: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:45:01,190: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:45:01,193: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:45:01,194: Re-using an available connection from the pool.
2018-07-30 14:45:01,194: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:45:01,197: Re-using an available connection from the pool.
2018-07-30 14:45:01,198: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:45:01,201: Re-using an available connection from the pool.
2018-07-30 14:45:01,341: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:45:01,346: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:45:01,945: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:45:02,091: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:45:02,091: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:45:02,690: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:45:02,842: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:45:02,844: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:45:04,247: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b0710>]}
2018-07-30 14:45:04,570: 14:45:04 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.10s]
2018-07-30 14:45:05,274: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85b2e8>]}
2018-07-30 14:45:05,567: 14:45:05 | 9 of 23 OK created table model template.agg_customers................ [OK in 4.14s]
2018-07-30 14:45:29,909: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:45:30,239: 14:45:30 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 28.78s]
2018-07-30 14:45:30,241: 14:45:30 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:45:30,241: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:45:30,262: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:45:30,262: Re-using an available connection from the pool.
2018-07-30 14:45:30,262: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:45:31,064: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:45:31,207: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:45:31,208: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:45:40,345: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:45:40,705: 14:45:40 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 10.10s]
2018-07-30 14:45:40,706: 14:45:40 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:45:40,706: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:45:40,720: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:45:40,734: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:45:40,734: Re-using an available connection from the pool.
2018-07-30 14:45:40,917: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:45:40,918: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:45:45,592: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:45:46,384: 14:45:46 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.89s]
2018-07-30 14:45:46,384: 14:45:46 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:45:46,385: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:45:46,391: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:45:46,393: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:45:46,393: Re-using an available connection from the pool.
2018-07-30 14:45:46,568: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:45:46,569: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:45:50,089: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:45:50,962: 14:45:50 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.70s]
2018-07-30 14:45:50,963: 14:45:50 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:45:50,963: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:45:50,971: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:45:50,973: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:45:50,973: Re-using an available connection from the pool.
2018-07-30 14:45:51,108: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:45:51,109: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:45:59,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:46:00,160: 14:46:00 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.87s]
2018-07-30 14:46:00,161: 14:46:00 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:46:00,161: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:46:00,176: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:46:00,172: 14:46:00 | 16 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:46:00,172: 14:46:00 | 17 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:46:00,177: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:46:00,177: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:46:00,183: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:46:00,190: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:46:00,192: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:46:00,194: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:46:00,194: Re-using an available connection from the pool.
2018-07-30 14:46:00,199: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:46:00,199: Re-using an available connection from the pool.
2018-07-30 14:46:00,202: Re-using an available connection from the pool.
2018-07-30 14:46:00,349: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:46:00,355: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:46:00,373: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:46:00,374: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:46:00,374: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:46:00,378: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:46:05,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e874978>]}
2018-07-30 14:46:06,035: 14:46:06 | 17 of 23 OK created table model template.monthly_cohort_stats........ [OK in 5.07s]
2018-07-30 14:46:12,347: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:46:12,662: 14:46:12 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.19s]
2018-07-30 14:46:26,903: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85ba20>]}
2018-07-30 14:46:27,212: 14:46:27 | 16 of 23 OK created table model template.customers_proc_yoy.......... [OK in 26.73s]
2018-07-30 14:46:27,213: 14:46:27 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:46:27,214: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:46:27,222: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:46:27,225: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:46:27,225: Re-using an available connection from the pool.
2018-07-30 14:46:27,382: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:46:27,383: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:46:57,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:46:58,572: 14:46:58 | 18 of 23 OK created table model template.customers_proc.............. [OK in 30.46s]
2018-07-30 14:46:58,573: 14:46:58 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:46:58,573: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:46:58,584: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:46:58,589: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:46:58,589: Re-using an available connection from the pool.
2018-07-30 14:46:58,715: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:46:58,716: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:47:25,562: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e66dc18>]}
2018-07-30 14:47:25,879: 14:47:25 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 26.99s]
2018-07-30 14:47:25,880: 14:47:25 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:47:25,880: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:47:25,891: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:47:25,895: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:47:25,895: Re-using an available connection from the pool.
2018-07-30 14:47:26,050: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:47:26,050: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newne
  );

    
2018-07-30 14:47:26,634: Bad request while running:
create dataset
2018-07-30 14:47:26,634: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/803bbb36-3409-4af5-8d37-c5bd6ff1fe30?maxResults=0: Unrecognized name: newne at [137:37]
2018-07-30 14:47:26,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7a9b38>]}
2018-07-30 14:47:26,927: 14:47:26 | 20 of 23 ERROR creating table model template.segment_stats_buyers_agg [ERROR in 0.75s]
2018-07-30 14:47:26,928: 14:47:26 | 21 of 23 SKIP relation template.segment_stats_buyers_view............ [SKIP]
2018-07-30 14:47:26,929: 14:47:26 | 22 of 23 SKIP relation template.buyer_segment_stats.................. [SKIP]
2018-07-30 14:47:26,929: 14:47:26 | 23 of 23 SKIP relation template.buyer_segment_lists.................. [SKIP]
2018-07-30 14:47:27,025: 14:47:27 | 
2018-07-30 14:47:27,025: 14:47:27 | Finished running 23 table models in 159.43s.
2018-07-30 14:47:27,026: Connection 'master' was left open.
2018-07-30 14:47:27,026: 
2018-07-30 14:47:27,026: Completed with 1 errors:
2018-07-30 14:47:27,027: 
2018-07-30 14:47:27,027: Database Error in model segment_stats_buyers_agg (models/math/buyer-segmentation/segment_stats_buyers_agg.sql)
2018-07-30 14:47:27,027:   Unrecognized name: newne at [137:37]
2018-07-30 14:47:27,027:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/segment_stats_buyers_agg.sql
2018-07-30 14:47:27,028: 
Done. PASS=19 ERROR=1 SKIP=3 TOTAL=23
2018-07-30 14:47:27,028: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e63e4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7d79e8>]}
2018-07-30 14:47:27,316: Flushing usage events
2018-07-30 14:47:27,608: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55713), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,609: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55705), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,609: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55719), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,610: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55721), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,610: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55720), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,611: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55718), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,611: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55715), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,611: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55714), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,612: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55717), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,612: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55716), raddr=('172.217.2.13', 443)>

2018-07-30 14:48:34,321: Tracking: tracking
2018-07-30 14:48:34,323: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cd278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cd588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cdf28>]}
2018-07-30 14:48:36,217: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:48:36,253: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:48:36,260: Parsing get_column_values.sql
2018-07-30 14:48:36,277: Parsing get_url_parameter.sql
2018-07-30 14:48:36,284: Parsing split_part.sql
2018-07-30 14:48:36,294: Parsing table_exists.sql
2018-07-30 14:48:36,304: Parsing core.sql
2018-07-30 14:48:36,319: Parsing adapters/bigquery.sql
2018-07-30 14:48:36,329: Parsing adapters/common.sql
2018-07-30 14:48:36,361: Parsing adapters/redshift.sql
2018-07-30 14:48:36,385: Parsing adapters/snowflake.sql
2018-07-30 14:48:36,391: Parsing etc/bigquery.sql
2018-07-30 14:48:36,395: Parsing etc/datetime.sql
2018-07-30 14:48:36,425: Parsing etc/get_custom_schema.sql
2018-07-30 14:48:36,439: Parsing materializations/helpers.sql
2018-07-30 14:48:36,466: Parsing materializations/archive/archive.sql
2018-07-30 14:48:36,508: Parsing materializations/incremental/incremental.sql
2018-07-30 14:48:36,552: Parsing materializations/seed/bigquery.sql
2018-07-30 14:48:36,566: Parsing materializations/seed/seed.sql
2018-07-30 14:48:36,629: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:48:36,675: Parsing materializations/table/table.sql
2018-07-30 14:48:36,717: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:48:36,732: Parsing materializations/view/view.sql
2018-07-30 14:48:36,755: Parsing schema_tests/accepted_values.sql
2018-07-30 14:48:36,762: Parsing schema_tests/not_null.sql
2018-07-30 14:48:36,766: Parsing schema_tests/relationships.sql
2018-07-30 14:48:36,772: Parsing schema_tests/unique.sql
2018-07-30 14:48:36,818: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:48:36,823: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:48:36,828: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:48:36,832: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:48:36,835: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:48:36,850: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:48:36,863: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:48:36,872: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:48:36,884: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:48:36,893: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:48:36,899: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:48:36,902: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:48:36,905: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:48:36,908: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:48:36,911: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:48:36,914: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:48:36,918: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:48:36,922: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:48:36,926: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:48:36,931: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:48:36,934: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:48:36,939: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:48:36,950: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:48:36,974: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:48:36,981: 
2018-07-30 14:48:36,990: Acquiring new bigquery connection "master".
2018-07-30 14:48:36,991: Opening a new connection (0 currently allocated)
2018-07-30 14:48:38,208: 14:48:38 | Concurrency: 4 threads (target='template')
2018-07-30 14:48:38,209: 14:48:38 | 
2018-07-30 14:48:38,302: 14:48:38 | 1 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:48:38,303: 14:48:38 | 2 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:48:38,303: 14:48:38 | 3 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:48:38,303: 14:48:38 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:48:38,303: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:48:38,304: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:48:38,304: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:48:38,304: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:48:38,311: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:48:38,315: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:48:38,327: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:48:38,328: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:48:38,334: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:48:38,336: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:48:38,336: Opening a new connection (1 currently allocated)
2018-07-30 14:48:38,338: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:48:38,339: Acquiring new bigquery connection "all_dates".
2018-07-30 14:48:38,341: Opening a new connection (2 currently allocated)
2018-07-30 14:48:38,352: Opening a new connection (3 currently allocated)
2018-07-30 14:48:38,357: Opening a new connection (4 currently allocated)
2018-07-30 14:48:38,874: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:48:38,875: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:48:38,929: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:48:38,938: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:48:38,958: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:48:38,958: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:48:38,994: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:48:38,995: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:48:40,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768bef0>]}
2018-07-30 14:48:40,685: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768bba8>]}
2018-07-30 14:48:40,702: 14:48:40 | 2 of 23 OK created table model template.all_dates.................... [OK in 2.06s]
2018-07-30 14:48:40,874: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768b908>]}
2018-07-30 14:48:41,051: 14:48:41 | 1 of 23 OK created table model template.monthend_dates............... [OK in 2.38s]
2018-07-30 14:48:41,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768bf98>]}
2018-07-30 14:48:41,409: 14:48:41 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.57s]
2018-07-30 14:48:41,797: 14:48:41 | 3 of 23 OK created table model template.stores_proc.................. [OK in 2.96s]
2018-07-30 14:48:41,798: 14:48:41 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:48:41,798: 14:48:41 | 6 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:48:41,799: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:48:41,798: 14:48:41 | 7 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:48:41,804: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:48:41,799: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:48:41,826: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:48:41,832: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:48:41,833: Re-using an available connection from the pool.
2018-07-30 14:48:41,840: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:48:41,840: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:41,841: Re-using an available connection from the pool.
2018-07-30 14:48:41,842: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:41,846: Re-using an available connection from the pool.
2018-07-30 14:48:41,846: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:43,367: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:48:43,519: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:48:43,526: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:48:43,527: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:48:43,704: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:48:43,705: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:48:44,990: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:48:45,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1d3a58>]}
2018-07-30 14:48:45,625: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:48:45,626: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:48:46,403: 14:48:46 | 6 of 23 OK created table model template.shopify_refunds_proc......... [OK in 3.81s]
2018-07-30 14:48:48,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d997b8>]}
2018-07-30 14:48:49,213: 14:48:49 | 7 of 23 OK created table model template.shopify_discounts_proc....... [OK in 7.00s]
2018-07-30 14:48:49,871: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a290940>]}
2018-07-30 14:48:50,237: 14:48:50 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 8.07s]
2018-07-30 14:48:50,238: 14:48:50 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:48:50,239: 14:48:50 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 14:48:50,239: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:48:50,239: 14:48:50 | 10 of 23 START table model template.agg_customers.................... [RUN]
2018-07-30 14:48:50,240: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:48:50,245: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:48:50,255: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:48:50,276: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:48:50,277: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:48:50,277: Re-using an available connection from the pool.
2018-07-30 14:48:50,278: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:50,278: Re-using an available connection from the pool.
2018-07-30 14:48:50,280: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:48:50,280: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:50,282: Re-using an available connection from the pool.
2018-07-30 14:48:50,799: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:48:50,802: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:48:52,475: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:48:53,006: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:48:53,010: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:48:53,010: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:48:53,786: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:48:53,787: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:48:55,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d4ef0>]}
2018-07-30 14:48:56,001: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a218908>]}
2018-07-30 14:48:56,564: 14:48:56 | 10 of 23 OK created table model template.agg_customers............... [OK in 5.75s]
2018-07-30 14:48:56,897: 14:48:56 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 5.76s]
2018-07-30 14:49:19,775: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2aaf60>]}
2018-07-30 14:49:20,094: 14:49:20 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 29.54s]
2018-07-30 14:49:20,096: 14:49:20 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:49:20,096: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:49:20,116: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:49:20,116: Re-using an available connection from the pool.
2018-07-30 14:49:20,116: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:49:22,936: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:49:23,600: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:49:23,601: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:49:33,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a259390>]}
2018-07-30 14:49:33,844: 14:49:33 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 12.97s]
2018-07-30 14:49:33,845: 14:49:33 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:49:33,845: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:49:33,854: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:49:33,856: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:49:33,856: Re-using an available connection from the pool.
2018-07-30 14:49:34,321: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:49:34,322: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:49:39,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a258d30>]}
2018-07-30 14:49:40,966: 14:49:40 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 5.69s]
2018-07-30 14:49:40,967: 14:49:40 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:49:40,967: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:49:40,978: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:49:40,979: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:49:40,980: Re-using an available connection from the pool.
2018-07-30 14:49:41,637: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:49:41,638: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:49:45,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2c8240>]}
2018-07-30 14:49:45,922: 14:49:45 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.64s]
2018-07-30 14:49:45,923: 14:49:45 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:49:45,924: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:49:45,937: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:49:45,940: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:49:45,941: Re-using an available connection from the pool.
2018-07-30 14:49:46,060: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:49:46,060: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:49:54,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2c8e80>]}
2018-07-30 14:49:54,942: 14:49:54 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.71s]
2018-07-30 14:49:54,943: 14:49:54 | 15 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:49:54,944: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:49:54,952: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:49:54,944: 14:49:54 | 16 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:49:54,952: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:49:54,944: 14:49:54 | 17 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:49:54,961: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:49:54,962: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:49:54,963: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:49:54,971: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:49:54,971: Re-using an available connection from the pool.
2018-07-30 14:49:54,972: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:49:54,973: Re-using an available connection from the pool.
2018-07-30 14:49:54,985: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:49:54,986: Re-using an available connection from the pool.
2018-07-30 14:49:55,134: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:49:55,141: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:49:55,153: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:49:55,154: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:49:55,181: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:49:55,182: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:49:59,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2398d0>]}
2018-07-30 14:50:00,474: 14:50:00 | 17 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.89s]
2018-07-30 14:50:07,742: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a258908>]}
2018-07-30 14:50:08,050: 14:50:08 | 16 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.79s]
2018-07-30 14:50:16,873: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2c8b38>]}
2018-07-30 14:50:17,171: 14:50:17 | 15 of 23 OK created table model template.customers_proc_yoy.......... [OK in 21.93s]
2018-07-30 14:50:17,172: 14:50:17 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:50:17,172: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:50:17,184: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:50:17,189: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:50:17,189: Re-using an available connection from the pool.
2018-07-30 14:50:17,322: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:50:17,323: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:50:41,612: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763eeb8>]}
2018-07-30 14:50:42,948: 14:50:42 | 18 of 23 OK created table model template.customers_proc.............. [OK in 24.44s]
2018-07-30 14:50:42,949: 14:50:42 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:50:42,950: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:50:42,958: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:50:42,960: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:50:42,961: Re-using an available connection from the pool.
2018-07-30 14:50:43,105: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:50:43,106: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:51:14,220: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763e438>]}
2018-07-30 14:51:14,655: 14:51:14 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 31.27s]
2018-07-30 14:51:14,655: 14:51:14 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:51:14,656: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:51:14,666: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:51:14,668: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:51:14,669: Re-using an available connection from the pool.
2018-07-30 14:51:15,024: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:51:15,025: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 14:51:53,228: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108716048>]}
2018-07-30 14:51:55,150: 14:51:55 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 38.57s]
2018-07-30 14:51:55,151: 14:51:55 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:51:55,151: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:51:55,171: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:51:55,174: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:51:55,175: Re-using an available connection from the pool.
2018-07-30 14:51:56,331: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:51:56,334: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 14:52:01,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a19c5f8>]}
2018-07-30 14:52:01,399: 14:52:01 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.96s]
2018-07-30 14:52:01,400: 14:52:01 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:52:01,401: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:52:01,410: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:52:01,412: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:52:01,413: Re-using an available connection from the pool.
2018-07-30 14:52:01,682: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:52:01,683: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:52:03,555: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108716048>]}
2018-07-30 14:52:04,343: 14:52:04 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.15s]
2018-07-30 14:52:04,344: 14:52:04 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:52:04,345: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:52:04,359: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:52:04,362: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:52:04,362: Re-using an available connection from the pool.
2018-07-30 14:52:04,515: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:52:04,516: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:52:36,255: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a239cc0>]}
2018-07-30 14:52:36,587: 14:52:36 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 31.91s]
2018-07-30 14:52:36,609: 14:52:36 | 
2018-07-30 14:52:36,609: 14:52:36 | Finished running 23 table models in 239.63s.
2018-07-30 14:52:36,609: Connection 'master' was left open.
2018-07-30 14:52:36,610: 
2018-07-30 14:52:36,610: Completed successfully
2018-07-30 14:52:36,610: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 14:52:36,611: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1d0518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a20a9e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a20acc0>]}
2018-07-30 14:52:36,911: Flushing usage events
2018-07-30 14:52:37,134: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56249), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,135: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56248), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,136: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56257), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,136: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56254), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,139: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56250), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,139: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56251), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,140: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56255), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,141: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56256), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,141: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56252), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,142: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56253), raddr=('172.217.2.13', 443)>

2018-07-30 15:14:21,706: Tracking: tracking
2018-07-30 15:14:21,708: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133ed2e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133ed400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133ede80>]}
2018-07-30 15:14:23,275: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:14:23,309: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:14:23,318: Parsing get_column_values.sql
2018-07-30 15:14:23,339: Parsing get_url_parameter.sql
2018-07-30 15:14:23,345: Parsing split_part.sql
2018-07-30 15:14:23,353: Parsing table_exists.sql
2018-07-30 15:14:23,364: Parsing core.sql
2018-07-30 15:14:23,380: Parsing adapters/bigquery.sql
2018-07-30 15:14:23,395: Parsing adapters/common.sql
2018-07-30 15:14:23,428: Parsing adapters/redshift.sql
2018-07-30 15:14:23,448: Parsing adapters/snowflake.sql
2018-07-30 15:14:23,454: Parsing etc/bigquery.sql
2018-07-30 15:14:23,459: Parsing etc/datetime.sql
2018-07-30 15:14:23,490: Parsing etc/get_custom_schema.sql
2018-07-30 15:14:23,498: Parsing materializations/helpers.sql
2018-07-30 15:14:23,518: Parsing materializations/archive/archive.sql
2018-07-30 15:14:23,566: Parsing materializations/incremental/incremental.sql
2018-07-30 15:14:23,609: Parsing materializations/seed/bigquery.sql
2018-07-30 15:14:23,619: Parsing materializations/seed/seed.sql
2018-07-30 15:14:23,687: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:14:23,725: Parsing materializations/table/table.sql
2018-07-30 15:14:23,751: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:14:23,765: Parsing materializations/view/view.sql
2018-07-30 15:14:23,787: Parsing schema_tests/accepted_values.sql
2018-07-30 15:14:23,793: Parsing schema_tests/not_null.sql
2018-07-30 15:14:23,797: Parsing schema_tests/relationships.sql
2018-07-30 15:14:23,804: Parsing schema_tests/unique.sql
2018-07-30 15:14:23,847: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:14:23,850: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:14:23,853: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:14:23,855: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:14:23,857: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:14:23,867: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:14:23,875: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:14:23,881: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:14:23,892: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:14:23,901: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:14:23,907: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:14:23,910: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:14:23,914: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:14:23,916: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:14:23,919: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:14:23,922: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:14:23,925: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:14:23,929: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:14:23,933: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:14:23,938: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:14:23,941: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:14:23,946: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:14:23,957: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:14:23,975: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:14:23,982: 
2018-07-30 15:14:23,989: Acquiring new bigquery connection "master".
2018-07-30 15:14:23,989: Opening a new connection (0 currently allocated)
2018-07-30 15:14:25,426: 15:14:25 | Concurrency: 4 threads (target='template')
2018-07-30 15:14:25,426: 15:14:25 | 
2018-07-30 15:14:25,494: 15:14:25 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:14:25,494: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:14:25,499: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:14:25,494: 15:14:25 | 2 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:14:25,494: 15:14:25 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:14:25,494: 15:14:25 | 4 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:14:25,500: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:14:25,500: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:14:25,500: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:14:25,506: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:14:25,510: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:14:25,518: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:14:25,520: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:14:25,522: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:14:25,522: Opening a new connection (1 currently allocated)
2018-07-30 15:14:25,526: Acquiring new bigquery connection "all_dates".
2018-07-30 15:14:25,529: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:14:25,538: Opening a new connection (2 currently allocated)
2018-07-30 15:14:25,542: Opening a new connection (3 currently allocated)
2018-07-30 15:14:25,546: Opening a new connection (4 currently allocated)
2018-07-30 15:14:25,975: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:14:25,991: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:14:26,002: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:14:26,003: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:14:26,009: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:14:26,015: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:14:26,015: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:14:26,028: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:14:27,802: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113535438>]}
2018-07-30 15:14:27,965: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113535a58>]}
2018-07-30 15:14:28,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113583ef0>]}
2018-07-30 15:14:28,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113535080>]}
2018-07-30 15:14:28,108: 15:14:28 | 2 of 23 OK created table model template.monthend_dates............... [OK in 2.30s]
2018-07-30 15:14:28,415: 15:14:28 | 4 of 23 OK created table model template.stores_proc.................. [OK in 2.46s]
2018-07-30 15:14:28,719: 15:14:28 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.57s]
2018-07-30 15:14:29,023: 15:14:29 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.58s]
2018-07-30 15:14:29,024: 15:14:29 | 5 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:14:29,024: 15:14:29 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:14:29,025: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:14:29,025: 15:14:29 | 7 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:14:29,025: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:14:29,032: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:14:29,046: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:14:29,069: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:14:29,074: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:14:29,074: Re-using an available connection from the pool.
2018-07-30 15:14:29,074: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:29,074: Re-using an available connection from the pool.
2018-07-30 15:14:29,077: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:29,077: Re-using an available connection from the pool.
2018-07-30 15:14:29,078: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:30,608: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:14:30,612: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:14:30,977: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:14:30,977: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:14:30,978: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:14:30,978: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:14:31,308: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:14:31,498: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:14:31,499: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:14:33,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695c50>]}
2018-07-30 15:14:33,544: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11361b550>]}
2018-07-30 15:14:34,118: 15:14:34 | 5 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.19s]
2018-07-30 15:14:34,419: 15:14:34 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.52s]
2018-07-30 15:14:36,528: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695240>]}
2018-07-30 15:14:36,837: 15:14:36 | 7 of 23 OK created table model template.shopify_customers_proc....... [OK in 7.50s]
2018-07-30 15:14:36,838: 15:14:36 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 15:14:36,839: 15:14:36 | 9 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 15:14:36,839: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:14:36,839: 15:14:36 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 15:14:36,839: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:14:36,850: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:14:36,856: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:14:36,872: Re-using an available connection from the pool.
2018-07-30 15:14:36,873: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:36,867: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:14:36,872: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:14:36,881: Re-using an available connection from the pool.
2018-07-30 15:14:36,881: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:36,877: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:14:36,882: Re-using an available connection from the pool.
2018-07-30 15:14:37,033: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:14:37,035: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:14:37,588: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:14:37,748: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:14:37,754: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:14:38,654: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:14:38,821: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:14:38,821: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:14:40,333: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136239b0>]}
2018-07-30 15:14:40,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695898>]}
2018-07-30 15:14:41,017: 15:14:41 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.48s]
2018-07-30 15:14:41,812: 15:14:41 | 9 of 23 OK created table model template.agg_customers................ [OK in 3.85s]
2018-07-30 15:15:04,363: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b96a0>]}
2018-07-30 15:15:04,693: 15:15:04 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 27.52s]
2018-07-30 15:15:04,694: 15:15:04 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:15:04,695: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:15:04,731: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:15:04,731: Re-using an available connection from the pool.
2018-07-30 15:15:04,731: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:15:05,445: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:15:05,668: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:15:05,669: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:15:16,584: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695240>]}
2018-07-30 15:15:16,894: 15:15:16 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.89s]
2018-07-30 15:15:16,895: 15:15:16 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:15:16,896: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:15:16,908: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:15:16,913: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:15:16,913: Re-using an available connection from the pool.
2018-07-30 15:15:17,109: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:15:17,110: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:15:21,940: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11366a048>]}
2018-07-30 15:15:22,231: 15:15:22 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 5.04s]
2018-07-30 15:15:22,231: 15:15:22 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:15:22,232: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:15:22,241: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:15:22,243: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:15:22,244: Re-using an available connection from the pool.
2018-07-30 15:15:22,411: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:15:22,416: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:15:26,206: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136464e0>]}
2018-07-30 15:15:27,692: 15:15:27 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.97s]
2018-07-30 15:15:27,693: 15:15:27 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:15:27,693: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:15:27,703: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:15:27,707: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:15:27,707: Re-using an available connection from the pool.
2018-07-30 15:15:27,923: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:15:27,926: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:15:36,620: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11366a048>]}
2018-07-30 15:15:36,997: 15:15:36 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.93s]
2018-07-30 15:15:36,998: 15:15:36 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:15:36,998: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:15:37,009: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:15:36,999: 15:15:36 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:15:37,009: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:15:36,999: 15:15:36 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:15:37,011: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:15:37,019: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:15:37,026: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:15:37,029: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:15:37,032: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:15:37,037: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:15:37,037: Re-using an available connection from the pool.
2018-07-30 15:15:37,038: Re-using an available connection from the pool.
2018-07-30 15:15:37,044: Re-using an available connection from the pool.
2018-07-30 15:15:37,379: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:15:37,384: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:15:37,391: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:15:37,411: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:15:37,413: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:15:37,420: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:15:41,838: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113563550>]}
2018-07-30 15:15:42,191: 15:15:42 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.83s]
2018-07-30 15:15:50,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136464e0>]}
2018-07-30 15:15:50,813: 15:15:50 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 13.24s]
2018-07-30 15:15:58,976: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a57828>]}
2018-07-30 15:15:59,268: 15:15:59 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 21.97s]
2018-07-30 15:15:59,270: 15:15:59 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:15:59,271: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:15:59,280: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:15:59,283: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:15:59,283: Re-using an available connection from the pool.
2018-07-30 15:15:59,410: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:15:59,412: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:16:25,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a621d0>]}
2018-07-30 15:16:27,228: 15:16:27 | 18 of 23 OK created table model template.customers_proc.............. [OK in 26.61s]
2018-07-30 15:16:27,230: 15:16:27 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:16:27,231: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:16:27,253: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:16:27,259: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:16:27,259: Re-using an available connection from the pool.
2018-07-30 15:16:27,408: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:16:27,410: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:16:53,775: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6aa58>]}
2018-07-30 15:16:55,067: 15:16:55 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 26.54s]
2018-07-30 15:16:55,067: 15:16:55 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:16:55,068: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:16:55,087: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:16:55,089: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:16:55,089: Re-using an available connection from the pool.
2018-07-30 15:16:55,481: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:16:55,481: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:17:37,049: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a29898>]}
2018-07-30 15:17:37,467: 15:17:37 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 41.98s]
2018-07-30 15:17:37,469: 15:17:37 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:17:37,469: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:17:37,500: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:17:37,505: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:17:37,506: Re-using an available connection from the pool.
2018-07-30 15:17:37,664: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:17:37,665: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:17:41,733: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6a6a0>]}
2018-07-30 15:17:42,375: 15:17:42 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 4.26s]
2018-07-30 15:17:42,376: 15:17:42 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:17:42,376: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:17:42,383: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:17:42,385: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:17:42,385: Re-using an available connection from the pool.
2018-07-30 15:17:42,513: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:17:42,514: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
frequency,
revenue,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:17:44,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6a320>]}
2018-07-30 15:17:44,637: 15:17:44 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 1.97s]
2018-07-30 15:17:44,637: 15:17:44 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:17:44,637: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:17:44,645: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:17:44,647: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:17:44,647: Re-using an available connection from the pool.
2018-07-30 15:17:44,762: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:17:44,762: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 15:18:23,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a3e8d0>]}
2018-07-30 15:18:24,055: 15:18:24 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 38.63s]
2018-07-30 15:18:24,162: 15:18:24 | 
2018-07-30 15:18:24,163: 15:18:24 | Finished running 23 table models in 240.18s.
2018-07-30 15:18:24,163: Connection 'master' was left open.
2018-07-30 15:18:24,163: 
2018-07-30 15:18:24,164: Completed successfully
2018-07-30 15:18:24,164: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:18:24,165: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135235c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113523a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113523390>]}
2018-07-30 15:18:24,529: Flushing usage events
2018-07-30 15:18:24,716: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56926), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,717: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56925), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,717: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56927), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,717: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56932), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,718: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56934), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,718: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56931), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,718: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56933), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,719: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56928), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,719: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56929), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,720: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56930), raddr=('172.217.2.13', 443)>

2018-07-30 15:35:17,310: Tracking: tracking
2018-07-30 15:35:17,311: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef2e208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef2e978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef2ed30>]}
2018-07-30 15:35:19,219: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:35:19,251: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:35:19,258: Parsing get_column_values.sql
2018-07-30 15:35:19,277: Parsing get_url_parameter.sql
2018-07-30 15:35:19,284: Parsing split_part.sql
2018-07-30 15:35:19,296: Parsing table_exists.sql
2018-07-30 15:35:19,315: Parsing core.sql
2018-07-30 15:35:19,342: Parsing adapters/bigquery.sql
2018-07-30 15:35:19,357: Parsing adapters/common.sql
2018-07-30 15:35:19,387: Parsing adapters/redshift.sql
2018-07-30 15:35:19,409: Parsing adapters/snowflake.sql
2018-07-30 15:35:19,415: Parsing etc/bigquery.sql
2018-07-30 15:35:19,421: Parsing etc/datetime.sql
2018-07-30 15:35:19,450: Parsing etc/get_custom_schema.sql
2018-07-30 15:35:19,460: Parsing materializations/helpers.sql
2018-07-30 15:35:19,481: Parsing materializations/archive/archive.sql
2018-07-30 15:35:19,521: Parsing materializations/incremental/incremental.sql
2018-07-30 15:35:19,563: Parsing materializations/seed/bigquery.sql
2018-07-30 15:35:19,572: Parsing materializations/seed/seed.sql
2018-07-30 15:35:19,630: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:35:19,666: Parsing materializations/table/table.sql
2018-07-30 15:35:19,693: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:35:19,709: Parsing materializations/view/view.sql
2018-07-30 15:35:19,738: Parsing schema_tests/accepted_values.sql
2018-07-30 15:35:19,747: Parsing schema_tests/not_null.sql
2018-07-30 15:35:19,752: Parsing schema_tests/relationships.sql
2018-07-30 15:35:19,758: Parsing schema_tests/unique.sql
2018-07-30 15:35:19,785: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:35:19,788: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:35:19,790: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:35:19,792: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:35:19,794: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:35:19,804: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:35:19,817: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:35:19,824: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:35:19,834: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:35:19,843: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:35:19,850: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:35:19,852: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:35:19,856: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:35:19,859: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:35:19,863: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:35:19,867: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:35:19,871: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:35:19,879: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:35:19,887: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:35:19,901: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:35:19,906: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:35:19,912: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:35:19,928: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:35:19,948: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:35:19,956: 
2018-07-30 15:35:19,963: Acquiring new bigquery connection "master".
2018-07-30 15:35:19,963: Opening a new connection (0 currently allocated)
2018-07-30 15:35:21,380: 15:35:21 | Concurrency: 4 threads (target='template')
2018-07-30 15:35:21,381: 15:35:21 | 
2018-07-30 15:35:21,466: 15:35:21 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:35:21,466: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:35:21,474: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:35:21,472: 15:35:21 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:35:21,472: 15:35:21 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:35:21,475: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:35:21,473: 15:35:21 | 4 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:35:21,475: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:35:21,480: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:35:21,480: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:35:21,503: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:35:21,506: Acquiring new bigquery connection "all_dates".
2018-07-30 15:35:21,506: Opening a new connection (1 currently allocated)
2018-07-30 15:35:21,522: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:35:21,525: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:35:21,525: Opening a new connection (2 currently allocated)
2018-07-30 15:35:21,530: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:35:21,532: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:35:21,535: Opening a new connection (3 currently allocated)
2018-07-30 15:35:21,541: Opening a new connection (4 currently allocated)
2018-07-30 15:35:21,988: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:35:22,000: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:35:22,007: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:35:22,017: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:35:22,024: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:35:22,043: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:35:22,046: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:35:22,046: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:35:23,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f032d30>]}
2018-07-30 15:35:23,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0e1eb8>]}
2018-07-30 15:35:24,172: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc7c940>]}
2018-07-30 15:35:24,282: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0c3e48>]}
2018-07-30 15:35:24,331: 15:35:24 | 4 of 23 OK created table model template.all_dates.................... [OK in 2.35s]
2018-07-30 15:35:27,305: 15:35:27 | 3 of 23 OK created table model template.monthend_dates............... [OK in 2.41s]
2018-07-30 15:35:28,089: 15:35:28 | 2 of 23 OK created table model template.stores_proc.................. [OK in 2.70s]
2018-07-30 15:35:28,876: 15:35:28 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.82s]
2018-07-30 15:35:28,877: 15:35:28 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:35:28,877: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:35:28,877: 15:35:28 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:35:28,879: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:35:28,888: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:35:28,877: 15:35:28 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:35:28,888: Re-using an available connection from the pool.
2018-07-30 15:35:28,896: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:35:28,897: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:35:28,897: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:28,897: Re-using an available connection from the pool.
2018-07-30 15:35:28,905: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:35:28,905: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:28,905: Re-using an available connection from the pool.
2018-07-30 15:35:28,909: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:30,611: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:35:30,613: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:35:30,787: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:35:30,788: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:35:30,789: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:35:30,795: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:35:30,929: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:35:31,253: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:35:31,253: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:35:33,299: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff90f0>]}
2018-07-30 15:35:33,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc9a9e8>]}
2018-07-30 15:35:33,618: 15:35:33 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.40s]
2018-07-30 15:35:34,334: 15:35:34 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.64s]
2018-07-30 15:35:35,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:35:36,390: 15:35:36 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.98s]
2018-07-30 15:35:36,391: 15:35:36 | 8 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 15:35:36,392: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:35:36,391: 15:35:36 | 9 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 15:35:36,391: 15:35:36 | 10 of 23 START table model template.agg_customers.................... [RUN]
2018-07-30 15:35:36,404: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:35:36,405: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:35:36,435: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:35:36,440: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:35:36,440: Re-using an available connection from the pool.
2018-07-30 15:35:36,441: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:35:36,441: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:36,443: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:35:36,443: Re-using an available connection from the pool.
2018-07-30 15:35:36,444: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:36,444: Re-using an available connection from the pool.
2018-07-30 15:35:36,752: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:35:36,760: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:35:37,523: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:35:37,764: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:35:37,765: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:35:38,144: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:35:38,337: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:35:38,338: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:35:40,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0c3e48>]}
2018-07-30 15:35:40,787: 15:35:40 | 8 of 23 OK created table model template.shopify_products_proc........ [OK in 3.70s]
2018-07-30 15:35:41,680: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc9a8d0>]}
2018-07-30 15:35:42,126: 15:35:42 | 10 of 23 OK created table model template.agg_customers............... [OK in 5.28s]
2018-07-30 15:36:03,132: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0b7160>]}
2018-07-30 15:36:03,461: 15:36:03 | 9 of 23 OK created table model template.ga_transactions.............. [OK in 26.73s]
2018-07-30 15:36:03,463: 15:36:03 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:36:03,463: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:36:03,488: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:36:03,488: Re-using an available connection from the pool.
2018-07-30 15:36:03,488: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:36:04,499: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:36:04,708: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:36:04,709: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:36:13,753: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:36:14,434: 15:36:14 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 10.29s]
2018-07-30 15:36:14,435: 15:36:14 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:36:14,436: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:36:14,449: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:36:14,452: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:36:14,452: Re-using an available connection from the pool.
2018-07-30 15:36:14,635: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:36:14,635: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:36:19,038: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd21fd0>]}
2018-07-30 15:36:19,896: 15:36:19 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.60s]
2018-07-30 15:36:19,900: 15:36:19 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:36:19,900: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:36:19,911: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:36:19,913: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:36:19,913: Re-using an available connection from the pool.
2018-07-30 15:36:20,068: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:36:20,069: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:36:25,189: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:36:25,977: 15:36:25 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 5.29s]
2018-07-30 15:36:25,978: 15:36:25 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:36:25,978: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:36:25,988: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:36:25,990: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:36:25,990: Re-using an available connection from the pool.
2018-07-30 15:36:26,170: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:36:26,171: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:36:34,816: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:36:35,606: 15:36:35 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.84s]
2018-07-30 15:36:35,607: 15:36:35 | 15 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:36:35,608: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:36:35,614: 15:36:35 | 16 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:36:35,618: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:36:35,618: 15:36:35 | 17 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:36:35,618: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:36:35,625: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:36:35,626: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:36:35,633: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:36:35,637: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:36:35,637: Re-using an available connection from the pool.
2018-07-30 15:36:35,639: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:36:35,640: Re-using an available connection from the pool.
2018-07-30 15:36:35,642: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:36:35,642: Re-using an available connection from the pool.
2018-07-30 15:36:35,917: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:36:35,950: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:36:35,965: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:36:35,979: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:36:35,991: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:36:35,993: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:36:41,519: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:36:41,806: 15:36:41 | 15 of 23 OK created table model template.monthly_cohort_stats........ [OK in 5.91s]
2018-07-30 15:36:49,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcb2470>]}
2018-07-30 15:36:49,825: 15:36:49 | 17 of 23 OK created table model template.customers_proc_qoq.......... [OK in 13.90s]
2018-07-30 15:37:00,370: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcb2240>]}
2018-07-30 15:37:01,013: 15:37:01 | 16 of 23 OK created table model template.customers_proc_yoy.......... [OK in 24.75s]
2018-07-30 15:37:01,014: 15:37:01 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:37:01,014: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:37:01,026: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:37:01,031: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:37:01,031: Re-using an available connection from the pool.
2018-07-30 15:37:01,393: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:37:01,393: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:37:27,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:37:29,205: 15:37:29 | 18 of 23 OK created table model template.customers_proc.............. [OK in 26.85s]
2018-07-30 15:37:29,208: 15:37:29 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:37:29,208: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:37:29,290: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:37:29,298: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:37:29,298: Re-using an available connection from the pool.
2018-07-30 15:37:29,684: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:37:29,684: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:37:58,154: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd560f0>]}
2018-07-30 15:37:59,593: 15:37:59 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 28.95s]
2018-07-30 15:37:59,599: 15:37:59 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:37:59,599: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:37:59,635: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:37:59,639: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:37:59,640: Re-using an available connection from the pool.
2018-07-30 15:37:59,912: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:37:59,913: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:38:43,057: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:38:44,535: 15:38:44 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 43.46s]
2018-07-30 15:38:44,572: 15:38:44 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:38:44,573: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:38:44,668: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:38:44,674: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:38:44,674: Re-using an available connection from the pool.
2018-07-30 15:38:45,177: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:38:45,178: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:38:50,830: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd5ef98>]}
2018-07-30 15:38:51,178: 15:38:51 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 6.26s]
2018-07-30 15:38:51,181: 15:38:51 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:38:51,181: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:38:51,229: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:38:51,277: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:38:51,281: Re-using an available connection from the pool.
2018-07-30 15:38:51,799: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:38:51,800: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:38:55,911: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:38:56,537: 15:38:56 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 4.73s]
2018-07-30 15:38:56,540: 15:38:56 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:38:56,540: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:38:56,557: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:38:56,560: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:38:56,560: Re-using an available connection from the pool.
2018-07-30 15:38:57,227: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:38:57,228: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 15:39:37,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca6e80>]}
2018-07-30 15:39:37,629: 15:39:37 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 40.76s]
2018-07-30 15:39:37,725: 15:39:37 | 
2018-07-30 15:39:37,726: 15:39:37 | Finished running 23 table models in 257.76s.
2018-07-30 15:39:37,726: Connection 'master' was left open.
2018-07-30 15:39:37,738: 
2018-07-30 15:39:37,738: Completed successfully
2018-07-30 15:39:37,738: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:39:37,770: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff97b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff9048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff9160>]}
2018-07-30 15:39:38,086: Flushing usage events
2018-07-30 15:39:38,662: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57477), raddr=('172.217.12.10', 443)>

2018-07-30 15:39:38,664: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57475), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,665: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57484), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,665: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57483), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,668: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57485), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,670: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57480), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,670: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57478), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,671: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57486), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,671: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57481), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,672: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57479), raddr=('172.217.1.205', 443)>

2018-07-30 15:47:15,499: Tracking: tracking
2018-07-30 15:47:15,501: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb0160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb0438>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb0e48>]}
2018-07-30 15:47:17,334: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:47:17,373: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:47:17,379: Parsing get_column_values.sql
2018-07-30 15:47:17,399: Parsing get_url_parameter.sql
2018-07-30 15:47:17,406: Parsing split_part.sql
2018-07-30 15:47:17,416: Parsing table_exists.sql
2018-07-30 15:47:17,428: Parsing core.sql
2018-07-30 15:47:17,443: Parsing adapters/bigquery.sql
2018-07-30 15:47:17,453: Parsing adapters/common.sql
2018-07-30 15:47:17,482: Parsing adapters/redshift.sql
2018-07-30 15:47:17,512: Parsing adapters/snowflake.sql
2018-07-30 15:47:17,517: Parsing etc/bigquery.sql
2018-07-30 15:47:17,523: Parsing etc/datetime.sql
2018-07-30 15:47:17,554: Parsing etc/get_custom_schema.sql
2018-07-30 15:47:17,565: Parsing materializations/helpers.sql
2018-07-30 15:47:17,587: Parsing materializations/archive/archive.sql
2018-07-30 15:47:17,633: Parsing materializations/incremental/incremental.sql
2018-07-30 15:47:17,672: Parsing materializations/seed/bigquery.sql
2018-07-30 15:47:17,681: Parsing materializations/seed/seed.sql
2018-07-30 15:47:17,733: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:47:17,772: Parsing materializations/table/table.sql
2018-07-30 15:47:17,805: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:47:17,825: Parsing materializations/view/view.sql
2018-07-30 15:47:17,853: Parsing schema_tests/accepted_values.sql
2018-07-30 15:47:17,861: Parsing schema_tests/not_null.sql
2018-07-30 15:47:17,866: Parsing schema_tests/relationships.sql
2018-07-30 15:47:17,872: Parsing schema_tests/unique.sql
2018-07-30 15:47:17,953: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:47:17,961: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:47:17,966: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:47:17,968: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:47:17,972: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:47:17,982: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:47:17,990: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:47:17,997: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:47:18,008: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:47:18,017: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:47:18,024: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:47:18,027: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:47:18,030: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:47:18,034: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:47:18,037: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:47:18,040: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:47:18,043: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:47:18,047: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:47:18,051: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:47:18,056: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:47:18,059: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:47:18,066: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:47:18,077: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:47:18,095: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:47:18,103: 
2018-07-30 15:47:18,110: Acquiring new bigquery connection "master".
2018-07-30 15:47:18,110: Opening a new connection (0 currently allocated)
2018-07-30 15:47:19,392: 15:47:19 | Concurrency: 4 threads (target='template')
2018-07-30 15:47:19,392: 15:47:19 | 
2018-07-30 15:47:19,554: 15:47:19 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:47:19,555: 15:47:19 | 2 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:47:19,555: 15:47:19 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:47:19,556: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:47:19,555: 15:47:19 | 4 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:47:19,556: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:47:19,556: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:47:19,565: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:47:19,566: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:47:19,571: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:47:19,578: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:47:19,584: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:47:19,587: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:47:19,588: Opening a new connection (1 currently allocated)
2018-07-30 15:47:19,593: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:47:19,596: Acquiring new bigquery connection "all_dates".
2018-07-30 15:47:19,598: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:47:19,600: Opening a new connection (2 currently allocated)
2018-07-30 15:47:19,602: Opening a new connection (3 currently allocated)
2018-07-30 15:47:19,610: Opening a new connection (4 currently allocated)
2018-07-30 15:47:20,017: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:47:20,018: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:47:20,131: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:47:20,132: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:47:20,149: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:47:20,151: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:47:20,199: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:47:20,204: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:47:21,548: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144978>]}
2018-07-30 15:47:21,580: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144828>]}
2018-07-30 15:47:21,788: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144630>]}
2018-07-30 15:47:21,857: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144be0>]}
2018-07-30 15:47:21,864: 15:47:21 | 3 of 23 OK created table model template.monthend_dates............... [OK in 1.99s]
2018-07-30 15:47:22,165: 15:47:22 | 2 of 23 OK created table model template.all_dates.................... [OK in 2.02s]
2018-07-30 15:47:22,475: 15:47:22 | 4 of 23 OK created table model template.stores_proc.................. [OK in 2.22s]
2018-07-30 15:47:22,787: 15:47:22 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.30s]
2018-07-30 15:47:22,788: 15:47:22 | 5 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:47:22,789: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:47:22,788: 15:47:22 | 6 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:47:22,795: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:47:22,788: 15:47:22 | 7 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:47:22,812: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:47:22,814: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:47:22,814: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:47:22,814: Re-using an available connection from the pool.
2018-07-30 15:47:22,820: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:22,824: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:47:22,824: Re-using an available connection from the pool.
2018-07-30 15:47:22,826: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:22,826: Re-using an available connection from the pool.
2018-07-30 15:47:22,828: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:24,398: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:47:24,402: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:47:24,553: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:47:24,554: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:47:24,590: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:47:24,591: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:47:24,607: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:47:24,798: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:47:24,799: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:47:26,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104142438>]}
2018-07-30 15:47:27,430: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10617ab00>]}
2018-07-30 15:47:27,622: 15:47:27 | 5 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.02s]
2018-07-30 15:47:28,159: 15:47:28 | 7 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.62s]
2018-07-30 15:47:30,101: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:47:30,403: 15:47:30 | 6 of 23 OK created table model template.shopify_customers_proc....... [OK in 7.31s]
2018-07-30 15:47:30,403: 15:47:30 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 15:47:30,404: 15:47:30 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 15:47:30,404: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:47:30,404: 15:47:30 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 15:47:30,404: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:47:30,410: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:47:30,410: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:47:30,425: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:47:30,471: Re-using an available connection from the pool.
2018-07-30 15:47:30,472: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:30,471: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:47:30,476: Re-using an available connection from the pool.
2018-07-30 15:47:30,476: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:30,499: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:47:30,500: Re-using an available connection from the pool.
2018-07-30 15:47:30,655: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:47:30,662: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:47:31,092: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:47:31,253: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:47:31,256: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:47:32,165: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:47:32,363: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:47:32,369: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:47:33,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10607d160>]}
2018-07-30 15:47:34,110: 15:47:34 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.08s]
2018-07-30 15:47:34,690: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10610c518>]}
2018-07-30 15:47:35,354: 15:47:35 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.29s]
2018-07-30 15:47:57,648: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ceb470>]}
2018-07-30 15:47:57,994: 15:47:57 | 10 of 23 OK created table model template.ga_transactions............. [OK in 27.24s]
2018-07-30 15:47:57,996: 15:47:57 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:47:57,997: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:47:58,041: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:47:58,042: Re-using an available connection from the pool.
2018-07-30 15:47:58,043: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:58,760: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:47:58,905: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:47:58,905: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:48:09,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:48:10,007: 15:48:10 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.66s]
2018-07-30 15:48:10,008: 15:48:10 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:48:10,009: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:48:10,020: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:48:10,026: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:48:10,026: Re-using an available connection from the pool.
2018-07-30 15:48:10,169: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:48:10,170: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:48:14,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:48:14,974: 15:48:14 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.17s]
2018-07-30 15:48:14,974: 15:48:14 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:48:14,974: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:48:14,982: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:48:14,987: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:48:14,987: Re-using an available connection from the pool.
2018-07-30 15:48:15,162: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:48:15,163: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:48:18,899: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:48:20,131: 15:48:20 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.92s]
2018-07-30 15:48:20,132: 15:48:20 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:48:20,132: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:48:20,145: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:48:20,152: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:48:20,152: Re-using an available connection from the pool.
2018-07-30 15:48:20,295: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:48:20,296: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:48:28,275: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:48:28,588: 15:48:28 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.14s]
2018-07-30 15:48:28,592: 15:48:28 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:48:28,593: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:48:28,592: 15:48:28 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:48:28,599: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:48:28,593: 15:48:28 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:48:28,608: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:48:28,616: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:48:28,617: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:48:28,625: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:48:28,627: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:48:28,628: Re-using an available connection from the pool.
2018-07-30 15:48:28,629: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:48:28,632: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:48:28,632: Re-using an available connection from the pool.
2018-07-30 15:48:28,634: Re-using an available connection from the pool.
2018-07-30 15:48:28,843: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:48:28,864: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:48:28,877: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:48:28,878: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:48:28,887: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:48:28,891: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:48:34,800: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ccd898>]}
2018-07-30 15:48:35,178: 15:48:35 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 6.20s]
2018-07-30 15:48:43,142: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:48:43,929: 15:48:43 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 14.55s]
2018-07-30 15:48:51,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061d36a0>]}
2018-07-30 15:48:52,216: 15:48:52 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 22.81s]
2018-07-30 15:48:52,217: 15:48:52 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:48:52,218: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:48:52,226: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:48:52,229: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:48:52,229: Re-using an available connection from the pool.
2018-07-30 15:48:52,419: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:48:52,420: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:49:17,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:49:18,153: 15:49:18 | 18 of 23 OK created table model template.customers_proc.............. [OK in 25.60s]
2018-07-30 15:49:18,155: 15:49:18 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:49:18,155: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:49:18,165: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:49:18,166: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:49:18,166: Re-using an available connection from the pool.
2018-07-30 15:49:18,296: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:49:18,297: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:49:46,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d66630>]}
2018-07-30 15:49:47,123: 15:49:47 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 27.99s]
2018-07-30 15:49:47,131: 15:49:47 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:49:47,136: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:49:47,194: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:49:47,200: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:49:47,201: Re-using an available connection from the pool.
2018-07-30 15:49:47,601: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:49:47,601: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:50:28,415: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:50:28,743: 15:50:28 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 41.28s]
2018-07-30 15:50:28,744: 15:50:28 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:50:28,745: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:50:28,769: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:50:28,772: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:50:28,772: Re-using an available connection from the pool.
2018-07-30 15:50:28,932: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:50:28,933: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:50:33,457: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d5ee48>]}
2018-07-30 15:50:33,754: 15:50:33 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 4.71s]
2018-07-30 15:50:33,755: 15:50:33 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:50:33,755: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:50:33,762: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:50:33,765: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:50:33,765: Re-using an available connection from the pool.
2018-07-30 15:50:33,897: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:50:33,898: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
case when total_revenue > 0 then revenue / total_revenue else null end as pct_of_revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:50:35,871: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:50:36,539: 15:50:36 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.12s]
2018-07-30 15:50:36,542: 15:50:36 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:50:36,542: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:50:36,557: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:50:36,562: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:50:36,563: Re-using an available connection from the pool.
2018-07-30 15:50:36,873: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:50:36,874: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 15:51:09,199: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d20c88>]}
2018-07-30 15:51:10,264: 15:51:10 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 32.66s]
2018-07-30 15:51:10,320: 15:51:10 | 
2018-07-30 15:51:10,320: 15:51:10 | Finished running 23 table models in 232.22s.
2018-07-30 15:51:10,321: Connection 'master' was left open.
2018-07-30 15:51:10,324: 
2018-07-30 15:51:10,324: Completed successfully
2018-07-30 15:51:10,324: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:51:10,325: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b14a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060eaa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060ea320>]}
2018-07-30 15:51:10,939: Flushing usage events
2018-07-30 15:51:11,456: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57773), raddr=('172.217.1.202', 443)>

2018-07-30 15:51:11,458: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57771), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,458: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57780), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,459: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57779), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,459: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57775), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,460: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57776), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,465: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57781), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,466: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57782), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,466: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57777), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,468: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57778), raddr=('172.217.2.13', 443)>

2018-07-30 15:55:11,118: Tracking: tracking
2018-07-30 15:55:11,120: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbae48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbaf28>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbaa20>]}
2018-07-30 15:55:12,106: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:55:12,148: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:55:12,155: Parsing get_column_values.sql
2018-07-30 15:55:12,204: Parsing get_url_parameter.sql
2018-07-30 15:55:12,211: Parsing split_part.sql
2018-07-30 15:55:12,232: Parsing table_exists.sql
2018-07-30 15:55:12,261: Parsing core.sql
2018-07-30 15:55:12,291: Parsing adapters/bigquery.sql
2018-07-30 15:55:12,302: Parsing adapters/common.sql
2018-07-30 15:55:12,343: Parsing adapters/redshift.sql
2018-07-30 15:55:12,370: Parsing adapters/snowflake.sql
2018-07-30 15:55:12,375: Parsing etc/bigquery.sql
2018-07-30 15:55:12,379: Parsing etc/datetime.sql
2018-07-30 15:55:12,419: Parsing etc/get_custom_schema.sql
2018-07-30 15:55:12,430: Parsing materializations/helpers.sql
2018-07-30 15:55:12,473: Parsing materializations/archive/archive.sql
2018-07-30 15:55:12,574: Parsing materializations/incremental/incremental.sql
2018-07-30 15:55:12,724: Parsing materializations/seed/bigquery.sql
2018-07-30 15:55:12,739: Parsing materializations/seed/seed.sql
2018-07-30 15:55:12,935: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:55:13,076: Parsing materializations/table/table.sql
2018-07-30 15:55:13,143: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:55:13,173: Parsing materializations/view/view.sql
2018-07-30 15:55:13,207: Parsing schema_tests/accepted_values.sql
2018-07-30 15:55:13,213: Parsing schema_tests/not_null.sql
2018-07-30 15:55:13,218: Parsing schema_tests/relationships.sql
2018-07-30 15:55:13,225: Parsing schema_tests/unique.sql
2018-07-30 15:55:13,246: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:55:13,250: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:55:13,252: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:55:13,254: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:55:13,257: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:55:13,271: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:55:13,283: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:55:13,290: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:55:13,301: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:55:13,309: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:55:13,316: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:55:13,319: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:55:13,322: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:55:13,327: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:55:13,331: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:55:13,335: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:55:13,338: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:55:13,342: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:55:13,346: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:55:13,352: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:55:13,355: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:55:13,360: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:55:13,372: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:55:13,396: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:55:13,404: 
2018-07-30 15:55:13,410: Acquiring new bigquery connection "master".
2018-07-30 15:55:13,410: Opening a new connection (0 currently allocated)
2018-07-30 15:55:14,721: 15:55:14 | Concurrency: 4 threads (target='template')
2018-07-30 15:55:14,721: 15:55:14 | 
2018-07-30 15:55:14,834: 15:55:14 | 1 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:55:14,835: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:55:14,834: 15:55:14 | 2 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:55:14,841: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:55:14,834: 15:55:14 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:55:14,842: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:55:14,835: 15:55:14 | 4 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:55:14,842: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:55:14,852: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:55:14,852: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:55:14,854: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:55:14,866: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:55:14,872: Opening a new connection (1 currently allocated)
2018-07-30 15:55:14,879: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:55:14,884: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:55:14,887: Acquiring new bigquery connection "all_dates".
2018-07-30 15:55:14,890: Opening a new connection (2 currently allocated)
2018-07-30 15:55:14,892: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:55:14,895: Opening a new connection (3 currently allocated)
2018-07-30 15:55:14,908: Opening a new connection (4 currently allocated)
2018-07-30 15:55:15,726: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:55:15,726: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:55:15,762: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:55:15,777: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:55:15,784: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:55:15,790: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:55:15,793: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:55:15,793: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:55:17,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd4a6a0>]}
2018-07-30 15:55:17,652: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd8cda0>]}
2018-07-30 15:55:17,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd8c5c0>]}
2018-07-30 15:55:18,150: 15:55:18 | 4 of 23 OK created table model template.monthend_dates............... [OK in 2.66s]
2018-07-30 15:55:18,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd12080>]}
2018-07-30 15:55:18,925: 15:55:18 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.81s]
2018-07-30 15:55:19,547: 15:55:19 | 2 of 23 OK created table model template.mappings_ga_proc............. [OK in 3.14s]
2018-07-30 15:55:20,210: 15:55:20 | 1 of 23 OK created table model template.stores_proc.................. [OK in 3.32s]
2018-07-30 15:55:20,210: 15:55:20 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:55:20,211: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:55:20,211: 15:55:20 | 6 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:55:20,211: 15:55:20 | 7 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:55:20,220: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:55:20,220: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:55:20,229: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:55:20,233: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:55:20,240: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:55:20,240: Re-using an available connection from the pool.
2018-07-30 15:55:20,241: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:20,241: Re-using an available connection from the pool.
2018-07-30 15:55:20,241: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:20,241: Re-using an available connection from the pool.
2018-07-30 15:55:20,243: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:21,709: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:55:21,719: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:55:21,948: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:55:21,949: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:55:21,967: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:55:21,968: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:55:22,045: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:55:22,186: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:55:22,187: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:55:24,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1fe048>]}
2018-07-30 15:55:24,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc876a0>]}
2018-07-30 15:55:24,490: 15:55:24 | 6 of 23 OK created table model template.shopify_refunds_proc......... [OK in 3.97s]
2018-07-30 15:55:24,808: 15:55:24 | 7 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.08s]
2018-07-30 15:55:26,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdc8438>]}
2018-07-30 15:55:27,416: 15:55:27 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.53s]
2018-07-30 15:55:27,418: 15:55:27 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 15:55:27,419: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:55:27,418: 15:55:27 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 15:55:27,418: 15:55:27 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 15:55:27,436: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:55:27,438: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:55:27,439: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:55:27,454: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:55:27,462: Re-using an available connection from the pool.
2018-07-30 15:55:27,466: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:27,472: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:55:27,473: Re-using an available connection from the pool.
2018-07-30 15:55:27,591: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:55:27,591: Re-using an available connection from the pool.
2018-07-30 15:55:27,591: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:27,938: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:55:27,945: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:55:28,544: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:55:28,853: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:55:28,854: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:55:29,157: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:55:29,350: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:55:29,351: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:55:31,288: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd4a9b0>]}
2018-07-30 15:55:31,613: 15:55:31 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.85s]
2018-07-30 15:55:32,010: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088827b8>]}
2018-07-30 15:55:32,312: 15:55:32 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.59s]
2018-07-30 15:55:55,292: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9fef0>]}
2018-07-30 15:55:55,927: 15:55:55 | 10 of 23 OK created table model template.ga_transactions............. [OK in 27.85s]
2018-07-30 15:55:55,928: 15:55:55 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:55:55,929: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:55:55,948: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:55:55,949: Re-using an available connection from the pool.
2018-07-30 15:55:55,949: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:56,720: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:55:56,896: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:55:56,897: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:56:07,846: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:56:08,163: 15:56:08 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.92s]
2018-07-30 15:56:08,164: 15:56:08 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:56:08,165: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:56:08,175: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:56:08,178: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:56:08,178: Re-using an available connection from the pool.
2018-07-30 15:56:08,319: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:56:08,323: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:56:12,301: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108910748>]}
2018-07-30 15:56:13,631: 15:56:13 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.14s]
2018-07-30 15:56:13,632: 15:56:13 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:56:13,632: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:56:13,638: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:56:13,639: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:56:13,639: Re-using an available connection from the pool.
2018-07-30 15:56:13,881: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:56:13,881: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:56:17,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:56:18,165: 15:56:18 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.23s]
2018-07-30 15:56:18,166: 15:56:18 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:56:18,167: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:56:18,176: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:56:18,180: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:56:18,180: Re-using an available connection from the pool.
2018-07-30 15:56:18,321: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:56:18,321: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:56:26,929: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bde6630>]}
2018-07-30 15:56:27,221: 15:56:27 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.76s]
2018-07-30 15:56:27,222: 15:56:27 | 15 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:56:27,222: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:56:27,232: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:56:27,232: 15:56:27 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:56:27,232: 15:56:27 | 17 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:56:27,232: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:56:27,233: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:56:27,250: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:56:27,256: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:56:27,256: Re-using an available connection from the pool.
2018-07-30 15:56:27,260: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:56:27,262: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:56:27,263: Re-using an available connection from the pool.
2018-07-30 15:56:27,276: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:56:27,277: Re-using an available connection from the pool.
2018-07-30 15:56:27,434: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:56:27,440: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:56:27,454: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:56:27,463: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:56:27,463: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:56:27,467: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:56:32,225: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd128d0>]}
2018-07-30 15:56:32,901: 15:56:32 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.99s]
2018-07-30 15:56:38,978: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd22208>]}
2018-07-30 15:56:39,329: 15:56:39 | 17 of 23 OK created table model template.customers_proc_qoq.......... [OK in 11.75s]
2018-07-30 15:56:49,194: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:56:49,489: 15:56:49 | 15 of 23 OK created table model template.customers_proc_yoy.......... [OK in 21.97s]
2018-07-30 15:56:49,491: 15:56:49 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:56:49,491: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:56:49,508: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:56:49,512: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:56:49,513: Re-using an available connection from the pool.
2018-07-30 15:56:49,646: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:56:49,646: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:57:18,354: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089210b8>]}
2018-07-30 15:57:19,238: 15:57:19 | 18 of 23 OK created table model template.customers_proc.............. [OK in 28.86s]
2018-07-30 15:57:19,240: 15:57:19 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:57:19,241: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:57:19,254: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:57:19,257: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:57:19,257: Re-using an available connection from the pool.
2018-07-30 15:57:19,408: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:57:19,409: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:57:52,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:57:53,162: 15:57:53 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 33.55s]
2018-07-30 15:57:53,164: 15:57:53 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:57:53,165: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:57:53,190: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:57:53,193: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:57:53,194: Re-using an available connection from the pool.
2018-07-30 15:57:53,344: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:57:53,345: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:58:34,979: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1fe048>]}
2018-07-30 15:58:37,167: 15:58:37 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 41.81s]
2018-07-30 15:58:37,169: 15:58:37 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:58:37,170: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:58:37,198: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:58:37,205: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:58:37,206: Re-using an available connection from the pool.
2018-07-30 15:58:37,829: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:58:37,830: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:58:43,127: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:58:43,436: 15:58:43 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.96s]
2018-07-30 15:58:43,439: 15:58:43 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:58:43,439: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:58:43,451: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:58:43,453: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:58:43,453: Re-using an available connection from the pool.
2018-07-30 15:58:44,007: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:58:44,008: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
case when total_revenue > 0 then revenue / total_revenue else null end as pct_of_revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:58:46,680: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1fe048>]}
2018-07-30 15:58:47,623: 15:58:47 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 3.24s]
2018-07-30 15:58:47,623: 15:58:47 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:58:47,624: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:58:47,635: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:58:47,638: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:58:47,638: Re-using an available connection from the pool.
2018-07-30 15:58:48,132: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:58:48,133: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    with buyer_lists as (

	SELECT
	a.store,
	period,
	date,
	customer_id,
	b.first_name,
	b.last_name,
	b.email,
	recency,
	frequency,
	revenue,
	aov,
	revenue_segment,
	frequency_segment
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
	LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
	ON (
		a.store = b.store AND
		a.customer_id = b.id
	)
	where ( revenue_segment != '' or frequency_segment != '' )
)

SELECT
store,
period,
date,
'Revenue' as segment_type,
revenue_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists

UNION ALL

SELECT
store,
period,
date,
'Frequency' as segment_type,
frequency_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists
  );

    
2018-07-30 15:59:27,394: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:59:27,718: 15:59:27 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 39.77s]
2018-07-30 15:59:27,818: 15:59:27 | 
2018-07-30 15:59:27,818: 15:59:27 | Finished running 23 table models in 254.41s.
2018-07-30 15:59:27,818: Connection 'master' was left open.
2018-07-30 15:59:27,818: 
2018-07-30 15:59:27,819: Completed successfully
2018-07-30 15:59:27,819: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:59:27,822: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c6f470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcbb4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcfe518>]}
2018-07-30 15:59:28,121: Flushing usage events
2018-07-30 15:59:28,392: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57980), raddr=('172.217.1.202', 443)>

2018-07-30 15:59:28,394: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57979), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,395: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57987), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,397: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57985), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,400: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57981), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,401: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57982), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,402: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57986), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,403: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57988), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,406: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57983), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,406: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57984), raddr=('172.217.2.13', 443)>

2018-07-30 16:06:42,246: Tracking: tracking
2018-07-30 16:06:42,251: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed4198>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed4a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed4f60>]}
2018-07-30 16:06:43,161: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 16:06:43,201: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 16:06:43,210: Parsing get_column_values.sql
2018-07-30 16:06:43,230: Parsing get_url_parameter.sql
2018-07-30 16:06:43,240: Parsing split_part.sql
2018-07-30 16:06:43,252: Parsing table_exists.sql
2018-07-30 16:06:43,264: Parsing core.sql
2018-07-30 16:06:43,284: Parsing adapters/bigquery.sql
2018-07-30 16:06:43,297: Parsing adapters/common.sql
2018-07-30 16:06:43,324: Parsing adapters/redshift.sql
2018-07-30 16:06:43,353: Parsing adapters/snowflake.sql
2018-07-30 16:06:43,362: Parsing etc/bigquery.sql
2018-07-30 16:06:43,367: Parsing etc/datetime.sql
2018-07-30 16:06:43,396: Parsing etc/get_custom_schema.sql
2018-07-30 16:06:43,410: Parsing materializations/helpers.sql
2018-07-30 16:06:43,440: Parsing materializations/archive/archive.sql
2018-07-30 16:06:43,486: Parsing materializations/incremental/incremental.sql
2018-07-30 16:06:43,531: Parsing materializations/seed/bigquery.sql
2018-07-30 16:06:43,541: Parsing materializations/seed/seed.sql
2018-07-30 16:06:43,598: Parsing materializations/table/bigquery_table.sql
2018-07-30 16:06:43,630: Parsing materializations/table/table.sql
2018-07-30 16:06:43,658: Parsing materializations/view/bigquery_view.sql
2018-07-30 16:06:43,674: Parsing materializations/view/view.sql
2018-07-30 16:06:43,699: Parsing schema_tests/accepted_values.sql
2018-07-30 16:06:43,706: Parsing schema_tests/not_null.sql
2018-07-30 16:06:43,711: Parsing schema_tests/relationships.sql
2018-07-30 16:06:43,718: Parsing schema_tests/unique.sql
2018-07-30 16:06:43,757: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 16:06:43,759: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 16:06:43,762: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 16:06:43,765: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 16:06:43,769: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 16:06:43,782: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 16:06:43,795: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 16:06:43,802: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 16:06:43,813: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 16:06:43,822: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 16:06:43,830: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 16:06:43,833: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 16:06:43,837: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 16:06:43,841: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 16:06:43,844: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 16:06:43,848: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 16:06:43,854: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 16:06:43,858: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 16:06:43,862: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 16:06:43,870: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 16:06:43,873: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 16:06:43,878: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 16:06:43,890: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 16:06:43,909: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 16:06:43,919: 
2018-07-30 16:06:43,927: Acquiring new bigquery connection "master".
2018-07-30 16:06:43,928: Opening a new connection (0 currently allocated)
2018-07-30 16:06:45,240: 16:06:45 | Concurrency: 4 threads (target='template')
2018-07-30 16:06:45,240: 16:06:45 | 
2018-07-30 16:06:45,324: 16:06:45 | 1 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 16:06:45,324: 16:06:45 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 16:06:45,324: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 16:06:45,324: 16:06:45 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 16:06:45,325: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 16:06:45,324: 16:06:45 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 16:06:45,330: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 16:06:45,330: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 16:06:45,336: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 16:06:45,337: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 16:06:45,342: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 16:06:45,347: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 16:06:45,352: Acquiring new bigquery connection "monthend_dates".
2018-07-30 16:06:45,352: Opening a new connection (1 currently allocated)
2018-07-30 16:06:45,354: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 16:06:45,357: Acquiring new bigquery connection "stores_proc".
2018-07-30 16:06:45,359: Acquiring new bigquery connection "all_dates".
2018-07-30 16:06:45,361: Opening a new connection (2 currently allocated)
2018-07-30 16:06:45,375: Opening a new connection (3 currently allocated)
2018-07-30 16:06:45,381: Opening a new connection (4 currently allocated)
2018-07-30 16:06:45,831: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 16:06:45,841: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 16:06:45,848: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 16:06:45,851: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 16:06:45,852: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 16:06:45,864: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 16:06:45,867: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 16:06:45,872: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 16:06:47,339: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140620b8>]}
2018-07-30 16:06:47,502: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114062e48>]}
2018-07-30 16:06:47,521: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114062470>]}
2018-07-30 16:06:48,128: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd7588>]}
2018-07-30 16:06:48,129: 16:06:48 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.01s]
2018-07-30 16:06:48,914: 16:06:48 | 1 of 23 OK created table model template.monthend_dates............... [OK in 2.18s]
2018-07-30 16:06:49,580: 16:06:49 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.19s]
2018-07-30 16:06:49,959: 16:06:49 | 2 of 23 OK created table model template.stores_proc.................. [OK in 2.80s]
2018-07-30 16:06:49,960: 16:06:49 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 16:06:49,961: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 16:06:49,961: 16:06:49 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 16:06:49,961: 16:06:49 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 16:06:49,968: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 16:06:49,968: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 16:06:49,979: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 16:06:49,982: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 16:06:49,992: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 16:06:49,992: Re-using an available connection from the pool.
2018-07-30 16:06:49,992: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:49,992: Re-using an available connection from the pool.
2018-07-30 16:06:49,993: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:49,993: Re-using an available connection from the pool.
2018-07-30 16:06:49,994: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:51,619: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 16:06:51,623: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 16:06:51,781: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 16:06:51,782: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 16:06:51,835: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 16:06:51,835: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 16:06:51,912: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 16:06:52,069: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 16:06:52,069: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 16:06:54,030: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127f8390>]}
2018-07-30 16:06:54,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ca57b8>]}
2018-07-30 16:06:54,327: 16:06:54 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.06s]
2018-07-30 16:06:54,632: 16:06:54 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.21s]
2018-07-30 16:06:56,901: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ea588>]}
2018-07-30 16:06:57,675: 16:06:57 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.94s]
2018-07-30 16:06:57,676: 16:06:57 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 16:06:57,676: 16:06:57 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 16:06:57,677: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 16:06:57,676: 16:06:57 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 16:06:57,677: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 16:06:57,687: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 16:06:57,688: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 16:06:57,724: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 16:06:57,725: Re-using an available connection from the pool.
2018-07-30 16:06:57,725: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:57,728: Acquiring new bigquery connection "ga_transactions".
2018-07-30 16:06:57,729: Re-using an available connection from the pool.
2018-07-30 16:06:57,729: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:57,750: Acquiring new bigquery connection "agg_customers".
2018-07-30 16:06:57,751: Re-using an available connection from the pool.
2018-07-30 16:06:58,021: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 16:06:58,024: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 16:06:58,794: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 16:06:58,983: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 16:06:58,984: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 16:06:59,342: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 16:06:59,457: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 16:06:59,457: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 16:07:01,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ead30>]}
2018-07-30 16:07:01,423: 16:07:01 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.44s]
2018-07-30 16:07:02,125: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd7588>]}
2018-07-30 16:07:02,423: 16:07:02 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.45s]
2018-07-30 16:07:24,348: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fa16a0>]}
2018-07-30 16:07:25,265: 16:07:25 | 10 of 23 OK created table model template.ga_transactions............. [OK in 26.66s]
2018-07-30 16:07:25,267: 16:07:25 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 16:07:25,267: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 16:07:25,288: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 16:07:25,288: Re-using an available connection from the pool.
2018-07-30 16:07:25,291: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:07:26,242: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 16:07:26,406: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 16:07:26,406: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 16:07:37,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140420f0>]}
2018-07-30 16:07:38,150: 16:07:38 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 12.54s]
2018-07-30 16:07:38,152: 16:07:38 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 16:07:38,152: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 16:07:38,162: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 16:07:38,164: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 16:07:38,164: Re-using an available connection from the pool.
2018-07-30 16:07:38,290: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 16:07:38,293: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 16:07:42,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d0dac8>]}
2018-07-30 16:07:42,752: 16:07:42 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.15s]
2018-07-30 16:07:42,754: 16:07:42 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 16:07:42,754: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 16:07:42,764: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 16:07:42,766: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 16:07:42,766: Re-using an available connection from the pool.
2018-07-30 16:07:42,939: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 16:07:42,942: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 16:07:46,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ac2e8>]}
2018-07-30 16:07:48,061: 16:07:48 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.04s]
2018-07-30 16:07:48,062: 16:07:48 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 16:07:48,062: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 16:07:48,080: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 16:07:48,083: Acquiring new bigquery connection "agg_transactions".
2018-07-30 16:07:48,084: Re-using an available connection from the pool.
2018-07-30 16:07:48,257: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 16:07:48,258: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 16:07:56,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ac710>]}
2018-07-30 16:07:57,256: 16:07:57 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.54s]
2018-07-30 16:07:57,258: 16:07:57 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 16:07:57,258: 16:07:57 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 16:07:57,259: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 16:07:57,259: 16:07:57 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 16:07:57,259: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 16:07:57,272: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 16:07:57,278: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 16:07:57,301: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 16:07:57,305: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 16:07:57,312: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 16:07:57,313: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 16:07:57,313: Re-using an available connection from the pool.
2018-07-30 16:07:57,315: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 16:07:57,316: Re-using an available connection from the pool.
2018-07-30 16:07:57,318: Re-using an available connection from the pool.
2018-07-30 16:07:57,476: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 16:07:57,509: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 16:07:57,529: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 16:07:57,544: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 16:07:57,647: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 16:07:57,681: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 16:08:04,991: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d27908>]}
2018-07-30 16:08:05,661: 16:08:05 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 7.73s]
2018-07-30 16:08:10,119: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ac2e8>]}
2018-07-30 16:08:10,409: 16:08:10 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.86s]
2018-07-30 16:08:19,454: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114020a58>]}
2018-07-30 16:08:19,811: 16:08:19 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 22.18s]
2018-07-30 16:08:19,812: 16:08:19 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 16:08:19,812: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 16:08:19,836: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 16:08:19,847: Acquiring new bigquery connection "customers_proc".
2018-07-30 16:08:19,847: Re-using an available connection from the pool.
2018-07-30 16:08:20,130: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 16:08:20,131: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 16:08:47,685: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a9ba8>]}
2018-07-30 16:08:48,949: 16:08:48 | 18 of 23 OK created table model template.customers_proc.............. [OK in 27.87s]
2018-07-30 16:08:48,952: 16:08:48 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 16:08:48,953: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 16:08:48,964: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 16:08:48,966: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 16:08:48,966: Re-using an available connection from the pool.
2018-07-30 16:08:49,469: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 16:08:49,469: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 16:09:20,902: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a9978>]}
2018-07-30 16:09:21,859: 16:09:21 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 31.95s]
2018-07-30 16:09:21,861: 16:09:21 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 16:09:21,862: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 16:09:21,886: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 16:09:21,889: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 16:09:21,889: Re-using an available connection from the pool.
2018-07-30 16:09:22,271: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 16:09:22,271: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 16:10:01,257: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114132278>]}
2018-07-30 16:10:02,117: 16:10:02 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 39.39s]
2018-07-30 16:10:02,119: 16:10:02 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 16:10:02,119: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 16:10:02,169: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 16:10:02,176: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 16:10:02,176: Re-using an available connection from the pool.
2018-07-30 16:10:02,336: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 16:10:02,382: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 16:10:06,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a9978>]}
2018-07-30 16:10:07,616: 16:10:07 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 4.68s]
2018-07-30 16:10:07,618: 16:10:07 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 16:10:07,618: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 16:10:07,639: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 16:10:07,642: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 16:10:07,643: Re-using an available connection from the pool.
2018-07-30 16:10:07,893: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 16:10:07,895: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
case when total_revenue > 0 then revenue / total_revenue else null end as pct_of_revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 16:10:09,847: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114132278>]}
2018-07-30 16:10:10,251: 16:10:10 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.23s]
2018-07-30 16:10:10,252: 16:10:10 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 16:10:10,253: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 16:10:10,278: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 16:10:10,283: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 16:10:10,283: Re-using an available connection from the pool.
2018-07-30 16:10:10,676: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 16:10:10,677: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    with buyer_lists as (

	SELECT
	a.store,
	period,
	date,
	customer_id,
	b.first_name,
	b.last_name,
	b.email,
	recency,
	frequency,
	revenue,
	aov,
	revenue_segment,
	frequency_segment
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
	LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
	ON (
		a.store = b.store AND
		a.customer_id = b.id
	)
	where revenue > 0
)

SELECT
store,
period,
date,
'Revenue' as segment_type,
revenue_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists

UNION ALL

SELECT
store,
period,
date,
'Frequency' as segment_type,
frequency_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists
  );

    
2018-07-30 16:10:59,047: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140b4d30>]}
2018-07-30 16:10:59,400: 16:10:59 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 48.79s]
2018-07-30 16:10:59,499: 16:10:59 | 
2018-07-30 16:10:59,499: 16:10:59 | Finished running 23 table models in 255.58s.
2018-07-30 16:10:59,499: Connection 'master' was left open.
2018-07-30 16:10:59,500: 
2018-07-30 16:10:59,500: Completed successfully
2018-07-30 16:10:59,500: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 16:10:59,501: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd44e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140acfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114062860>]}
2018-07-30 16:10:59,826: Flushing usage events
2018-07-30 16:10:59,996: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58289), raddr=('172.217.2.13', 443)>

2018-07-30 16:10:59,998: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58288), raddr=('172.217.2.10', 443)>

2018-07-30 16:10:59,998: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58287), raddr=('172.217.2.13', 443)>

2018-07-30 16:10:59,999: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58296), raddr=('172.217.12.10', 443)>

2018-07-30 16:10:59,999: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58293), raddr=('172.217.12.10', 443)>

2018-07-30 16:11:00,000: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58295), raddr=('172.217.12.10', 443)>

2018-07-30 16:11:00,001: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58294), raddr=('172.217.12.10', 443)>

2018-07-30 16:11:00,002: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58290), raddr=('172.217.2.13', 443)>

2018-07-30 16:11:00,002: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58291), raddr=('172.217.2.13', 443)>

2018-07-30 16:11:00,002: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58292), raddr=('172.217.2.13', 443)>

2020-11-10 09:01:53.303960 (MainThread): Running with dbt=0.18.1
2020-11-10 09:01:53.597905 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2020-11-10 09:01:53.620533 (MainThread): Tracking: tracking
2020-11-10 09:01:53.621359 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d5cb6e198>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d5cb058d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d5cb11828>]}
2020-11-10 09:01:53.621758 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=13
2020-11-10 09:01:53.622267 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2020-11-10 09:01:53.623975 (MainThread): Send requests to http://localhost:8580/jsonrpc
2020-11-10 09:01:53.655333 (Thread-1): Parsing macros/split_part.sql
2020-11-10 09:01:53.664075 (Thread-1): Parsing macros/get_url_parameter.sql
2020-11-10 09:01:53.670192 (Thread-1): Parsing macros/get_column_values.sql
2020-11-10 09:01:53.681634 (Thread-1): Parsing macros/table_exists.sql
2020-11-10 09:01:53.686190 (Thread-1): Parsing macros/adapters.sql
2020-11-10 09:01:53.721604 (Thread-1): Parsing macros/etc.sql
2020-11-10 09:01:53.723940 (Thread-1): Parsing macros/catalog.sql
2020-11-10 09:01:53.734532 (Thread-1): Parsing macros/materializations/table.sql
2020-11-10 09:01:53.753177 (Thread-1): Parsing macros/materializations/view.sql
2020-11-10 09:01:53.758371 (Thread-1): Parsing macros/materializations/copy.sql
2020-11-10 09:01:53.766290 (Thread-1): Parsing macros/materializations/seed.sql
2020-11-10 09:01:53.771303 (Thread-1): Parsing macros/materializations/incremental.sql
2020-11-10 09:01:53.795378 (Thread-1): Parsing macros/materializations/snapshot.sql
2020-11-10 09:01:53.800492 (Thread-1): Parsing macros/core.sql
2020-11-10 09:01:53.807122 (Thread-1): Parsing macros/adapters/common.sql
2020-11-10 09:01:53.885513 (Thread-1): Parsing macros/materializations/helpers.sql
2020-11-10 09:01:53.902058 (Thread-1): Parsing macros/materializations/table/table.sql
2020-11-10 09:01:53.915291 (Thread-1): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:01:53.953980 (Thread-1): Parsing macros/materializations/view/view.sql
2020-11-10 09:01:53.965861 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:01:53.975050 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:01:53.978813 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:01:53.990636 (Thread-1): Parsing macros/materializations/common/merge.sql
2020-11-10 09:01:54.016577 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:01:54.038587 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:01:54.040517 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:01:54.071840 (Thread-1): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:01:54.073953 (Thread-1): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:01:54.075652 (Thread-1): Parsing macros/schema_tests/unique.sql
2020-11-10 09:01:54.077467 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:01:54.080400 (Thread-1): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:01:54.082235 (Thread-1): Parsing macros/etc/query.sql
2020-11-10 09:01:54.083350 (Thread-1): Parsing macros/etc/datetime.sql
2020-11-10 09:01:54.093058 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:01:54.094120 (Thread-1): Parsing macros/etc/is_incremental.sql
2020-11-10 09:01:54.095816 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:01:54.104003 (Thread-1): * Deprecation Warning: dbt v0.17.0 introduces a new config format for the
dbt_project.yml file. Support for the existing version 1 format will be removed
in a future release of dbt. The following packages are currently configured with
config version 1:
 - shopify_buyer_segmentation

For upgrading instructions, consult the documentation:
  https://docs.getdbt.com/docs/guides/migration-guide/upgrading-to-0-17-0

2020-11-10 09:01:54.104398 (Thread-1): Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e13551b1-7553-435e-a639-2222afab5b16', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d5c2ddda0>]}
2020-11-10 09:01:54.187505 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:01:54.223989 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:01:54.240926 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:01:54.257894 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:01:54.277664 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:01:54.309708 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:01:54.330817 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:01:54.350252 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:01:54.371350 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:01:54.384279 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:01:54.397429 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:01:54.410194 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:01:54.423138 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:01:54.433883 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:01:54.443440 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:01:54.454080 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:01:54.482523 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:01:54.498964 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:01:54.513067 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:01:54.743027 (Thread-2): handling status request
2020-11-10 09:01:54.743574 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e13551b1-7553-435e-a639-2222afab5b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d5c0e92e8>]}
2020-11-10 09:01:54.751103 (Thread-2): sending response (<Response 17348 bytes [200 OK]>) to 10.0.35.67
2020-11-10 09:01:55.148267 (Thread-3): handling status request
2020-11-10 09:01:55.148771 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e13551b1-7553-435e-a639-2222afab5b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d5c0749e8>]}
2020-11-10 09:01:55.155636 (Thread-3): sending response (<Response 17348 bytes [200 OK]>) to 10.0.25.53
2020-11-10 09:04:42.179763 (MainThread): writing 1 spans (enabled:True), 113 additional messages skipped
2020-11-10 09:04:42.181442 (MainThread): 
      name jinja2.compile
        id 2074463182352066445
  trace_id 12807628916087394829
 parent_id None
   service None
  resource <memory>
      type template
     start 1604999082.178772
       end 1604999082.179525
  duration 0.000753s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:764ba627597b47bfb1e2944e58d4f732, 147 additional messages skipped
2020-11-10 09:04:42.238037 (MainThread): Connection 'model.shopify_buyer_segmentation.shopify_orders_proc' was properly closed.
2020-11-10 09:04:42.275294 (Thread-4): Parsing macros/split_part.sql
2020-11-10 09:04:42.281144 (Thread-4): Parsing macros/get_url_parameter.sql
2020-11-10 09:04:42.285687 (Thread-4): Parsing macros/get_column_values.sql
2020-11-10 09:04:42.292559 (Thread-4): Parsing macros/table_exists.sql
2020-11-10 09:04:42.295268 (Thread-4): Parsing macros/adapters.sql
2020-11-10 09:04:42.316811 (Thread-4): Parsing macros/etc.sql
2020-11-10 09:04:42.318177 (Thread-4): Parsing macros/catalog.sql
2020-11-10 09:04:42.324213 (Thread-4): Parsing macros/materializations/table.sql
2020-11-10 09:04:42.334521 (Thread-4): Parsing macros/materializations/view.sql
2020-11-10 09:04:42.337409 (Thread-4): Parsing macros/materializations/copy.sql
2020-11-10 09:04:42.341961 (Thread-4): Parsing macros/materializations/seed.sql
2020-11-10 09:04:42.344766 (Thread-4): Parsing macros/materializations/incremental.sql
2020-11-10 09:04:42.358482 (Thread-4): Parsing macros/materializations/snapshot.sql
2020-11-10 09:04:42.361568 (AgentWriter): reported 37 traces in 0.00523s, 3 additional messages skipped
2020-11-10 09:04:42.361908 (AgentWriter): initialized RateSampler, sample 100% of traces, 127 additional messages skipped
2020-11-10 09:04:42.363376 (Thread-4): Parsing macros/core.sql
2020-11-10 09:04:42.367369 (Thread-4): Parsing macros/adapters/common.sql
2020-11-10 09:04:42.414072 (Thread-4): Parsing macros/materializations/helpers.sql
2020-11-10 09:04:42.425180 (Thread-4): Parsing macros/materializations/table/table.sql
2020-11-10 09:04:42.432130 (Thread-4): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:04:42.456744 (Thread-4): Parsing macros/materializations/view/view.sql
2020-11-10 09:04:42.464611 (Thread-4): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:04:42.473896 (Thread-4): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:04:42.477299 (Thread-4): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:04:42.488085 (Thread-4): Parsing macros/materializations/common/merge.sql
2020-11-10 09:04:42.503140 (Thread-4): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:04:42.520553 (Thread-4): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:04:42.523275 (Thread-4): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:04:42.562218 (Thread-4): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:04:42.565597 (Thread-4): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:04:42.568218 (Thread-4): Parsing macros/schema_tests/unique.sql
2020-11-10 09:04:42.571236 (Thread-4): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:04:42.575095 (Thread-4): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:04:42.576838 (Thread-4): Parsing macros/etc/query.sql
2020-11-10 09:04:42.578048 (Thread-4): Parsing macros/etc/datetime.sql
2020-11-10 09:04:42.589674 (Thread-4): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:04:42.591304 (Thread-4): Parsing macros/etc/is_incremental.sql
2020-11-10 09:04:42.594121 (Thread-4): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:04:42.665840 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_by_transaction".
2020-11-10 09:04:42.705660 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.agg_customers".
2020-11-10 09:04:42.724110 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:04:42.741344 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.agg_transactions".
2020-11-10 09:04:42.761744 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:04:42.836807 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc".
2020-11-10 09:04:42.947805 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:04:42.950778 (Thread-5): handling status request
2020-11-10 09:04:42.981228 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:04:43.011239 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e13551b1-7553-435e-a639-2222afab5b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d57f27748>]}
2020-11-10 09:04:43.035848 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:04:43.058355 (Thread-5): sending response (<Response 184 bytes [200 OK]>) to 10.0.29.97
2020-11-10 09:04:43.081273 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:04:43.099770 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:04:43.116456 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:04:43.132346 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.stores_proc".
2020-11-10 09:04:43.149528 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.monthend_dates".
2020-11-10 09:04:43.162454 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:04:43.177615 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.ga_transactions".
2020-11-10 09:04:43.201602 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_products_proc".
2020-11-10 09:04:43.226843 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:04:43.249856 (Thread-4): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:04:44.606616 (Thread-6): handling status request
2020-11-10 09:04:44.607164 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e13551b1-7553-435e-a639-2222afab5b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d576dcac8>]}
2020-11-10 09:04:44.613311 (Thread-6): sending response (<Response 16162 bytes [200 OK]>) to 10.0.29.97
2020-11-10 09:05:01.229020 (MainThread): Running with dbt=0.18.1
2020-11-10 09:05:01.536127 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2020-11-10 09:05:01.551773 (MainThread): Tracking: tracking
2020-11-10 09:05:01.563477 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6bc16df98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6bc15e4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6bc15e5f8>]}
2020-11-10 09:05:01.563976 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=13
2020-11-10 09:05:01.564547 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2020-11-10 09:05:01.565079 (MainThread): Send requests to http://localhost:8580/jsonrpc
2020-11-10 09:05:01.577479 (Thread-1): Parsing macros/split_part.sql
2020-11-10 09:05:01.587004 (Thread-1): Parsing macros/get_url_parameter.sql
2020-11-10 09:05:01.593320 (Thread-1): Parsing macros/get_column_values.sql
2020-11-10 09:05:01.602231 (Thread-1): Parsing macros/table_exists.sql
2020-11-10 09:05:01.605061 (Thread-1): Parsing macros/adapters.sql
2020-11-10 09:05:01.626145 (Thread-1): Parsing macros/etc.sql
2020-11-10 09:05:01.627721 (Thread-1): Parsing macros/catalog.sql
2020-11-10 09:05:01.633741 (Thread-1): Parsing macros/materializations/table.sql
2020-11-10 09:05:01.643893 (Thread-1): Parsing macros/materializations/view.sql
2020-11-10 09:05:01.646814 (Thread-1): Parsing macros/materializations/copy.sql
2020-11-10 09:05:01.651252 (Thread-1): Parsing macros/materializations/seed.sql
2020-11-10 09:05:01.654046 (Thread-1): Parsing macros/materializations/incremental.sql
2020-11-10 09:05:01.670135 (Thread-1): Parsing macros/materializations/snapshot.sql
2020-11-10 09:05:01.673158 (Thread-1): Parsing macros/core.sql
2020-11-10 09:05:01.676971 (Thread-1): Parsing macros/adapters/common.sql
2020-11-10 09:05:01.734171 (Thread-1): Parsing macros/materializations/helpers.sql
2020-11-10 09:05:01.743638 (Thread-1): Parsing macros/materializations/table/table.sql
2020-11-10 09:05:01.752948 (Thread-1): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:05:01.777180 (Thread-1): Parsing macros/materializations/view/view.sql
2020-11-10 09:05:01.784217 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:05:01.789433 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:05:01.791455 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:05:01.798558 (Thread-1): Parsing macros/materializations/common/merge.sql
2020-11-10 09:05:01.813744 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:05:01.830964 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:05:01.832834 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:05:01.862061 (Thread-1): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:05:01.864114 (Thread-1): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:05:01.865741 (Thread-1): Parsing macros/schema_tests/unique.sql
2020-11-10 09:05:01.867595 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:05:01.870389 (Thread-1): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:05:01.872162 (Thread-1): Parsing macros/etc/query.sql
2020-11-10 09:05:01.873286 (Thread-1): Parsing macros/etc/datetime.sql
2020-11-10 09:05:01.884192 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:05:01.885254 (Thread-1): Parsing macros/etc/is_incremental.sql
2020-11-10 09:05:01.887007 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:05:01.967262 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_by_transaction".
2020-11-10 09:05:02.001258 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.agg_customers".
2020-11-10 09:05:02.021839 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:05:02.040239 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.agg_transactions".
2020-11-10 09:05:02.065141 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:05:02.093001 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc".
2020-11-10 09:05:02.104786 (AgentWriter): reported 75 traces in 0.01144s
2020-11-10 09:05:02.106483 (AgentWriter): initialized RateSampler, sample 100% of traces, 31 additional messages skipped
2020-11-10 09:05:02.113718 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:05:02.134264 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:05:02.162204 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:05:02.190258 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:05:02.218597 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:05:02.244767 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:05:02.271045 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.stores_proc".
2020-11-10 09:05:02.295192 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.monthend_dates".
2020-11-10 09:05:02.317077 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:05:02.340757 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.ga_transactions".
2020-11-10 09:05:02.378385 (Thread-2): handling status request
2020-11-10 09:05:02.378879 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b779b4a8>]}
2020-11-10 09:05:02.380758 (Thread-2): sending response (<Response 184 bytes [200 OK]>) to 10.0.35.67
2020-11-10 09:05:02.389969 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_products_proc".
2020-11-10 09:05:02.413486 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:05:02.433042 (Thread-1): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:05:03.741564 (Thread-3): handling status request
2020-11-10 09:05:03.742134 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6ebfef0>]}
2020-11-10 09:05:03.749843 (Thread-3): sending response (<Response 16162 bytes [200 OK]>) to 10.0.35.171
2020-11-10 09:06:13.090524 (Thread-4): handling status request
2020-11-10 09:06:13.092554 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b77338d0>]}
2020-11-10 09:06:13.100802 (Thread-4): sending response (<Response 16162 bytes [200 OK]>) to 10.0.26.169
2020-11-10 09:06:23.345769 (MainThread): writing 1 spans (enabled:True), 99 additional messages skipped
2020-11-10 09:06:23.345966 (MainThread): 
      name jinja2.compile
        id 2058392945410356548
  trace_id 3214555415330625304
 parent_id None
   service None
  resource <memory>
      type template
     start 1604999183.345104
       end 1604999183.34561
  duration 0.000506s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:db2c4ca49b8b4c2cb4341de9754324c9, 121 additional messages skipped
2020-11-10 09:06:23.380016 (MainThread): Connection 'model.dbt_buyer_segmentation.shopify_orders_proc' was properly closed.
2020-11-10 09:06:23.412899 (Thread-5): Parsing macros/split_part.sql
2020-11-10 09:06:23.418537 (Thread-5): Parsing macros/get_url_parameter.sql
2020-11-10 09:06:23.423631 (Thread-5): Parsing macros/get_column_values.sql
2020-11-10 09:06:23.431468 (Thread-5): Parsing macros/table_exists.sql
2020-11-10 09:06:23.434134 (Thread-5): Parsing macros/adapters.sql
2020-11-10 09:06:23.454425 (Thread-5): Parsing macros/etc.sql
2020-11-10 09:06:23.455880 (Thread-5): Parsing macros/catalog.sql
2020-11-10 09:06:23.461891 (Thread-5): Parsing macros/materializations/table.sql
2020-11-10 09:06:23.475197 (Thread-5): Parsing macros/materializations/view.sql
2020-11-10 09:06:23.478126 (Thread-5): Parsing macros/materializations/copy.sql
2020-11-10 09:06:23.482655 (Thread-5): Parsing macros/materializations/seed.sql
2020-11-10 09:06:23.485533 (Thread-5): Parsing macros/materializations/incremental.sql
2020-11-10 09:06:23.498881 (Thread-5): Parsing macros/materializations/snapshot.sql
2020-11-10 09:06:23.501685 (Thread-5): Parsing macros/core.sql
2020-11-10 09:06:23.505487 (Thread-5): Parsing macros/adapters/common.sql
2020-11-10 09:06:23.551525 (Thread-5): Parsing macros/materializations/helpers.sql
2020-11-10 09:06:23.562442 (Thread-5): Parsing macros/materializations/table/table.sql
2020-11-10 09:06:23.572518 (Thread-5): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:06:23.594747 (Thread-5): Parsing macros/materializations/view/view.sql
2020-11-10 09:06:23.601570 (Thread-5): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:06:23.606848 (Thread-5): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:06:23.608776 (Thread-5): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:06:23.615367 (Thread-5): Parsing macros/materializations/common/merge.sql
2020-11-10 09:06:23.630106 (Thread-5): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:06:23.647265 (Thread-5): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:06:23.649156 (Thread-5): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:06:23.689389 (Thread-5): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:06:23.691522 (Thread-5): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:06:23.693288 (Thread-5): Parsing macros/schema_tests/unique.sql
2020-11-10 09:06:23.695153 (Thread-5): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:06:23.698165 (Thread-5): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:06:23.700087 (Thread-5): Parsing macros/etc/query.sql
2020-11-10 09:06:23.701270 (Thread-5): Parsing macros/etc/datetime.sql
2020-11-10 09:06:23.711058 (Thread-5): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:06:23.712181 (Thread-5): Parsing macros/etc/is_incremental.sql
2020-11-10 09:06:23.713984 (Thread-5): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:06:23.772125 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_by_transaction".
2020-11-10 09:06:23.788371 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.agg_customers".
2020-11-10 09:06:23.803779 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:06:23.819112 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.agg_transactions".
2020-11-10 09:06:23.835528 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:06:23.860195 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc".
2020-11-10 09:06:23.876536 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:06:23.893900 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:06:23.912876 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:06:23.931022 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:06:23.947041 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:06:23.964247 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:06:23.979658 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.stores_proc".
2020-11-10 09:06:23.993794 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.monthend_dates".
2020-11-10 09:06:24.007139 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:06:24.015825 (Thread-6): handling status request
2020-11-10 09:06:24.016247 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6d663c8>]}
2020-11-10 09:06:24.016945 (Thread-6): sending response (<Response 184 bytes [200 OK]>) to 10.0.44.58
2020-11-10 09:06:24.022509 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.ga_transactions".
2020-11-10 09:06:24.045729 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_products_proc".
2020-11-10 09:06:24.069355 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:06:24.096068 (Thread-5): Acquiring new bigquery connection "model.dbt_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:06:24.127686 (AgentWriter): reported 73 traces in 0.00385s, 1 additional messages skipped
2020-11-10 09:06:24.127931 (AgentWriter): initialized RateSampler, sample 100% of traces, 63 additional messages skipped
2020-11-10 09:06:25.384945 (Thread-7): handling status request
2020-11-10 09:06:25.385469 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6d4a518>]}
2020-11-10 09:06:25.391690 (Thread-7): sending response (<Response 16162 bytes [200 OK]>) to 10.0.44.58
2020-11-10 09:06:43.547431 (MainThread): Connection 'model.dbt_buyer_segmentation.shopify_orders_proc' was properly closed.
2020-11-10 09:06:43.581844 (Thread-8): Parsing macros/split_part.sql
2020-11-10 09:06:43.587485 (Thread-8): Parsing macros/get_url_parameter.sql
2020-11-10 09:06:43.592075 (Thread-8): Parsing macros/get_column_values.sql
2020-11-10 09:06:43.598810 (Thread-8): Parsing macros/table_exists.sql
2020-11-10 09:06:43.601418 (Thread-8): Parsing macros/adapters.sql
2020-11-10 09:06:43.621918 (Thread-8): Parsing macros/etc.sql
2020-11-10 09:06:43.623276 (Thread-8): Parsing macros/catalog.sql
2020-11-10 09:06:43.629387 (Thread-8): Parsing macros/materializations/table.sql
2020-11-10 09:06:43.639655 (Thread-8): Parsing macros/materializations/view.sql
2020-11-10 09:06:43.642567 (Thread-8): Parsing macros/materializations/copy.sql
2020-11-10 09:06:43.647077 (Thread-8): Parsing macros/materializations/seed.sql
2020-11-10 09:06:43.649904 (Thread-8): Parsing macros/materializations/incremental.sql
2020-11-10 09:06:43.663295 (Thread-8): Parsing macros/materializations/snapshot.sql
2020-11-10 09:06:43.666807 (Thread-8): Parsing macros/core.sql
2020-11-10 09:06:43.670596 (Thread-8): Parsing macros/adapters/common.sql
2020-11-10 09:06:43.717095 (Thread-8): Parsing macros/materializations/helpers.sql
2020-11-10 09:06:43.726336 (Thread-8): Parsing macros/materializations/table/table.sql
2020-11-10 09:06:43.734036 (Thread-8): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:06:43.758162 (Thread-8): Parsing macros/materializations/view/view.sql
2020-11-10 09:06:43.767662 (Thread-8): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:06:43.775748 (Thread-8): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:06:43.778721 (Thread-8): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:06:43.788843 (Thread-8): Parsing macros/materializations/common/merge.sql
2020-11-10 09:06:43.811246 (Thread-8): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:06:43.828277 (Thread-8): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:06:43.834577 (Thread-8): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:06:43.873187 (Thread-8): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:06:43.875336 (Thread-8): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:06:43.877055 (Thread-8): Parsing macros/schema_tests/unique.sql
2020-11-10 09:06:43.878934 (Thread-8): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:06:43.881808 (Thread-8): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:06:43.883597 (Thread-8): Parsing macros/etc/query.sql
2020-11-10 09:06:43.884724 (Thread-8): Parsing macros/etc/datetime.sql
2020-11-10 09:06:43.894050 (Thread-8): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:06:43.895078 (Thread-8): Parsing macros/etc/is_incremental.sql
2020-11-10 09:06:43.896747 (Thread-8): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:06:43.949848 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:06:43.962046 (Thread-9): handling status request
2020-11-10 09:06:43.968192 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:06:43.968831 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6d78d68>]}
2020-11-10 09:06:43.979269 (Thread-9): sending response (<Response 184 bytes [200 OK]>) to 10.0.44.58
2020-11-10 09:06:43.988487 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:06:44.006185 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:06:44.024711 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:06:44.051732 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:06:44.071109 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:06:44.090682 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:06:44.112412 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:06:44.131742 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:06:44.150984 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:06:44.169145 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:06:44.186893 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:06:44.208157 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:06:44.224843 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:06:44.248091 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:06:44.277083 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:06:44.301338 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:06:44.325056 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:06:45.323695 (Thread-10): handling status request
2020-11-10 09:06:45.324224 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6c0b908>]}
2020-11-10 09:06:45.330505 (Thread-10): sending response (<Response 16238 bytes [200 OK]>) to 10.0.26.169
2020-11-10 09:06:53.403858 (Thread-11): handling status request
2020-11-10 09:06:53.404441 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6c49be0>]}
2020-11-10 09:06:53.410527 (Thread-11): sending response (<Response 16238 bytes [200 OK]>) to 10.0.4.172
2020-11-10 09:07:00.123065 (MainThread): writing 1 spans (enabled:True), 145 additional messages skipped
2020-11-10 09:07:00.123353 (MainThread): 
      name jinja2.compile
        id 4055269352261444997
  trace_id 12838502604795859141
 parent_id None
   service None
  resource <memory>
      type template
     start 1604999220.122119
       end 1604999220.1228518
  duration 0.000733s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:db2c4ca49b8b4c2cb4341de9754324c9, 145 additional messages skipped
2020-11-10 09:07:00.172087 (MainThread): Connection 'model.shopify_buyer_segmentation.shopify_orders_proc' was properly closed.
2020-11-10 09:07:00.174986 (AgentWriter): reported 23 traces in 0.01968s, 2 additional messages skipped
2020-11-10 09:07:00.176000 (AgentWriter): initialized RateSampler, sample 100% of traces, 95 additional messages skipped
2020-11-10 09:07:00.210473 (Thread-12): Parsing macros/split_part.sql
2020-11-10 09:07:00.218363 (Thread-12): Parsing macros/get_url_parameter.sql
2020-11-10 09:07:00.223781 (Thread-12): Parsing macros/get_column_values.sql
2020-11-10 09:07:00.230552 (Thread-12): Parsing macros/table_exists.sql
2020-11-10 09:07:00.233190 (Thread-12): Parsing macros/adapters.sql
2020-11-10 09:07:00.253954 (Thread-12): Parsing macros/etc.sql
2020-11-10 09:07:00.255436 (Thread-12): Parsing macros/catalog.sql
2020-11-10 09:07:00.261606 (Thread-12): Parsing macros/materializations/table.sql
2020-11-10 09:07:00.272208 (Thread-12): Parsing macros/materializations/view.sql
2020-11-10 09:07:00.275262 (Thread-12): Parsing macros/materializations/copy.sql
2020-11-10 09:07:00.280130 (Thread-12): Parsing macros/materializations/seed.sql
2020-11-10 09:07:00.283179 (Thread-12): Parsing macros/materializations/incremental.sql
2020-11-10 09:07:00.297972 (Thread-12): Parsing macros/materializations/snapshot.sql
2020-11-10 09:07:00.301096 (Thread-12): Parsing macros/core.sql
2020-11-10 09:07:00.305148 (Thread-12): Parsing macros/adapters/common.sql
2020-11-10 09:07:00.352265 (Thread-12): Parsing macros/materializations/helpers.sql
2020-11-10 09:07:00.361996 (Thread-12): Parsing macros/materializations/table/table.sql
2020-11-10 09:07:00.369255 (Thread-12): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:07:00.390920 (Thread-12): Parsing macros/materializations/view/view.sql
2020-11-10 09:07:00.397483 (Thread-12): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:07:00.402777 (Thread-12): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:07:00.405705 (Thread-12): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:07:00.412338 (Thread-12): Parsing macros/materializations/common/merge.sql
2020-11-10 09:07:00.427019 (Thread-12): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:07:00.444420 (Thread-12): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:07:00.446602 (Thread-12): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:07:00.476708 (Thread-12): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:07:00.479041 (Thread-12): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:07:00.489855 (Thread-12): Parsing macros/schema_tests/unique.sql
2020-11-10 09:07:00.499611 (Thread-12): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:07:00.502491 (Thread-12): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:07:00.511378 (Thread-12): Parsing macros/etc/query.sql
2020-11-10 09:07:00.519838 (Thread-12): Parsing macros/etc/datetime.sql
2020-11-10 09:07:00.529240 (Thread-12): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:07:00.530299 (Thread-12): Parsing macros/etc/is_incremental.sql
2020-11-10 09:07:00.532237 (Thread-12): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:07:00.667387 (Thread-13): handling status request
2020-11-10 09:07:00.668076 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6e99438>]}
2020-11-10 09:07:00.674119 (Thread-13): sending response (<Response 184 bytes [200 OK]>) to 10.0.21.85
2020-11-10 09:07:00.710095 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:07:00.728722 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:07:00.749521 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:07:00.776146 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:07:00.795845 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:07:00.825234 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:07:00.846319 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:07:00.866307 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:07:00.887624 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:07:00.906458 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:07:00.925960 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:07:00.944429 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:07:00.962239 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:07:00.979366 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:07:00.995607 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:07:01.012811 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:07:01.038134 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:07:01.061022 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:07:01.081878 (Thread-12): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:07:02.195114 (Thread-14): handling status request
2020-11-10 09:07:02.195634 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b7759ba8>]}
2020-11-10 09:07:02.202382 (Thread-14): sending response (<Response 16293 bytes [200 OK]>) to 10.0.10.5
2020-11-10 09:07:13.383705 (Thread-15): handling status request
2020-11-10 09:07:13.384189 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6cffe10>]}
2020-11-10 09:07:13.390255 (Thread-15): sending response (<Response 16293 bytes [200 OK]>) to 10.0.26.169
2020-11-10 09:07:13.733446 (Thread-16): handling compile_sql request
2020-11-10 09:07:13.733929 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '56deaa25-48c5-4ed6-93a8-fc33721f7e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6b6e992e8>]}
2020-11-10 09:07:13.734463 (Thread-16): sending response (<Response 746 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:07:53.855093 (MainThread): Running with dbt=0.18.1
2020-11-10 09:07:54.126998 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2020-11-10 09:07:54.145067 (MainThread): Tracking: tracking
2020-11-10 09:07:54.157614 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff452a71780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff452ab46a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff452ad1eb8>]}
2020-11-10 09:07:54.158012 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=13
2020-11-10 09:07:54.158666 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2020-11-10 09:07:54.159147 (MainThread): Send requests to http://localhost:8580/jsonrpc
2020-11-10 09:07:54.168139 (Thread-1): Parsing macros/split_part.sql
2020-11-10 09:07:54.175635 (Thread-1): Parsing macros/get_url_parameter.sql
2020-11-10 09:07:54.180956 (Thread-1): Parsing macros/get_column_values.sql
2020-11-10 09:07:54.192192 (Thread-1): Parsing macros/table_exists.sql
2020-11-10 09:07:54.195073 (Thread-1): Parsing macros/adapters.sql
2020-11-10 09:07:54.221639 (Thread-1): Parsing macros/etc.sql
2020-11-10 09:07:54.223638 (Thread-1): Parsing macros/catalog.sql
2020-11-10 09:07:54.233096 (Thread-1): Parsing macros/materializations/table.sql
2020-11-10 09:07:54.250902 (Thread-1): Parsing macros/materializations/view.sql
2020-11-10 09:07:54.255973 (Thread-1): Parsing macros/materializations/copy.sql
2020-11-10 09:07:54.263901 (Thread-1): Parsing macros/materializations/seed.sql
2020-11-10 09:07:54.268777 (Thread-1): Parsing macros/materializations/incremental.sql
2020-11-10 09:07:54.291896 (Thread-1): Parsing macros/materializations/snapshot.sql
2020-11-10 09:07:54.296768 (Thread-1): Parsing macros/core.sql
2020-11-10 09:07:54.303248 (Thread-1): Parsing macros/adapters/common.sql
2020-11-10 09:07:54.351496 (Thread-1): Parsing macros/materializations/helpers.sql
2020-11-10 09:07:54.362522 (Thread-1): Parsing macros/materializations/table/table.sql
2020-11-10 09:07:54.369702 (Thread-1): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:07:54.390966 (Thread-1): Parsing macros/materializations/view/view.sql
2020-11-10 09:07:54.397461 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:07:54.402722 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:07:54.404703 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:07:54.411548 (Thread-1): Parsing macros/materializations/common/merge.sql
2020-11-10 09:07:54.426081 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:07:54.443381 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:07:54.445308 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:07:54.474667 (Thread-1): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:07:54.476789 (Thread-1): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:07:54.478430 (Thread-1): Parsing macros/schema_tests/unique.sql
2020-11-10 09:07:54.480304 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:07:54.483314 (Thread-1): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:07:54.485279 (Thread-1): Parsing macros/etc/query.sql
2020-11-10 09:07:54.486520 (Thread-1): Parsing macros/etc/datetime.sql
2020-11-10 09:07:54.496027 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:07:54.497060 (Thread-1): Parsing macros/etc/is_incremental.sql
2020-11-10 09:07:54.498760 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:07:54.570324 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:07:54.600438 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:07:54.620006 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:07:54.640844 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:07:54.660532 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:07:54.681257 (Thread-2): handling status request
2020-11-10 09:07:54.681684 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'aba92477-19b7-4db4-be50-717d910a7e8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4520d9160>]}
2020-11-10 09:07:54.683653 (Thread-2): sending response (<Response 184 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:07:54.693677 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:07:54.724081 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:07:54.751844 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:07:54.773694 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:07:54.794441 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:07:54.813922 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:07:54.832438 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:07:54.850307 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:07:54.868029 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:07:54.884925 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:07:54.902400 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:07:54.937996 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:07:54.961665 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:07:54.983640 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:07:56.039434 (Thread-3): handling status request
2020-11-10 09:07:56.039996 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'aba92477-19b7-4db4-be50-717d910a7e8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4517e1908>]}
2020-11-10 09:07:56.047120 (Thread-3): sending response (<Response 16238 bytes [200 OK]>) to 10.0.10.5
2020-11-10 09:10:28.260893 (MainThread): Running with dbt=0.18.1
2020-11-10 09:10:28.522783 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2020-11-10 09:10:28.537304 (MainThread): Tracking: tracking
2020-11-10 09:10:28.548031 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2671d6d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb26761be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb26761ba8>]}
2020-11-10 09:10:28.548425 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=13
2020-11-10 09:10:28.548894 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2020-11-10 09:10:28.549276 (MainThread): Send requests to http://localhost:8580/jsonrpc
2020-11-10 09:10:28.558722 (Thread-1): Parsing macros/split_part.sql
2020-11-10 09:10:28.565123 (Thread-1): Parsing macros/get_url_parameter.sql
2020-11-10 09:10:28.570120 (Thread-1): Parsing macros/get_column_values.sql
2020-11-10 09:10:28.577341 (Thread-1): Parsing macros/table_exists.sql
2020-11-10 09:10:28.581044 (Thread-1): Parsing macros/adapters.sql
2020-11-10 09:10:28.605518 (Thread-1): Parsing macros/etc.sql
2020-11-10 09:10:28.607046 (Thread-1): Parsing macros/catalog.sql
2020-11-10 09:10:28.614434 (Thread-1): Parsing macros/materializations/table.sql
2020-11-10 09:10:28.626550 (Thread-1): Parsing macros/materializations/view.sql
2020-11-10 09:10:28.630059 (Thread-1): Parsing macros/materializations/copy.sql
2020-11-10 09:10:28.635321 (Thread-1): Parsing macros/materializations/seed.sql
2020-11-10 09:10:28.638313 (Thread-1): Parsing macros/materializations/incremental.sql
2020-11-10 09:10:28.651461 (Thread-1): Parsing macros/materializations/snapshot.sql
2020-11-10 09:10:28.654325 (Thread-1): Parsing macros/core.sql
2020-11-10 09:10:28.658133 (Thread-1): Parsing macros/adapters/common.sql
2020-11-10 09:10:28.703879 (Thread-1): Parsing macros/materializations/helpers.sql
2020-11-10 09:10:28.715775 (Thread-1): Parsing macros/materializations/table/table.sql
2020-11-10 09:10:28.724750 (Thread-1): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:10:28.752126 (Thread-1): Parsing macros/materializations/view/view.sql
2020-11-10 09:10:28.759903 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:10:28.765028 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:10:28.766984 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:10:28.773761 (Thread-1): Parsing macros/materializations/common/merge.sql
2020-11-10 09:10:28.788031 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:10:28.805558 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:10:28.807465 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:10:28.839160 (Thread-1): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:10:28.844100 (Thread-1): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:10:28.845779 (Thread-1): Parsing macros/schema_tests/unique.sql
2020-11-10 09:10:28.847604 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:10:28.850453 (Thread-1): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:10:28.852211 (Thread-1): Parsing macros/etc/query.sql
2020-11-10 09:10:28.853338 (Thread-1): Parsing macros/etc/datetime.sql
2020-11-10 09:10:28.867320 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:10:28.868905 (Thread-1): Parsing macros/etc/is_incremental.sql
2020-11-10 09:10:28.871623 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:10:28.951229 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:10:28.981106 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:10:28.999833 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:10:29.018443 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:10:29.037278 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:10:29.064329 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:10:29.075513 (Thread-2): handling status request
2020-11-10 09:10:29.075922 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25d1b7f0>]}
2020-11-10 09:10:29.077925 (Thread-2): sending response (<Response 184 bytes [200 OK]>) to 10.0.21.85
2020-11-10 09:10:29.084295 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:10:29.103320 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:10:29.124240 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:10:29.143717 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:10:29.162488 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:10:29.180885 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:10:29.200781 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:10:29.223120 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:10:29.242543 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:10:29.259484 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:10:29.295444 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:10:29.327601 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:10:29.349712 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:10:30.372223 (Thread-3): handling status request
2020-11-10 09:10:30.372806 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25492390>]}
2020-11-10 09:10:30.378894 (Thread-3): sending response (<Response 16238 bytes [200 OK]>) to 10.0.25.53
2020-11-10 09:12:40.847210 (MainThread): writing 1 spans (enabled:True), 113 additional messages skipped
2020-11-10 09:12:40.849024 (MainThread): 
      name jinja2.compile
        id 7192758563566238712
  trace_id 3812311705783743227
 parent_id None
   service None
  resource <memory>
      type template
     start 1604999560.846503
       end 1604999560.847028
  duration 0.000525s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:b02e17b6d3404bcea8c7363c41b00add, 147 additional messages skipped
2020-11-10 09:12:40.886549 (MainThread): Connection 'model.shopify_buyer_segmentation.shopify_orders_proc' was properly closed.
2020-11-10 09:12:40.901825 (AgentWriter): reported 28 traces in 0.02620s, 2 additional messages skipped
2020-11-10 09:12:40.902907 (AgentWriter): initialized RateSampler, sample 100% of traces, 95 additional messages skipped
2020-11-10 09:12:40.925447 (Thread-4): Parsing macros/split_part.sql
2020-11-10 09:12:40.931704 (Thread-4): Parsing macros/get_url_parameter.sql
2020-11-10 09:12:40.936227 (Thread-4): Parsing macros/get_column_values.sql
2020-11-10 09:12:40.943145 (Thread-4): Parsing macros/table_exists.sql
2020-11-10 09:12:40.945668 (Thread-4): Parsing macros/adapters.sql
2020-11-10 09:12:40.965538 (Thread-4): Parsing macros/etc.sql
2020-11-10 09:12:40.966863 (Thread-4): Parsing macros/catalog.sql
2020-11-10 09:12:40.973218 (Thread-4): Parsing macros/materializations/table.sql
2020-11-10 09:12:40.983353 (Thread-4): Parsing macros/materializations/view.sql
2020-11-10 09:12:40.986368 (Thread-4): Parsing macros/materializations/copy.sql
2020-11-10 09:12:40.990875 (Thread-4): Parsing macros/materializations/seed.sql
2020-11-10 09:12:40.993654 (Thread-4): Parsing macros/materializations/incremental.sql
2020-11-10 09:12:41.006881 (Thread-4): Parsing macros/materializations/snapshot.sql
2020-11-10 09:12:41.009670 (Thread-4): Parsing macros/core.sql
2020-11-10 09:12:41.013499 (Thread-4): Parsing macros/adapters/common.sql
2020-11-10 09:12:41.057996 (Thread-4): Parsing macros/materializations/helpers.sql
2020-11-10 09:12:41.068115 (Thread-4): Parsing macros/materializations/table/table.sql
2020-11-10 09:12:41.075170 (Thread-4): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:12:41.096666 (Thread-4): Parsing macros/materializations/view/view.sql
2020-11-10 09:12:41.103088 (Thread-4): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:12:41.108209 (Thread-4): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:12:41.110175 (Thread-4): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:12:41.116559 (Thread-4): Parsing macros/materializations/common/merge.sql
2020-11-10 09:12:41.130943 (Thread-4): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:12:41.148718 (Thread-4): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:12:41.150607 (Thread-4): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:12:41.180434 (Thread-4): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:12:41.182456 (Thread-4): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:12:41.184082 (Thread-4): Parsing macros/schema_tests/unique.sql
2020-11-10 09:12:41.185896 (Thread-4): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:12:41.188792 (Thread-4): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:12:41.190581 (Thread-4): Parsing macros/etc/query.sql
2020-11-10 09:12:41.191692 (Thread-4): Parsing macros/etc/datetime.sql
2020-11-10 09:12:41.200787 (Thread-4): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:12:41.201808 (Thread-4): Parsing macros/etc/is_incremental.sql
2020-11-10 09:12:41.203481 (Thread-4): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:12:41.259171 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:12:41.276944 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:12:41.294546 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:12:41.312033 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:12:41.330639 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:12:41.356969 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:12:41.397169 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:12:41.419346 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:12:41.447665 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:12:41.473424 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:12:41.515514 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:12:41.550519 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:12:41.557448 (Thread-5): handling status request
2020-11-10 09:12:41.594191 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:12:41.594595 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25334748>]}
2020-11-10 09:12:41.603972 (Thread-5): sending response (<Response 184 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:12:41.611688 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:12:41.627779 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:12:41.644815 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:12:41.669322 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:12:41.691330 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:12:41.710898 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:12:41.734492 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_refunds_proc".
2020-11-10 09:12:41.754588 (Thread-4): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_customers_proc".
2020-11-10 09:12:43.021923 (Thread-6): handling status request
2020-11-10 09:12:43.022432 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb251d7438>]}
2020-11-10 09:12:43.028526 (Thread-6): sending response (<Response 16671 bytes [200 OK]>) to 10.0.6.63
2020-11-10 09:13:02.717668 (Thread-7): handling status request
2020-11-10 09:13:02.721768 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb251d3d68>]}
2020-11-10 09:13:02.727840 (Thread-7): sending response (<Response 16671 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:13:09.365402 (MainThread): writing 1 spans (enabled:True), 77 additional messages skipped
2020-11-10 09:13:09.365595 (MainThread): 
      name jinja2.compile
        id 18360795908025693097
  trace_id 14778299025611851285
 parent_id None
   service None
  resource <memory>
      type template
     start 1604999589.3647318
       end 1604999589.3652458
  duration 0.000514s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:b02e17b6d3404bcea8c7363c41b00add, 77 additional messages skipped
2020-11-10 09:13:09.398525 (MainThread): Connection 'model.shopify_buyer_segmentation.shopify_customers_proc' was properly closed.
2020-11-10 09:13:09.432122 (Thread-8): Parsing macros/split_part.sql
2020-11-10 09:13:09.437893 (Thread-8): Parsing macros/get_url_parameter.sql
2020-11-10 09:13:09.442490 (Thread-8): Parsing macros/get_column_values.sql
2020-11-10 09:13:09.449382 (Thread-8): Parsing macros/table_exists.sql
2020-11-10 09:13:09.451899 (Thread-8): Parsing macros/adapters.sql
2020-11-10 09:13:09.471450 (Thread-8): Parsing macros/etc.sql
2020-11-10 09:13:09.472797 (Thread-8): Parsing macros/catalog.sql
2020-11-10 09:13:09.478764 (Thread-8): Parsing macros/materializations/table.sql
2020-11-10 09:13:09.488769 (Thread-8): Parsing macros/materializations/view.sql
2020-11-10 09:13:09.491628 (Thread-8): Parsing macros/materializations/copy.sql
2020-11-10 09:13:09.496012 (Thread-8): Parsing macros/materializations/seed.sql
2020-11-10 09:13:09.498890 (Thread-8): Parsing macros/materializations/incremental.sql
2020-11-10 09:13:09.511873 (Thread-8): Parsing macros/materializations/snapshot.sql
2020-11-10 09:13:09.514651 (Thread-8): Parsing macros/core.sql
2020-11-10 09:13:09.518572 (Thread-8): Parsing macros/adapters/common.sql
2020-11-10 09:13:09.562710 (Thread-8): Parsing macros/materializations/helpers.sql
2020-11-10 09:13:09.571918 (Thread-8): Parsing macros/materializations/table/table.sql
2020-11-10 09:13:09.579306 (Thread-8): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:13:09.605646 (Thread-8): Parsing macros/materializations/view/view.sql
2020-11-10 09:13:09.615364 (Thread-8): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:13:09.622926 (Thread-8): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:13:09.625703 (Thread-8): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:13:09.635405 (Thread-8): Parsing macros/materializations/common/merge.sql
2020-11-10 09:13:09.651836 (Thread-8): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:13:09.668749 (Thread-8): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:13:09.670621 (Thread-8): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:13:09.699553 (Thread-8): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:13:09.710742 (Thread-8): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:13:09.747884 (Thread-8): Parsing macros/schema_tests/unique.sql
2020-11-10 09:13:09.749684 (Thread-8): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:13:09.752496 (Thread-8): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:13:09.774182 (Thread-9): handling status request
2020-11-10 09:13:09.792910 (Thread-8): Parsing macros/etc/query.sql
2020-11-10 09:13:09.814538 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25364b00>]}
2020-11-10 09:13:09.816387 (Thread-9): sending response (<Response 184 bytes [200 OK]>) to 10.0.36.232
2020-11-10 09:13:09.816976 (Thread-8): Parsing macros/etc/datetime.sql
2020-11-10 09:13:09.826569 (Thread-8): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:13:09.827600 (Thread-8): Parsing macros/etc/is_incremental.sql
2020-11-10 09:13:09.829367 (Thread-8): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:13:09.885671 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:13:09.903674 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:13:09.915960 (AgentWriter): reported 42 traces in 0.00319s, 1 additional messages skipped
2020-11-10 09:13:09.920899 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:13:09.921121 (AgentWriter): initialized RateSampler, sample 100% of traces, 63 additional messages skipped
2020-11-10 09:13:09.938509 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:13:09.957546 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:13:09.983977 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:13:10.103554 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:13:10.122460 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:13:10.143054 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:13:10.161710 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:13:10.180641 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:13:10.198455 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:13:10.215693 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:13:10.232453 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:13:10.248357 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:13:10.264707 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:13:10.288670 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:13:10.311495 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:13:10.331820 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:13:10.355163 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_refunds_proc".
2020-11-10 09:13:10.374976 (Thread-8): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_customers_proc".
2020-11-10 09:13:11.216146 (Thread-10): handling status request
2020-11-10 09:13:11.216644 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2535be48>]}
2020-11-10 09:13:11.222917 (Thread-10): sending response (<Response 16671 bytes [200 OK]>) to 10.0.10.5
2020-11-10 09:15:42.197850 (Thread-11): handling status request
2020-11-10 09:15:42.198529 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2535be48>]}
2020-11-10 09:15:42.210075 (Thread-11): sending response (<Response 16671 bytes [200 OK]>) to 10.0.44.58
2020-11-10 09:17:30.092541 (MainThread): writing 1 spans (enabled:True), 77 additional messages skipped
2020-11-10 09:17:30.094231 (MainThread): 
      name jinja2.compile
        id 1947468539536799514
  trace_id 11992088854260170642
 parent_id None
   service None
  resource <memory>
      type template
     start 1604999850.091871
       end 1604999850.092385
  duration 0.000514s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:b02e17b6d3404bcea8c7363c41b00add, 77 additional messages skipped
2020-11-10 09:17:30.127132 (MainThread): Connection 'model.shopify_buyer_segmentation.shopify_customers_proc' was properly closed.
2020-11-10 09:17:30.197929 (Thread-12): Got an acceptable cached parse result
2020-11-10 09:17:30.837218 (Thread-13): handling status request
2020-11-10 09:17:30.837700 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2524b6d8>]}
2020-11-10 09:17:30.838627 (Thread-13): sending response (<Response 446 bytes [200 OK]>) to 10.0.11.107
2020-11-10 09:17:30.974220 (AgentWriter): reported 38 traces in 0.00409s, 1 additional messages skipped
2020-11-10 09:17:30.974457 (AgentWriter): initialized RateSampler, sample 100% of traces, 63 additional messages skipped
2020-11-10 09:17:48.667350 (Thread-14): handling status request
2020-11-10 09:17:48.667864 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb250ccda0>]}
2020-11-10 09:17:48.668760 (Thread-14): sending response (<Response 446 bytes [200 OK]>) to 10.0.25.53
2020-11-10 09:17:48.872686 (Thread-15): handling ps request
2020-11-10 09:17:48.873192 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb250cc978>]}
2020-11-10 09:17:48.875154 (Thread-15): sending response (<Response 104 bytes [200 OK]>) to 10.0.4.172
2020-11-10 09:23:54.617336 (Thread-16): handling status request
2020-11-10 09:23:54.619825 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb250cc518>]}
2020-11-10 09:23:54.620720 (Thread-16): sending response (<Response 446 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:24:00.329483 (MainThread): writing 1 spans (enabled:True), 37 additional messages skipped
2020-11-10 09:24:00.329679 (MainThread): 
      name jinja2.compile
        id 12757058343043350431
  trace_id 4128362950296987134
 parent_id None
   service None
  resource <memory>
      type template
     start 1605000240.328789
       end 1605000240.329314
  duration 0.000525s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:b02e17b6d3404bcea8c7363c41b00add, 37 additional messages skipped
2020-11-10 09:24:00.398590 (Thread-17): Parsing macros/split_part.sql
2020-11-10 09:24:00.404502 (Thread-17): Parsing macros/get_url_parameter.sql
2020-11-10 09:24:00.409350 (Thread-17): Parsing macros/get_column_values.sql
2020-11-10 09:24:00.417612 (Thread-17): Parsing macros/table_exists.sql
2020-11-10 09:24:00.420314 (Thread-17): Parsing macros/adapters.sql
2020-11-10 09:24:00.441249 (Thread-17): Parsing macros/etc.sql
2020-11-10 09:24:00.442740 (Thread-17): Parsing macros/catalog.sql
2020-11-10 09:24:00.449125 (Thread-17): Parsing macros/materializations/table.sql
2020-11-10 09:24:00.459919 (Thread-17): Parsing macros/materializations/view.sql
2020-11-10 09:24:00.463031 (Thread-17): Parsing macros/materializations/copy.sql
2020-11-10 09:24:00.467820 (Thread-17): Parsing macros/materializations/seed.sql
2020-11-10 09:24:00.470801 (Thread-17): Parsing macros/materializations/incremental.sql
2020-11-10 09:24:00.484695 (Thread-17): Parsing macros/materializations/snapshot.sql
2020-11-10 09:24:00.487676 (Thread-17): Parsing macros/core.sql
2020-11-10 09:24:00.491723 (Thread-17): Parsing macros/adapters/common.sql
2020-11-10 09:24:00.538542 (Thread-17): Parsing macros/materializations/helpers.sql
2020-11-10 09:24:00.548475 (Thread-17): Parsing macros/materializations/table/table.sql
2020-11-10 09:24:00.555906 (Thread-17): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:24:00.578679 (Thread-17): Parsing macros/materializations/view/view.sql
2020-11-10 09:24:00.594811 (Thread-17): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:24:00.602000 (Thread-17): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:24:00.612031 (Thread-17): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:24:00.626643 (Thread-17): Parsing macros/materializations/common/merge.sql
2020-11-10 09:24:00.641276 (Thread-17): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:24:00.679143 (Thread-17): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:24:00.682067 (Thread-17): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:24:00.712565 (Thread-17): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:24:00.714607 (Thread-17): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:24:00.716225 (Thread-17): Parsing macros/schema_tests/unique.sql
2020-11-10 09:24:00.726084 (Thread-17): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:24:00.728881 (Thread-17): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:24:00.730685 (Thread-17): Parsing macros/etc/query.sql
2020-11-10 09:24:00.731798 (Thread-17): Parsing macros/etc/datetime.sql
2020-11-10 09:24:00.741090 (Thread-17): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:24:00.742154 (Thread-17): Parsing macros/etc/is_incremental.sql
2020-11-10 09:24:00.743845 (Thread-17): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:24:00.801967 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:24:00.820036 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:24:00.838514 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:24:00.856229 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:24:00.874725 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:24:00.893839 (Thread-18): handling status request
2020-11-10 09:24:00.894392 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24fb7240>]}
2020-11-10 09:24:00.895302 (Thread-18): sending response (<Response 184 bytes [200 OK]>) to 10.0.35.67
2020-11-10 09:24:00.901693 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:24:00.921081 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:24:00.939888 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:24:00.960973 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:24:00.979905 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:24:00.999177 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:24:01.016529 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:24:01.025815 (AgentWriter): reported 60 traces in 0.00409s
2020-11-10 09:24:01.035509 (AgentWriter): initialized RateSampler, sample 100% of traces, 31 additional messages skipped
2020-11-10 09:24:01.043880 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:24:01.060420 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:24:01.075696 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:24:01.093366 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:24:01.120685 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:24:01.143059 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:24:01.162444 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:24:01.185900 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_refunds_proc".
2020-11-10 09:24:01.205420 (Thread-17): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_customers_proc".
2020-11-10 09:24:02.317386 (Thread-19): handling status request
2020-11-10 09:24:02.317933 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24e2f2b0>]}
2020-11-10 09:24:02.324058 (Thread-19): sending response (<Response 16728 bytes [200 OK]>) to 10.0.36.232
2020-11-10 09:24:06.094267 (Thread-20): handling status request
2020-11-10 09:24:06.094771 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24e2ff98>]}
2020-11-10 09:24:06.100866 (Thread-20): sending response (<Response 16728 bytes [200 OK]>) to 10.0.11.107
2020-11-10 09:24:06.118059 (Thread-21): handling status request
2020-11-10 09:24:06.118467 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24e21b00>]}
2020-11-10 09:24:06.124507 (Thread-21): sending response (<Response 16728 bytes [200 OK]>) to 10.0.6.63
2020-11-10 09:24:06.446960 (Thread-22): handling cli_args request
2020-11-10 09:24:06.447458 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24e1ab38>]}
2020-11-10 09:24:06.458063 (Thread-22): Connection 'model.shopify_buyer_segmentation.shopify_customers_proc' was properly closed.
2020-11-10 09:24:07.387353 (Thread-22): sending response (<Response 137 bytes [200 OK]>) to 10.0.4.172
2020-11-10 09:24:07.453782 (MainThread): Partial parsing not enabled
2020-11-10 09:24:07.459823 (MainThread): Parsing macros/split_part.sql
2020-11-10 09:24:07.466303 (MainThread): Parsing macros/get_url_parameter.sql
2020-11-10 09:24:07.471628 (MainThread): Parsing macros/get_column_values.sql
2020-11-10 09:24:07.478937 (MainThread): Parsing macros/table_exists.sql
2020-11-10 09:24:07.481450 (MainThread): Parsing macros/adapters.sql
2020-11-10 09:24:07.501197 (MainThread): Parsing macros/etc.sql
2020-11-10 09:24:07.502590 (MainThread): Parsing macros/catalog.sql
2020-11-10 09:24:07.508618 (MainThread): Parsing macros/materializations/table.sql
2020-11-10 09:24:07.519091 (MainThread): Parsing macros/materializations/view.sql
2020-11-10 09:24:07.522060 (MainThread): Parsing macros/materializations/copy.sql
2020-11-10 09:24:07.526608 (MainThread): Parsing macros/materializations/seed.sql
2020-11-10 09:24:07.529461 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-10 09:24:07.542587 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-10 09:24:07.545576 (MainThread): Parsing macros/core.sql
2020-11-10 09:24:07.549503 (MainThread): Parsing macros/adapters/common.sql
2020-11-10 09:24:07.594106 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-10 09:24:07.603569 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-10 09:24:07.610985 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:24:07.632419 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-10 09:24:07.639097 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:24:07.644263 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:24:07.646335 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:24:07.652912 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-10 09:24:07.667344 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:24:07.684299 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:24:07.686248 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:24:07.715553 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:24:07.717661 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:24:07.719413 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-10 09:24:07.721345 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:24:07.724282 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:24:07.727309 (Thread-23): handling poll request
2020-11-10 09:24:07.726218 (MainThread): Parsing macros/etc/query.sql
2020-11-10 09:24:07.728040 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24fc7b70>]}
2020-11-10 09:24:07.734533 (Thread-23): sending response (<Response 9329 bytes [200 OK]>) to 10.0.35.171
2020-11-10 09:24:07.727498 (MainThread): Parsing macros/etc/datetime.sql
2020-11-10 09:24:07.737019 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:24:07.738243 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-10 09:24:07.740131 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:24:07.752223 (MainThread): Partial parsing not enabled
2020-11-10 09:24:07.814160 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:24:07.841817 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:24:07.858889 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:24:07.876267 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:24:07.894776 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:24:07.920481 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:24:07.938803 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:24:07.957548 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:24:07.978327 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:24:07.997012 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:24:08.015279 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:24:08.033361 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:24:08.050530 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:24:08.066959 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:24:08.083058 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:24:08.099525 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:24:08.133301 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:24:08.155374 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:24:08.175084 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:24:08.198853 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_refunds_proc".
2020-11-10 09:24:08.219683 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_customers_proc".
2020-11-10 09:24:08.529212 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 161 macros, 0 operations, 0 seed files, 0 sources
2020-11-10 09:24:08.531594 (MainThread): 
2020-11-10 09:24:08.531925 (MainThread): Acquiring new bigquery connection "master".
2020-11-10 09:24:08.566114 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-projects".
2020-11-10 09:24:08.566258 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-11-10 09:24:08.818923 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-projects_dbt_buyer_segmentation".
2020-11-10 09:24:08.819194 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-projects_dbt_buyer_segmentation".
2020-11-10 09:24:08.819260 (ThreadPoolExecutor-0_0): Creating schema "dbt-projects.dbt_buyer_segmentation".
2020-11-10 09:24:08.819326 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-11-10 09:24:08.819789 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-10 09:24:09.071977 (Thread-24): handling poll request
2020-11-10 09:24:09.072463 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24f73b00>]}
2020-11-10 09:24:09.076811 (Thread-24): sending response (<Response 11139 bytes [200 OK]>) to 10.0.11.107
2020-11-10 09:24:09.262363 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-projects_dbt_buyer_segmentation".
2020-11-10 09:24:09.262506 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-11-10 09:24:09.263034 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-10 09:24:09.482726 (MainThread): 09:24:09 | Concurrency: 1 threads (target='default')
2020-11-10 09:24:09.482870 (MainThread): 09:24:09 | 
2020-11-10 09:24:09.484652 (Thread-1): Began running node model.shopify_buyer_segmentation.stores_proc
2020-11-10 09:24:09.485945 (Thread-1): 09:24:09 | 1 of 21 START table model dbt_buyer_segmentation.stores_proc......... [RUN]
2020-11-10 09:24:09.486238 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:24:09.486537 (Thread-1): Compiling model.shopify_buyer_segmentation.stores_proc
2020-11-10 09:24:09.502168 (Thread-1): Writing injected SQL for node "model.shopify_buyer_segmentation.stores_proc"
2020-11-10 09:24:09.541265 (Thread-1): finished collecting timing info
2020-11-10 09:24:09.574901 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.250', 59406), raddr=('172.217.7.170', 443)>
2020-11-10 09:24:09.575197 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.250', 47454), raddr=('172.217.9.202', 443)>
2020-11-10 09:24:09.575429 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.250', 59420), raddr=('172.217.7.170', 443)>
2020-11-10 09:24:09.575635 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.250', 43130), raddr=('172.217.2.106', 443)>
2020-11-10 09:24:09.578872 (Thread-1): Writing runtime SQL for node "model.shopify_buyer_segmentation.stores_proc"
2020-11-10 09:24:09.617646 (Thread-1): Opening a new connection, currently in state closed
2020-11-10 09:24:09.618103 (Thread-1): On model.shopify_buyer_segmentation.stores_proc: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.stores_proc"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`stores_proc`
  
  
  OPTIONS()
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
store,
bigquery_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
FROM `dbt-projects.agency_data_pipeline.data_feeds` 
where store_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );
    
2020-11-10 09:24:10.401090 (Thread-25): handling poll request
2020-11-10 09:24:10.401586 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2500e898>]}
2020-11-10 09:24:10.403911 (Thread-25): sending response (<Response 5864 bytes [200 OK]>) to 10.0.3.8
2020-11-10 09:24:10.434141 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dbt-projects/queries/92f22607-7417-472d-aa1d-fa03bb28fde8?maxResults=0&location=US&prettyPrint=false: Unrecognized name: store_name at [26:7]',)
2020-11-10 09:24:11.363965 (Thread-1): finished collecting timing info
2020-11-10 09:24:11.364583 (Thread-1): Database Error in model stores_proc (models/admin/stores_proc.sql)
  Unrecognized name: store_name at [26:7]
  compiled SQL at target/run/shopify_buyer_segmentation/models/admin/stores_proc.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/_http.py", line 435, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/dbt-projects/queries/d052b68f-05f2-428f-a7cb-fd246cf898ae?maxResults=0&location=US&prettyPrint=false: Unrecognized name: store_name at [26:7]

(job ID: d052b68f-05f2-428f-a7cb-fd246cf898ae)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.stores_proc"} */
   2:
   3:
   4:  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`stores_proc`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    select 
  10:store,
  11:store_name,
  12:account,
  13:platform,
  14:max(time_of_entry) time_of_entry
  15:
  16:from  ( 
  17:
  18:SELECT  
  19:store,
  20:bigquery_name store_name,
  21:account,
  22:platform,
  23:time_of_entry,
  24:first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
  25:FROM `dbt-projects.agency_data_pipeline.data_feeds` 
  26:where store_name != ''
  27:
  28:) 
  29:
  30:WHERE lv = time_of_entry
  31:group by store, store_name, account, platform
  32:  );
  33:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stores_proc (models/admin/stores_proc.sql)
  Unrecognized name: store_name at [26:7]
  compiled SQL at target/run/shopify_buyer_segmentation/models/admin/stores_proc.sql
2020-11-10 09:24:11.367272 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69be6c07-c976-40e4-8b4a-e37a674c41ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bbe182c88>]}
2020-11-10 09:24:11.368476 (Thread-1): 09:24:11 | 1 of 21 ERROR creating table model dbt_buyer_segmentation.stores_proc [ERROR in 1.88s]
2020-11-10 09:24:11.368577 (Thread-1): Finished running node model.shopify_buyer_segmentation.stores_proc
2020-11-10 09:24:11.368707 (Thread-1): Began running node model.shopify_buyer_segmentation.mappings_ga_proc
2020-11-10 09:24:11.370196 (Thread-1): 09:24:11 | 2 of 21 START table model dbt_buyer_segmentation.mappings_ga_proc.... [RUN]
2020-11-10 09:24:11.370519 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:24:11.370615 (Thread-1): Compiling model.shopify_buyer_segmentation.mappings_ga_proc
2020-11-10 09:24:11.378422 (Thread-1): Writing injected SQL for node "model.shopify_buyer_segmentation.mappings_ga_proc"
2020-11-10 09:24:11.390436 (Thread-1): finished collecting timing info
2020-11-10 09:24:11.396698 (Thread-1): Writing runtime SQL for node "model.shopify_buyer_segmentation.mappings_ga_proc"
2020-11-10 09:24:11.409395 (Thread-1): Opening a new connection, currently in state closed
2020-11-10 09:24:11.409793 (Thread-1): On model.shopify_buyer_segmentation.mappings_ga_proc: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.mappings_ga_proc"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`mappings_ga_proc`
  
  
  OPTIONS()
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
store,
account,
bigquery_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
FROM `dbt-projects.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );
    
2020-11-10 09:24:11.748799 (Thread-26): handling poll request
2020-11-10 09:24:11.749282 (Thread-26): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24f504a8>]}
2020-11-10 09:24:11.751857 (Thread-26): sending response (<Response 16084 bytes [200 OK]>) to 10.0.4.172
2020-11-10 09:24:13.123672 (Thread-27): handling poll request
2020-11-10 09:24:13.124176 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2500e198>]}
2020-11-10 09:24:13.125194 (Thread-27): sending response (<Response 287 bytes [200 OK]>) to 10.0.25.53
2020-11-10 09:24:13.209422 (Thread-1): finished collecting timing info
2020-11-10 09:24:13.210192 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69be6c07-c976-40e4-8b4a-e37a674c41ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bbdf519e8>]}
2020-11-10 09:24:13.211320 (Thread-1): 09:24:13 | 2 of 21 OK created table model dbt_buyer_segmentation.mappings_ga_proc [CREATE TABLE (10.0 rows, 910.0 Bytes processed) in 1.84s]
2020-11-10 09:24:13.211422 (Thread-1): Finished running node model.shopify_buyer_segmentation.mappings_ga_proc
2020-11-10 09:24:13.211550 (Thread-1): Began running node model.shopify_buyer_segmentation.monthend_dates
2020-11-10 09:24:13.212456 (Thread-1): 09:24:13 | 3 of 21 START table model dbt_buyer_segmentation.monthend_dates...... [RUN]
2020-11-10 09:24:13.212688 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:24:13.212770 (Thread-1): Compiling model.shopify_buyer_segmentation.monthend_dates
2020-11-10 09:24:13.218939 (Thread-1): Writing injected SQL for node "model.shopify_buyer_segmentation.monthend_dates"
2020-11-10 09:24:13.231038 (Thread-1): finished collecting timing info
2020-11-10 09:24:13.235547 (Thread-1): Writing runtime SQL for node "model.shopify_buyer_segmentation.monthend_dates"
2020-11-10 09:24:13.249053 (Thread-1): Opening a new connection, currently in state closed
2020-11-10 09:24:13.249380 (Thread-1): On model.shopify_buyer_segmentation.monthend_dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.monthend_dates"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`monthend_dates`
  
  
  OPTIONS()
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );
    
2020-11-10 09:24:14.451938 (Thread-28): handling poll request
2020-11-10 09:24:14.452462 (Thread-28): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24f882b0>]}
2020-11-10 09:24:14.454825 (Thread-28): sending response (<Response 7223 bytes [200 OK]>) to 10.0.42.233
2020-11-10 09:24:15.227876 (Thread-1): finished collecting timing info
2020-11-10 09:24:15.228650 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69be6c07-c976-40e4-8b4a-e37a674c41ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bbe0c2710>]}
2020-11-10 09:24:15.229758 (Thread-1): 09:24:15 | 3 of 21 OK created table model dbt_buyer_segmentation.monthend_dates. [CREATE TABLE (59.0 rows, 0.0 Bytes processed) in 2.02s]
2020-11-10 09:24:15.229857 (Thread-1): Finished running node model.shopify_buyer_segmentation.monthend_dates
2020-11-10 09:24:15.229987 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_refunds_proc
2020-11-10 09:24:15.230085 (Thread-1): 09:24:15 | 4 of 21 SKIP relation dbt_buyer_segmentation.shopify_refunds_proc.... [SKIP]
2020-11-10 09:24:15.230149 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_refunds_proc
2020-11-10 09:24:15.230231 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_discounts_proc
2020-11-10 09:24:15.230304 (Thread-1): 09:24:15 | 5 of 21 SKIP relation dbt_buyer_segmentation.shopify_discounts_proc.. [SKIP]
2020-11-10 09:24:15.230363 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_discounts_proc
2020-11-10 09:24:15.230439 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_customers_proc
2020-11-10 09:24:15.230519 (Thread-1): 09:24:15 | 6 of 21 SKIP relation dbt_buyer_segmentation.shopify_customers_proc.. [SKIP]
2020-11-10 09:24:15.230591 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_customers_proc
2020-11-10 09:24:15.230673 (Thread-1): Began running node model.shopify_buyer_segmentation.ga_transactions
2020-11-10 09:24:15.230744 (Thread-1): 09:24:15 | 7 of 21 SKIP relation dbt_buyer_segmentation.ga_transactions......... [SKIP]
2020-11-10 09:24:15.230801 (Thread-1): Finished running node model.shopify_buyer_segmentation.ga_transactions
2020-11-10 09:24:15.231623 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_orders_proc
2020-11-10 09:24:15.231730 (Thread-1): 09:24:15 | 8 of 21 SKIP relation dbt_buyer_segmentation.shopify_orders_proc..... [SKIP]
2020-11-10 09:24:15.231794 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_orders_proc
2020-11-10 09:24:15.231885 (Thread-1): Began running node model.shopify_buyer_segmentation.agg_customers
2020-11-10 09:24:15.231959 (Thread-1): 09:24:15 | 9 of 21 SKIP relation dbt_buyer_segmentation.agg_customers........... [SKIP]
2020-11-10 09:24:15.232016 (Thread-1): Finished running node model.shopify_buyer_segmentation.agg_customers
2020-11-10 09:24:15.232091 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_products_proc
2020-11-10 09:24:15.232165 (Thread-1): 09:24:15 | 10 of 21 SKIP relation dbt_buyer_segmentation.shopify_products_proc.. [SKIP]
2020-11-10 09:24:15.232220 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_products_proc
2020-11-10 09:24:15.233014 (Thread-1): Began running node model.shopify_buyer_segmentation.transaction_by_order_number
2020-11-10 09:24:15.233109 (Thread-1): 09:24:15 | 11 of 21 SKIP relation dbt_buyer_segmentation.transaction_by_order_number [SKIP]
2020-11-10 09:24:15.233169 (Thread-1): Finished running node model.shopify_buyer_segmentation.transaction_by_order_number
2020-11-10 09:24:15.233902 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_by_transaction
2020-11-10 09:24:15.233997 (Thread-1): 09:24:15 | 12 of 21 SKIP relation dbt_buyer_segmentation.customers_by_transaction [SKIP]
2020-11-10 09:24:15.234059 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_by_transaction
2020-11-10 09:24:15.234459 (Thread-1): Began running node model.shopify_buyer_segmentation.agg_transactions
2020-11-10 09:24:15.234552 (Thread-1): 09:24:15 | 13 of 21 SKIP relation dbt_buyer_segmentation.agg_transactions....... [SKIP]
2020-11-10 09:24:15.234614 (Thread-1): Finished running node model.shopify_buyer_segmentation.agg_transactions
2020-11-10 09:24:15.235034 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_proc_qoq
2020-11-10 09:24:15.235126 (Thread-1): 09:24:15 | 14 of 21 SKIP relation dbt_buyer_segmentation.customers_proc_qoq..... [SKIP]
2020-11-10 09:24:15.235187 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_proc_qoq
2020-11-10 09:24:15.235272 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_proc_yoy
2020-11-10 09:24:15.235345 (Thread-1): 09:24:15 | 15 of 21 SKIP relation dbt_buyer_segmentation.customers_proc_yoy..... [SKIP]
2020-11-10 09:24:15.235401 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_proc_yoy
2020-11-10 09:24:15.235938 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_proc
2020-11-10 09:24:15.236030 (Thread-1): 09:24:15 | 16 of 21 SKIP relation dbt_buyer_segmentation.customers_proc......... [SKIP]
2020-11-10 09:24:15.236092 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_proc
2020-11-10 09:24:15.236488 (Thread-1): Began running node model.shopify_buyer_segmentation.segment_proc_buyers
2020-11-10 09:24:15.236581 (Thread-1): 09:24:15 | 17 of 21 SKIP relation dbt_buyer_segmentation.segment_proc_buyers.... [SKIP]
2020-11-10 09:24:15.236640 (Thread-1): Finished running node model.shopify_buyer_segmentation.segment_proc_buyers
2020-11-10 09:24:15.237004 (Thread-1): Began running node model.shopify_buyer_segmentation.segment_stats_buyers_agg
2020-11-10 09:24:15.237105 (Thread-1): 09:24:15 | 18 of 21 SKIP relation dbt_buyer_segmentation.segment_stats_buyers_agg [SKIP]
2020-11-10 09:24:15.237175 (Thread-1): Finished running node model.shopify_buyer_segmentation.segment_stats_buyers_agg
2020-11-10 09:24:15.237605 (Thread-1): Began running node model.shopify_buyer_segmentation.segment_stats_buyers_view
2020-11-10 09:24:15.237690 (Thread-1): 09:24:15 | 19 of 21 SKIP relation dbt_buyer_segmentation.segment_stats_buyers_view [SKIP]
2020-11-10 09:24:15.237758 (Thread-1): Finished running node model.shopify_buyer_segmentation.segment_stats_buyers_view
2020-11-10 09:24:15.237847 (Thread-1): Began running node model.shopify_buyer_segmentation.buyer_segment_lists
2020-11-10 09:24:15.237928 (Thread-1): 09:24:15 | 20 of 21 SKIP relation dbt_buyer_segmentation.buyer_segment_lists.... [SKIP]
2020-11-10 09:24:15.237993 (Thread-1): Finished running node model.shopify_buyer_segmentation.buyer_segment_lists
2020-11-10 09:24:15.238669 (Thread-1): Began running node model.shopify_buyer_segmentation.buyer_segment_stats
2020-11-10 09:24:15.238773 (Thread-1): 09:24:15 | 21 of 21 SKIP relation dbt_buyer_segmentation.buyer_segment_stats.... [SKIP]
2020-11-10 09:24:15.238842 (Thread-1): Finished running node model.shopify_buyer_segmentation.buyer_segment_stats
2020-11-10 09:24:15.292382 (MainThread): Acquiring new bigquery connection "master".
2020-11-10 09:24:15.292675 (MainThread): 09:24:15 | 
2020-11-10 09:24:15.292752 (MainThread): 09:24:15 | Finished running 21 table models in 6.76s.
2020-11-10 09:24:15.292815 (MainThread): Connection 'master' was properly closed.
2020-11-10 09:24:15.292862 (MainThread): Connection 'model.shopify_buyer_segmentation.monthend_dates' was properly closed.
2020-11-10 09:24:15.376706 (MainThread): 
2020-11-10 09:24:15.376819 (MainThread): Completed with 1 error and 0 warnings:
2020-11-10 09:24:15.376885 (MainThread): 
2020-11-10 09:24:15.376947 (MainThread): Database Error in model stores_proc (models/admin/stores_proc.sql)
2020-11-10 09:24:15.376999 (MainThread):   Unrecognized name: store_name at [26:7]
2020-11-10 09:24:15.377044 (MainThread):   compiled SQL at target/run/shopify_buyer_segmentation/models/admin/stores_proc.sql
2020-11-10 09:24:15.377114 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=18 TOTAL=21
2020-11-10 09:24:15.788679 (Thread-29): handling poll request
2020-11-10 09:24:15.789220 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24f50eb8>]}
2020-11-10 09:24:15.852630 (Thread-29): sending response (<Response 107951 bytes [200 OK]>) to 10.0.35.67
2020-11-10 09:24:16.194245 (Thread-30): handling status request
2020-11-10 09:24:16.194744 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24f02160>]}
2020-11-10 09:24:16.200977 (Thread-30): sending response (<Response 16728 bytes [200 OK]>) to 10.0.21.85
2020-11-10 09:28:59.938695 (Thread-31): handling status request
2020-11-10 09:28:59.939252 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24e959b0>]}
2020-11-10 09:28:59.945427 (Thread-31): sending response (<Response 16728 bytes [200 OK]>) to 10.0.35.171
2020-11-10 09:31:24.175122 (Thread-32): handling status request
2020-11-10 09:31:24.175609 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24f0b1d0>]}
2020-11-10 09:31:24.181867 (Thread-32): sending response (<Response 16728 bytes [200 OK]>) to 10.0.44.58
2020-11-10 09:31:59.654300 (Thread-33): handling status request
2020-11-10 09:31:59.654782 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24eaa898>]}
2020-11-10 09:31:59.660913 (Thread-33): sending response (<Response 16728 bytes [200 OK]>) to 10.0.25.53
2020-11-10 09:32:32.187855 (Thread-34): handling status request
2020-11-10 09:32:32.188375 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24eb8630>]}
2020-11-10 09:32:32.192279 (Thread-34): Checking header 'user-agent' tracing in whitelist set(), 44 additional messages skipped
2020-11-10 09:32:32.231916 (Thread-34): writing 1 spans (enabled:True), 77 additional messages skipped
2020-11-10 09:32:32.232087 (Thread-34): 
      name requests.request
        id 408772510085621630
  trace_id 15690955452636087258
 parent_id None
   service requests
  resource requests.request
      type http
     start 1605000752.191749
       end 1605000752.231826
  duration 0.040077s
     error 0
      tags 
           http.method:POST
           http.status_code:200
           http.url:https://fishtownanalytics.sinter-collect.com/com.snowplowanalytics.snowplow/tp2
           runtime-id:b02e17b6d3404bcea8c7363c41b00add, 77 additional messages skipped
2020-11-10 09:32:32.239115 (Thread-34): sending response (<Response 16728 bytes [200 OK]>) to 10.0.35.171
2020-11-10 09:32:33.100768 (AgentWriter): reported 1 traces in 0.00340s, 1 additional messages skipped
2020-11-10 09:32:33.101006 (AgentWriter): initialized RateSampler, sample 100% of traces, 63 additional messages skipped
2020-11-10 09:33:06.429209 (MainThread): writing 1 spans (enabled:True)
2020-11-10 09:33:06.429410 (MainThread): 
      name jinja2.compile
        id 14284477737498616095
  trace_id 2935786749528167658
 parent_id None
   service None
  resource <memory>
      type template
     start 1605000786.428372
       end 1605000786.429056
  duration 0.000684s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:b02e17b6d3404bcea8c7363c41b00add
2020-11-10 09:33:06.537668 (Thread-35): Got an acceptable cached parse result
2020-11-10 09:33:06.747213 (Thread-35): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:33:06.910391 (Thread-36): handling status request
2020-11-10 09:33:06.911005 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24d4fc18>]}
2020-11-10 09:33:06.912043 (Thread-36): sending response (<Response 184 bytes [200 OK]>) to 10.0.35.171
2020-11-10 09:33:07.111035 (AgentWriter): reported 40 traces in 0.00572s
2020-11-10 09:33:07.111290 (AgentWriter): initialized RateSampler, sample 100% of traces, 31 additional messages skipped
2020-11-10 09:33:08.294820 (Thread-37): handling status request
2020-11-10 09:33:08.295313 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24d1b3c8>]}
2020-11-10 09:33:08.296353 (Thread-37): sending response (<Response 760 bytes [200 OK]>) to 10.0.11.107
2020-11-10 09:33:25.053591 (Thread-38): handling status request
2020-11-10 09:33:25.054153 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24ecb3c8>]}
2020-11-10 09:33:25.055157 (Thread-38): sending response (<Response 760 bytes [200 OK]>) to 10.0.29.97
2020-11-10 09:33:32.957543 (MainThread): Connection 'model.shopify_buyer_segmentation.stores_proc' was properly closed.
2020-11-10 09:33:32.992151 (Thread-39): Parsing macros/split_part.sql
2020-11-10 09:33:32.997884 (Thread-39): Parsing macros/get_url_parameter.sql
2020-11-10 09:33:33.002520 (Thread-39): Parsing macros/get_column_values.sql
2020-11-10 09:33:33.009848 (Thread-39): Parsing macros/table_exists.sql
2020-11-10 09:33:33.012601 (Thread-39): Parsing macros/adapters.sql
2020-11-10 09:33:33.032970 (Thread-39): Parsing macros/etc.sql
2020-11-10 09:33:33.034310 (Thread-39): Parsing macros/catalog.sql
2020-11-10 09:33:33.040336 (Thread-39): Parsing macros/materializations/table.sql
2020-11-10 09:33:33.051053 (Thread-39): Parsing macros/materializations/view.sql
2020-11-10 09:33:33.053966 (Thread-39): Parsing macros/materializations/copy.sql
2020-11-10 09:33:33.058499 (Thread-39): Parsing macros/materializations/seed.sql
2020-11-10 09:33:33.061303 (Thread-39): Parsing macros/materializations/incremental.sql
2020-11-10 09:33:33.075150 (Thread-39): Parsing macros/materializations/snapshot.sql
2020-11-10 09:33:33.078639 (Thread-39): Parsing macros/core.sql
2020-11-10 09:33:33.082554 (Thread-39): Parsing macros/adapters/common.sql
2020-11-10 09:33:33.136440 (Thread-39): Parsing macros/materializations/helpers.sql
2020-11-10 09:33:33.148595 (Thread-39): Parsing macros/materializations/table/table.sql
2020-11-10 09:33:33.156134 (Thread-39): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:33:33.180182 (Thread-39): Parsing macros/materializations/view/view.sql
2020-11-10 09:33:33.186886 (Thread-39): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:33:33.192297 (Thread-39): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:33:33.194458 (Thread-39): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:33:33.205057 (Thread-39): Parsing macros/materializations/common/merge.sql
2020-11-10 09:33:33.221852 (Thread-39): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:33:33.239720 (Thread-39): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:33:33.241686 (Thread-39): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:33:33.288617 (Thread-40): handling status request
2020-11-10 09:33:33.289111 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25d195c0>]}
2020-11-10 09:33:33.289983 (Thread-40): sending response (<Response 184 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:33:33.290625 (Thread-39): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:33:33.294326 (Thread-39): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:33:33.297066 (Thread-39): Parsing macros/schema_tests/unique.sql
2020-11-10 09:33:33.300145 (Thread-39): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:33:33.304953 (Thread-39): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:33:33.307978 (Thread-39): Parsing macros/etc/query.sql
2020-11-10 09:33:33.309873 (Thread-39): Parsing macros/etc/datetime.sql
2020-11-10 09:33:33.321329 (Thread-39): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:33:33.322408 (Thread-39): Parsing macros/etc/is_incremental.sql
2020-11-10 09:33:33.324128 (Thread-39): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:33:33.381230 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:33:33.399704 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:33:33.419637 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:33:33.437438 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:33:33.456640 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:33:33.483632 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:33:33.502236 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:33:33.521571 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:33:33.543256 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:33:33.561747 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:33:33.581471 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:33:33.600526 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:33:33.618743 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:33:33.636391 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:33:33.652370 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:33:33.669337 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:33:33.693677 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:33:33.720096 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:33:33.739641 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:33:33.763322 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_refunds_proc".
2020-11-10 09:33:33.783503 (Thread-39): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_customers_proc".
2020-11-10 09:33:34.664230 (Thread-41): handling status request
2020-11-10 09:33:34.664766 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25e176a0>]}
2020-11-10 09:33:34.671126 (Thread-41): sending response (<Response 16728 bytes [200 OK]>) to 10.0.42.233
2020-11-10 09:33:42.775649 (Thread-42): handling status request
2020-11-10 09:33:42.776146 (Thread-42): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2545e208>]}
2020-11-10 09:33:42.782335 (Thread-42): sending response (<Response 16728 bytes [200 OK]>) to 10.0.25.53
2020-11-10 09:33:42.804869 (Thread-43): handling status request
2020-11-10 09:33:42.805371 (Thread-43): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb254743c8>]}
2020-11-10 09:33:42.815318 (Thread-43): sending response (<Response 16728 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:33:43.151144 (Thread-44): handling cli_args request
2020-11-10 09:33:43.151637 (Thread-44): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2545e048>]}
2020-11-10 09:33:43.160729 (Thread-44): Connection 'model.shopify_buyer_segmentation.shopify_customers_proc' was properly closed.
2020-11-10 09:33:44.102592 (Thread-44): sending response (<Response 137 bytes [200 OK]>) to 10.0.26.169
2020-11-10 09:33:44.170755 (MainThread): Partial parsing not enabled
2020-11-10 09:33:44.176750 (MainThread): Parsing macros/split_part.sql
2020-11-10 09:33:44.183822 (MainThread): Parsing macros/get_url_parameter.sql
2020-11-10 09:33:44.189517 (MainThread): Parsing macros/get_column_values.sql
2020-11-10 09:33:44.197200 (MainThread): Parsing macros/table_exists.sql
2020-11-10 09:33:44.200088 (MainThread): Parsing macros/adapters.sql
2020-11-10 09:33:44.220319 (MainThread): Parsing macros/etc.sql
2020-11-10 09:33:44.221716 (MainThread): Parsing macros/catalog.sql
2020-11-10 09:33:44.227819 (MainThread): Parsing macros/materializations/table.sql
2020-11-10 09:33:44.238117 (MainThread): Parsing macros/materializations/view.sql
2020-11-10 09:33:44.241046 (MainThread): Parsing macros/materializations/copy.sql
2020-11-10 09:33:44.245591 (MainThread): Parsing macros/materializations/seed.sql
2020-11-10 09:33:44.248472 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-10 09:33:44.262113 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-10 09:33:44.264920 (MainThread): Parsing macros/core.sql
2020-11-10 09:33:44.268775 (MainThread): Parsing macros/adapters/common.sql
2020-11-10 09:33:44.315412 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-10 09:33:44.324791 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-10 09:33:44.332811 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-10 09:33:44.362410 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-10 09:33:44.374023 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-10 09:33:44.383116 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-10 09:33:44.386500 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-10 09:33:44.395416 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-10 09:33:44.410049 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-10 09:33:44.427517 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-10 09:33:44.429451 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-10 09:33:44.458988 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-10 09:33:44.461069 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-10 09:33:44.462787 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-10 09:33:44.464646 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-10 09:33:44.467558 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-10 09:33:44.469357 (MainThread): Parsing macros/etc/query.sql
2020-11-10 09:33:44.470565 (MainThread): Parsing macros/etc/datetime.sql
2020-11-10 09:33:44.480710 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-10 09:33:44.481818 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-10 09:33:44.483568 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-10 09:33:44.494660 (MainThread): Partial parsing not enabled
2020-11-10 09:33:44.508554 (Thread-45): handling poll request
2020-11-10 09:33:44.509094 (Thread-45): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25d79358>]}
2020-11-10 09:33:44.514249 (Thread-45): sending response (<Response 10668 bytes [200 OK]>) to 10.0.29.97
2020-11-10 09:33:44.555074 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_by_transaction".
2020-11-10 09:33:44.583803 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_customers".
2020-11-10 09:33:44.601760 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.transaction_by_order_number".
2020-11-10 09:33:44.620484 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.agg_transactions".
2020-11-10 09:33:44.639310 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_view".
2020-11-10 09:33:44.666547 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc".
2020-11-10 09:33:44.685694 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_yoy".
2020-11-10 09:33:44.704949 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_stats_buyers_agg".
2020-11-10 09:33:44.728058 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.customers_proc_qoq".
2020-11-10 09:33:44.749714 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_lists".
2020-11-10 09:33:44.778775 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.buyer_segment_stats".
2020-11-10 09:33:44.807049 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.segment_proc_buyers".
2020-11-10 09:33:44.834219 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:33:44.860318 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:33:44.883812 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:33:44.900846 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.ga_transactions".
2020-11-10 09:33:44.934405 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_products_proc".
2020-11-10 09:33:44.956984 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_discounts_proc".
2020-11-10 09:33:44.976322 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_orders_proc".
2020-11-10 09:33:45.000511 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_refunds_proc".
2020-11-10 09:33:45.020263 (MainThread): Acquiring new bigquery connection "model.shopify_buyer_segmentation.shopify_customers_proc".
2020-11-10 09:33:45.323906 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 161 macros, 0 operations, 0 seed files, 0 sources
2020-11-10 09:33:45.326383 (MainThread): 
2020-11-10 09:33:45.326722 (MainThread): Acquiring new bigquery connection "master".
2020-11-10 09:33:45.399949 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-projects".
2020-11-10 09:33:45.400162 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-11-10 09:33:45.637822 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-projects_dbt_buyer_segmentation".
2020-11-10 09:33:45.638031 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-11-10 09:33:45.638679 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-10 09:33:45.855616 (MainThread): 09:33:45 | Concurrency: 1 threads (target='default')
2020-11-10 09:33:45.855743 (MainThread): 09:33:45 | 
2020-11-10 09:33:45.857434 (Thread-1): Began running node model.shopify_buyer_segmentation.stores_proc
2020-11-10 09:33:45.858547 (Thread-1): 09:33:45 | 1 of 21 START table model dbt_buyer_segmentation.stores_proc......... [RUN]
2020-11-10 09:33:45.858823 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.stores_proc".
2020-11-10 09:33:45.858915 (Thread-1): Compiling model.shopify_buyer_segmentation.stores_proc
2020-11-10 09:33:45.874336 (Thread-1): Writing injected SQL for node "model.shopify_buyer_segmentation.stores_proc"
2020-11-10 09:33:45.896191 (Thread-46): handling poll request
2020-11-10 09:33:45.896937 (Thread-46): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2538bc18>]}
2020-11-10 09:33:45.901196 (Thread-46): sending response (<Response 11874 bytes [200 OK]>) to 10.0.36.232
2020-11-10 09:33:45.897074 (Thread-1): finished collecting timing info
2020-11-10 09:33:45.910880 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.250', 34486), raddr=('172.217.164.138', 443)>
2020-11-10 09:33:45.911116 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.250', 53506), raddr=('172.217.7.202', 443)>
2020-11-10 09:33:45.911275 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.250', 40482), raddr=('172.217.8.10', 443)>
2020-11-10 09:33:45.911421 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.250', 34498), raddr=('172.217.164.138', 443)>
2020-11-10 09:33:45.933468 (Thread-1): Writing runtime SQL for node "model.shopify_buyer_segmentation.stores_proc"
2020-11-10 09:33:45.952319 (Thread-1): Opening a new connection, currently in state closed
2020-11-10 09:33:45.952671 (Thread-1): On model.shopify_buyer_segmentation.stores_proc: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.stores_proc"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`stores_proc`
  
  
  OPTIONS()
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
store,
bigquery_name, 
name as store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
FROM `dbt-projects.dbt_buyer_segmentation.data_feeds` 
where store_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );
    
2020-11-10 09:33:46.510829 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.stores_proc"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`stores_proc`
  
  
  OPTIONS()
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
store,
bigquery_name, 
name as store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
FROM `dbt-projects.dbt_buyer_segmentation.data_feeds` 
where store_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );
    
2020-11-10 09:33:46.511095 (Thread-1): finished collecting timing info
2020-11-10 09:33:46.511640 (Thread-1): Runtime Error in model stores_proc (models/admin/stores_proc.sql)
  404 Not found: Table dbt-projects:dbt_buyer_segmentation.data_feeds was not found in location US
  
  (job ID: ea20eeb7-fae7-447b-9c20-d9976f57349f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table dbt-projects:dbt_buyer_segmentation.data_feeds was not found in location US

(job ID: ea20eeb7-fae7-447b-9c20-d9976f57349f)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.stores_proc"} */
   2:
   3:
   4:  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`stores_proc`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    select 
  10:store,
  11:store_name,
  12:account,
  13:platform,
  14:max(time_of_entry) time_of_entry
  15:
  16:from  ( 
  17:
  18:SELECT  
  19:store,
  20:bigquery_name, 
  21:name as store_name,
  22:account,
  23:platform,
  24:time_of_entry,
  25:first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
  26:FROM `dbt-projects.dbt_buyer_segmentation.data_feeds` 
  27:where store_name != ''
  28:
  29:) 
  30:
  31:WHERE lv = time_of_entry
  32:group by store, store_name, account, platform
  33:  );
  34:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model stores_proc (models/admin/stores_proc.sql)
  404 Not found: Table dbt-projects:dbt_buyer_segmentation.data_feeds was not found in location US
  
  (job ID: ea20eeb7-fae7-447b-9c20-d9976f57349f)
2020-11-10 09:33:46.514803 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203a51b-3173-4c54-8178-8ab0917c5c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7086eedc50>]}
2020-11-10 09:33:46.516030 (Thread-1): 09:33:46 | 1 of 21 ERROR creating table model dbt_buyer_segmentation.stores_proc [ERROR in 0.66s]
2020-11-10 09:33:46.516130 (Thread-1): Finished running node model.shopify_buyer_segmentation.stores_proc
2020-11-10 09:33:46.516257 (Thread-1): Began running node model.shopify_buyer_segmentation.mappings_ga_proc
2020-11-10 09:33:46.517234 (Thread-1): 09:33:46 | 2 of 21 START table model dbt_buyer_segmentation.mappings_ga_proc.... [RUN]
2020-11-10 09:33:46.517500 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.mappings_ga_proc".
2020-11-10 09:33:46.517585 (Thread-1): Compiling model.shopify_buyer_segmentation.mappings_ga_proc
2020-11-10 09:33:46.524896 (Thread-1): Writing injected SQL for node "model.shopify_buyer_segmentation.mappings_ga_proc"
2020-11-10 09:33:46.545497 (Thread-1): finished collecting timing info
2020-11-10 09:33:46.549690 (Thread-1): Opening a new connection, currently in state closed
2020-11-10 09:33:46.550142 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-10 09:33:46.728553 (Thread-1): Writing runtime SQL for node "model.shopify_buyer_segmentation.mappings_ga_proc"
2020-11-10 09:33:46.752890 (Thread-1): On model.shopify_buyer_segmentation.mappings_ga_proc: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.mappings_ga_proc"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`mappings_ga_proc`
  
  
  OPTIONS()
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
store,
account,
bigquery_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY store ORDER BY time_of_entry DESC) lv
FROM `dbt-projects.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );
    
2020-11-10 09:33:47.244214 (Thread-47): handling poll request
2020-11-10 09:33:47.244747 (Thread-47): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25d8dfd0>]}
2020-11-10 09:33:47.247744 (Thread-47): sending response (<Response 17127 bytes [200 OK]>) to 10.0.3.8
2020-11-10 09:33:48.557925 (Thread-48): handling poll request
2020-11-10 09:33:48.558479 (Thread-48): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25d62278>]}
2020-11-10 09:33:48.559489 (Thread-48): sending response (<Response 287 bytes [200 OK]>) to 10.0.3.8
2020-11-10 09:33:48.842552 (Thread-1): finished collecting timing info
2020-11-10 09:33:48.843314 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203a51b-3173-4c54-8178-8ab0917c5c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7086f12208>]}
2020-11-10 09:33:48.844403 (Thread-1): 09:33:48 | 2 of 21 OK created table model dbt_buyer_segmentation.mappings_ga_proc [CREATE TABLE (10.0 rows, 910.0 Bytes processed) in 2.33s]
2020-11-10 09:33:48.844504 (Thread-1): Finished running node model.shopify_buyer_segmentation.mappings_ga_proc
2020-11-10 09:33:48.844630 (Thread-1): Began running node model.shopify_buyer_segmentation.monthend_dates
2020-11-10 09:33:48.845581 (Thread-1): 09:33:48 | 3 of 21 START table model dbt_buyer_segmentation.monthend_dates...... [RUN]
2020-11-10 09:33:48.845865 (Thread-1): Acquiring new bigquery connection "model.shopify_buyer_segmentation.monthend_dates".
2020-11-10 09:33:48.845956 (Thread-1): Compiling model.shopify_buyer_segmentation.monthend_dates
2020-11-10 09:33:48.852071 (Thread-1): Writing injected SQL for node "model.shopify_buyer_segmentation.monthend_dates"
2020-11-10 09:33:48.873884 (Thread-1): finished collecting timing info
2020-11-10 09:33:48.878027 (Thread-1): Opening a new connection, currently in state closed
2020-11-10 09:33:48.878483 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-10 09:33:49.060301 (Thread-1): Writing runtime SQL for node "model.shopify_buyer_segmentation.monthend_dates"
2020-11-10 09:33:49.082089 (Thread-1): On model.shopify_buyer_segmentation.monthend_dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "model.shopify_buyer_segmentation.monthend_dates"} */


  create or replace table `dbt-projects`.`dbt_buyer_segmentation`.`monthend_dates`
  
  
  OPTIONS()
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );
    
2020-11-10 09:33:49.872210 (Thread-49): handling poll request
2020-11-10 09:33:49.872706 (Thread-49): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25d8de80>]}
2020-11-10 09:33:49.875131 (Thread-49): sending response (<Response 7221 bytes [200 OK]>) to 10.0.6.63
2020-11-10 09:33:50.769185 (Thread-1): finished collecting timing info
2020-11-10 09:33:50.769993 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203a51b-3173-4c54-8178-8ab0917c5c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70870ac5c0>]}
2020-11-10 09:33:50.771082 (Thread-1): 09:33:50 | 3 of 21 OK created table model dbt_buyer_segmentation.monthend_dates. [CREATE TABLE (59.0 rows, 0.0 Bytes processed) in 1.92s]
2020-11-10 09:33:50.771184 (Thread-1): Finished running node model.shopify_buyer_segmentation.monthend_dates
2020-11-10 09:33:50.771312 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_refunds_proc
2020-11-10 09:33:50.771411 (Thread-1): 09:33:50 | 4 of 21 SKIP relation dbt_buyer_segmentation.shopify_refunds_proc.... [SKIP]
2020-11-10 09:33:50.771474 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_refunds_proc
2020-11-10 09:33:50.771555 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_discounts_proc
2020-11-10 09:33:50.771630 (Thread-1): 09:33:50 | 5 of 21 SKIP relation dbt_buyer_segmentation.shopify_discounts_proc.. [SKIP]
2020-11-10 09:33:50.771687 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_discounts_proc
2020-11-10 09:33:50.771763 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_customers_proc
2020-11-10 09:33:50.771834 (Thread-1): 09:33:50 | 6 of 21 SKIP relation dbt_buyer_segmentation.shopify_customers_proc.. [SKIP]
2020-11-10 09:33:50.771888 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_customers_proc
2020-11-10 09:33:50.771961 (Thread-1): Began running node model.shopify_buyer_segmentation.ga_transactions
2020-11-10 09:33:50.772030 (Thread-1): 09:33:50 | 7 of 21 SKIP relation dbt_buyer_segmentation.ga_transactions......... [SKIP]
2020-11-10 09:33:50.772086 (Thread-1): Finished running node model.shopify_buyer_segmentation.ga_transactions
2020-11-10 09:33:50.773026 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_orders_proc
2020-11-10 09:33:50.773203 (Thread-1): 09:33:50 | 8 of 21 SKIP relation dbt_buyer_segmentation.shopify_orders_proc..... [SKIP]
2020-11-10 09:33:50.773309 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_orders_proc
2020-11-10 09:33:50.773463 (Thread-1): Began running node model.shopify_buyer_segmentation.agg_customers
2020-11-10 09:33:50.773590 (Thread-1): 09:33:50 | 9 of 21 SKIP relation dbt_buyer_segmentation.agg_customers........... [SKIP]
2020-11-10 09:33:50.773660 (Thread-1): Finished running node model.shopify_buyer_segmentation.agg_customers
2020-11-10 09:33:50.773770 (Thread-1): Began running node model.shopify_buyer_segmentation.shopify_products_proc
2020-11-10 09:33:50.773858 (Thread-1): 09:33:50 | 10 of 21 SKIP relation dbt_buyer_segmentation.shopify_products_proc.. [SKIP]
2020-11-10 09:33:50.773927 (Thread-1): Finished running node model.shopify_buyer_segmentation.shopify_products_proc
2020-11-10 09:33:50.774601 (Thread-1): Began running node model.shopify_buyer_segmentation.transaction_by_order_number
2020-11-10 09:33:50.774791 (Thread-1): 09:33:50 | 11 of 21 SKIP relation dbt_buyer_segmentation.transaction_by_order_number [SKIP]
2020-11-10 09:33:50.774915 (Thread-1): Finished running node model.shopify_buyer_segmentation.transaction_by_order_number
2020-11-10 09:33:50.775736 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_by_transaction
2020-11-10 09:33:50.775916 (Thread-1): 09:33:50 | 12 of 21 SKIP relation dbt_buyer_segmentation.customers_by_transaction [SKIP]
2020-11-10 09:33:50.776033 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_by_transaction
2020-11-10 09:33:50.776744 (Thread-1): Began running node model.shopify_buyer_segmentation.agg_transactions
2020-11-10 09:33:50.776928 (Thread-1): 09:33:50 | 13 of 21 SKIP relation dbt_buyer_segmentation.agg_transactions....... [SKIP]
2020-11-10 09:33:50.777044 (Thread-1): Finished running node model.shopify_buyer_segmentation.agg_transactions
2020-11-10 09:33:50.777808 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_proc_qoq
2020-11-10 09:33:50.777986 (Thread-1): 09:33:50 | 14 of 21 SKIP relation dbt_buyer_segmentation.customers_proc_qoq..... [SKIP]
2020-11-10 09:33:50.778104 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_proc_qoq
2020-11-10 09:33:50.778263 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_proc_yoy
2020-11-10 09:33:50.778410 (Thread-1): 09:33:50 | 15 of 21 SKIP relation dbt_buyer_segmentation.customers_proc_yoy..... [SKIP]
2020-11-10 09:33:50.778518 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_proc_yoy
2020-11-10 09:33:50.779104 (Thread-1): Began running node model.shopify_buyer_segmentation.customers_proc
2020-11-10 09:33:50.779235 (Thread-1): 09:33:50 | 16 of 21 SKIP relation dbt_buyer_segmentation.customers_proc......... [SKIP]
2020-11-10 09:33:50.779305 (Thread-1): Finished running node model.shopify_buyer_segmentation.customers_proc
2020-11-10 09:33:50.780034 (Thread-1): Began running node model.shopify_buyer_segmentation.segment_proc_buyers
2020-11-10 09:33:50.780202 (Thread-1): 09:33:50 | 17 of 21 SKIP relation dbt_buyer_segmentation.segment_proc_buyers.... [SKIP]
2020-11-10 09:33:50.780308 (Thread-1): Finished running node model.shopify_buyer_segmentation.segment_proc_buyers
2020-11-10 09:33:50.781305 (Thread-1): Began running node model.shopify_buyer_segmentation.segment_stats_buyers_agg
2020-11-10 09:33:50.781429 (Thread-1): 09:33:50 | 18 of 21 SKIP relation dbt_buyer_segmentation.segment_stats_buyers_agg [SKIP]
2020-11-10 09:33:50.781497 (Thread-1): Finished running node model.shopify_buyer_segmentation.segment_stats_buyers_agg
2020-11-10 09:33:50.782414 (Thread-1): Began running node model.shopify_buyer_segmentation.segment_stats_buyers_view
2020-11-10 09:33:50.782523 (Thread-1): 09:33:50 | 19 of 21 SKIP relation dbt_buyer_segmentation.segment_stats_buyers_view [SKIP]
2020-11-10 09:33:50.782586 (Thread-1): Finished running node model.shopify_buyer_segmentation.segment_stats_buyers_view
2020-11-10 09:33:50.782673 (Thread-1): Began running node model.shopify_buyer_segmentation.buyer_segment_lists
2020-11-10 09:33:50.782748 (Thread-1): 09:33:50 | 20 of 21 SKIP relation dbt_buyer_segmentation.buyer_segment_lists.... [SKIP]
2020-11-10 09:33:50.782804 (Thread-1): Finished running node model.shopify_buyer_segmentation.buyer_segment_lists
2020-11-10 09:33:50.783630 (Thread-1): Began running node model.shopify_buyer_segmentation.buyer_segment_stats
2020-11-10 09:33:50.783720 (Thread-1): 09:33:50 | 21 of 21 SKIP relation dbt_buyer_segmentation.buyer_segment_stats.... [SKIP]
2020-11-10 09:33:50.783776 (Thread-1): Finished running node model.shopify_buyer_segmentation.buyer_segment_stats
2020-11-10 09:33:50.864466 (MainThread): Acquiring new bigquery connection "master".
2020-11-10 09:33:50.864881 (MainThread): 09:33:50 | 
2020-11-10 09:33:50.864971 (MainThread): 09:33:50 | Finished running 21 table models in 5.54s.
2020-11-10 09:33:50.865043 (MainThread): Connection 'master' was properly closed.
2020-11-10 09:33:50.865096 (MainThread): Connection 'model.shopify_buyer_segmentation.monthend_dates' was properly closed.
2020-11-10 09:33:50.901374 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.250', 53532), raddr=('172.217.7.202', 443)>
2020-11-10 09:33:50.901619 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.250', 53528), raddr=('172.217.7.202', 443)>
2020-11-10 09:33:50.901837 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.250', 40506), raddr=('172.217.8.10', 443)>
2020-11-10 09:33:50.901989 (MainThread): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.250', 34522), raddr=('172.217.164.138', 443)>
2020-11-10 09:33:50.968918 (MainThread): 
2020-11-10 09:33:50.969132 (MainThread): Completed with 1 error and 0 warnings:
2020-11-10 09:33:50.969232 (MainThread): 
2020-11-10 09:33:50.969321 (MainThread): Runtime Error in model stores_proc (models/admin/stores_proc.sql)
2020-11-10 09:33:50.969393 (MainThread):   404 Not found: Table dbt-projects:dbt_buyer_segmentation.data_feeds was not found in location US
2020-11-10 09:33:50.969456 (MainThread):   
2020-11-10 09:33:50.969523 (MainThread):   (job ID: ea20eeb7-fae7-447b-9c20-d9976f57349f)
2020-11-10 09:33:50.969620 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=18 TOTAL=21
2020-11-10 09:33:51.168481 (Thread-50): handling poll request
2020-11-10 09:33:51.168984 (Thread-50): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb253a57b8>]}
2020-11-10 09:33:51.234188 (Thread-50): sending response (<Response 108409 bytes [200 OK]>) to 10.0.26.205
2020-11-10 09:33:51.596156 (Thread-51): handling status request
2020-11-10 09:33:51.596704 (Thread-51): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25e32a58>]}
2020-11-10 09:33:51.612763 (Thread-51): sending response (<Response 16728 bytes [200 OK]>) to 10.0.35.67
2020-11-10 09:37:39.362045 (Thread-52): handling status request
2020-11-10 09:37:39.364118 (Thread-52): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e5d6373e-bdd8-490d-835f-8f45f185452c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25481fd0>]}
2020-11-10 09:37:39.370390 (Thread-52): sending response (<Response 16728 bytes [200 OK]>) to 10.0.35.67
